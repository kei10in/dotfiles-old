This is python-howto-3.2.2.info, produced by makeinfo version 4.13 from
python-howto-3.2.2.texi.

Generated by Sphinx 1.1.2.
INFO-DIR-SECTION Python v3 2 2
START-INFO-DIR-ENTRY
* Python HOWTOs: (python-howto-3.2.2.info). in-depth documents on specific topics
END-INFO-DIR-ENTRY

     Python 3.2.2, February 11, 2012

     Guido van Rossum\\Fred L. Drake, Jr., editor

     Copyright (C) 1990-2012, Python Software Foundation


File: python-howto-3.2.2.info,  Node: Top,  Next: Python Advocacy HOWTO,  Up: (dir)

Python HOWTOs
*************

     Python 3.2.2, February 11, 2012

     Guido van Rossum\\Fred L. Drake, Jr., editor

     Copyright (C) 1990-2012, Python Software Foundation

  Python HOWTOs are documents that cover a single, specific topic, and
attempt to cover it fairly completely. Modelled on the Linux
Documentation Project's HOWTO collection, this collection is an effort
to foster documentation that's more detailed than the Python Library
Reference.

  Currently, the HOWTOs are:

* Menu:

* Python Advocacy HOWTO::
* Porting Python 2 Code to Python 3::
* Porting Extension Modules to 3.0: Porting Extension Modules to 3 0.
* Curses Programming with Python::
* Descriptor HowTo Guide::
* Functional Programming HOWTO::
* Logging HOWTO::
* Logging Cookbook::
* Regular Expression HOWTO::
* Socket Programming HOWTO::
* Sorting HOW TO::
* Unicode HOWTO::
* HOWTO Fetch Internet Resources Using The urllib Package::
* HOWTO Use Python in the web::
* Index::

 --- The Detailed Node Listing ---

Python Advocacy HOWTO

* Reasons to Use Python::
* Arguments and Rebuttals::
* Useful Resources::

Reasons to Use Python

* Programmability::
* Prototyping::
* Simplicity and Ease of Understanding::
* Java Integration::

Porting Python 2 Code to Python 3

* Choosing a Strategy::
* Python 3 and 3to2::
* Python 2 and 2to3::
* Python 2/3 Compatible Source::
* Other Resources::

Choosing a Strategy

* Universal Bits of Advice::

Python 2 and 2to3

* Support Python 2.7: Support Python 2 7.
* Try to Support Python 2.6 and Newer Only: Try to Support Python 2 6 and Newer Only.
* Supporting Python 2.5 and Newer Only: Supporting Python 2 5 and Newer Only.
* Handle Common "Gotchas"::
* Eliminate -3 Warnings::
* Run 2to3::
* Verify & Test::

Try to Support Python 2.6 and Newer Only

* from __future__ import print_function::
* from __future__ import unicode_literals::
* Bytes literals::

Supporting Python 2.5 and Newer Only

* from __future__ import absolute_import::

Handle Common "Gotchas"

* from __future__ import division::
* Specify when opening a file as binary::
* Text files::
* Subclass object::
* Deal With the Bytes/String Dichotomy::
* Indexing bytes objects::
* __str__()/__unicode__(): __str__ /__unicode__.
* Don't Index on Exceptions::
* Don't use __getslice__ & Friends::
* Updating doctests::

Deal With the Bytes/String Dichotomy

* Mark Up Python 2 String Literals::
* Decide what APIs Will Accept::
* Bytes / Unicode Comparison::

Run 2to3

* Manually::
* During Installation::

Python 2/3 Compatible Source

* Follow The Steps for Using 2to3::
* Use six::
* Capturing the Currently Raised Exception::

Porting Extension Modules to 3.0

* Conditional compilation::
* Changes to Object APIs::
* Module initialization and state::
* Other options::

Changes to Object APIs

* str/unicode Unification::
* long/int Unification::

Curses Programming with Python

* What is curses?::
* Starting and ending a curses application::
* Windows and Pads::
* Displaying Text::
* User Input::
* For More Information::

What is curses?

* The Python curses module::

Displaying Text

* Attributes and Color::

Descriptor HowTo Guide

* Abstract::
* Definition and Introduction::
* Descriptor Protocol::
* Invoking Descriptors::
* Descriptor Example::
* Properties::
* Functions and Methods::
* Static Methods and Class Methods::

Functional Programming HOWTO

* Introduction::
* Iterators::
* Generator expressions and list comprehensions::
* Generators::
* Built-in functions::
* The itertools module::
* The functools module::
* Small functions and the lambda expression::
* Revision History and Acknowledgements::
* References::

Introduction

* Formal provability::
* Modularity::
* Ease of debugging and testing::
* Composability::

Iterators

* Data Types That Support Iterators::

Generators

* Passing values into a generator::

The itertools module

* Creating new iterators::
* Calling functions on elements::
* Selecting elements::
* Grouping elements::

The functools module

* The operator module::
* The functional module::

References

* General::
* Python-specific::
* Python documentation::

Logging HOWTO

* Basic Logging Tutorial::
* Advanced Logging Tutorial::
* Logging Levels::
* Useful Handlers::
* Exceptions raised during logging::
* Using arbitrary objects as messages::
* Optimization::

Basic Logging Tutorial

* When to use logging::
* A simple example::
* Logging to a file::
* Logging from multiple modules::
* Logging variable data::
* Changing the format of displayed messages::
* Displaying the date/time in messages::
* Next Steps::

Advanced Logging Tutorial

* Loggers::
* Handlers::
* Formatters::
* Configuring Logging::
* What happens if no configuration is provided::
* Configuring Logging for a Library::

Logging Levels

* Custom Levels::

Logging Cookbook

* Using logging in multiple modules::
* Multiple handlers and formatters::
* Logging to multiple destinations::
* Configuration server example::
* Dealing with handlers that block::
* Sending and receiving logging events across a network::
* Adding contextual information to your logging output::
* Logging to a single file from multiple processes::
* Using file rotation::
* Subclassing QueueHandler - a ZeroMQ example::
* Subclassing QueueListener - a ZeroMQ example::

Adding contextual information to your logging output

* Using LoggerAdapters to impart contextual information::
* Using Filters to impart contextual information::

Regular Expression HOWTO

* Introduction: Introduction<2>.
* Simple Patterns::
* Using Regular Expressions::
* More Pattern Power::
* Modifying Strings::
* Common Problems::
* Feedback::

Simple Patterns

* Matching Characters::
* Repeating Things::

Using Regular Expressions

* Compiling Regular Expressions::
* The Backslash Plague::
* Performing Matches::
* Module-Level Functions::
* Compilation Flags::

More Pattern Power

* More Metacharacters::
* Grouping::
* Non-capturing and Named Groups::
* Lookahead Assertions::

Modifying Strings

* Splitting Strings::
* Search and Replace::

Common Problems

* Use String Methods::
* match() versus search(): match versus search.
* Greedy versus Non-Greedy::
* Using re.VERBOSE: Using re VERBOSE.

Socket Programming HOWTO

* Sockets::
* Creating a Socket::
* Using a Socket::
* Disconnecting::
* Non-blocking Sockets::

Sockets

* History::

Creating a Socket

* IPC::

Using a Socket

* Binary Data::

Disconnecting

* When Sockets Die::

Non-blocking Sockets

* Performance::

Sorting HOW TO

* Sorting Basics::
* Key Functions::
* Operator Module Functions::
* Ascending and Descending::
* Sort Stability and Complex Sorts::
* The Old Way Using Decorate-Sort-Undecorate::
* The Old Way Using the cmp Parameter::
* Odd and Ends::

Unicode HOWTO

* Introduction to Unicode::
* Python's Unicode Support::
* Reading and Writing Unicode Data::
* Acknowledgements::

Introduction to Unicode

* History of Character Codes::
* Definitions::
* Encodings::
* References: References<2>.

Python's Unicode Support

* The String Type::
* Converting to Bytes::
* Unicode Literals in Python Source Code::
* Unicode Properties::
* References: References<3>.

Reading and Writing Unicode Data

* Unicode filenames::
* Tips for Writing Unicode-aware Programs::
* References: References<4>.

HOWTO Fetch Internet Resources Using The urllib Package

* Introduction: Introduction<3>.
* Fetching URLs::
* Handling Exceptions::
* info and geturl::
* Openers and Handlers::
* Basic Authentication::
* Proxies::
* Sockets and Layers::
* Footnotes::

Fetching URLs

* Data::
* Headers::

Handling Exceptions

* URLError::
* HTTPError::
* Wrapping it Up::

HTTPError

* Error Codes::

Wrapping it Up

* Number 1::
* Number 2::

HOWTO Use Python in the web

* The Low-Level View::
* Step back; WSGI: Step back WSGI.
* Model-View-Controller::
* Ingredients for Websites::
* Frameworks::

The Low-Level View

* Common Gateway Interface::
* mod_python::
* FastCGI and SCGI::
* mod_wsgi::

Common Gateway Interface

* Simple script for testing CGI::
* Setting up CGI on your own server::
* Common problems with CGI scripts::

FastCGI and SCGI

* Setting up FastCGI::

Step back: WSGI

* WSGI Servers::
* Case study; MoinMoin: Case study MoinMoin.

Ingredients for Websites

* Templates::
* Data persistence::

Frameworks

* Some notable frameworks::

Some notable frameworks

* Django::
* TurboGears::
* Zope::
* Other notable frameworks::


File: python-howto-3.2.2.info,  Node: Python Advocacy HOWTO,  Next: Porting Python 2 Code to Python 3,  Prev: Top,  Up: Top

1 Python Advocacy HOWTO
***********************

     Author: A.M. Kuchling

     Release: 0.03

Abstract
--------

It's usually difficult to get your management to accept open source
software, and Python is no exception to this rule.  This document
discusses reasons to use Python, strategies for winning acceptance,
facts and arguments you can use, and cases where you _shouldn't_ try to
use Python.

* Menu:

* Reasons to Use Python::
* Arguments and Rebuttals::
* Useful Resources::

Reasons to Use Python

* Programmability::
* Prototyping::
* Simplicity and Ease of Understanding::
* Java Integration::


File: python-howto-3.2.2.info,  Node: Reasons to Use Python,  Next: Arguments and Rebuttals,  Up: Python Advocacy HOWTO

1.1 Reasons to Use Python
=========================

There are several reasons to incorporate a scripting language into your
development process, and this section will discuss them, and why Python
has some properties that make it a particularly good choice.

* Menu:

* Programmability::
* Prototyping::
* Simplicity and Ease of Understanding::
* Java Integration::


File: python-howto-3.2.2.info,  Node: Programmability,  Next: Prototyping,  Up: Reasons to Use Python

1.1.1 Programmability
---------------------

Programs are often organized in a modular fashion.  Lower-level
operations are grouped together, and called by higher-level functions,
which may in turn be used as basic operations by still further upper
levels.

  For example, the lowest level might define a very low-level set of
functions for accessing a hash table.  The next level might use hash
tables to store the headers of a mail message, mapping a header name
like `Date' to a value such as `Tue, 13 May 1997 20:00:54 -0400'.  A
yet higher level may operate on message objects, without knowing or
caring that message headers are stored in a hash table, and so forth.

  Often, the lowest levels do very simple things; they implement a data
structure such as a binary tree or hash table, or they perform some
simple computation, such as converting a date string to a number.  The
higher levels then contain logic connecting these primitive operations.
Using the approach, the primitives can be seen as basic building blocks
which are then glued together to produce the complete product.

  Why is this design approach relevant to Python?  Because Python is
well suited to functioning as such a glue language.  A common approach
is to write a Python module that implements the lower level operations;
for the sake of speed, the implementation might be in C, Java, or even
Fortran.  Once the primitives are available to Python programs, the
logic underlying higher level operations is written in the form of
Python code.  The high-level logic is then more understandable, and
easier to modify.

  John Ousterhout wrote a paper that explains this idea at greater
length, entitled "Scripting: Higher Level Programming for the 21st
Century".  I recommend that you read this paper; see the references for
the URL.  Ousterhout is the inventor of the Tcl language, and therefore
argues that Tcl should be used for this purpose; he only briefly refers
to other languages such as Python, Perl, and Lisp/Scheme, but in
reality, Ousterhout's argument applies to scripting languages in
general, since you could equally write extensions for any of the
languages mentioned above.


File: python-howto-3.2.2.info,  Node: Prototyping,  Next: Simplicity and Ease of Understanding,  Prev: Programmability,  Up: Reasons to Use Python

1.1.2 Prototyping
-----------------

In _The Mythical Man-Month_, Fredrick Brooks suggests the following
rule when planning software projects: "Plan to throw one away; you will
anyway."  Brooks is saying that the first attempt at a software design
often turns out to be wrong; unless the problem is very simple or
you're an extremely good designer, you'll find that new requirements
and features become apparent once development has actually started.  If
these new requirements can't be cleanly incorporated into the program's
structure, you're presented with two unpleasant choices: hammer the new
features into the program somehow, or scrap everything and write a new
version of the program, taking the new features into account from the
beginning.

  Python provides you with a good environment for quickly developing an
initial prototype.  That lets you get the overall program structure and
logic right, and you can fine-tune small details in the fast
development cycle that Python provides.  Once you're satisfied with the
GUI interface or program output, you can translate the Python code into
C++, Fortran, Java, or some other compiled language.

  Prototyping means you have to be careful not to use too many Python
features that are hard to implement in your other language.  Using
`eval()', or regular expressions, or the `pickle' module, means that
you're going to need C or Java libraries for formula evaluation,
regular expressions, and serialization, for example.  But it's not hard
to avoid such tricky code, and in the end the translation usually isn't
very difficult.  The resulting code can be rapidly debugged, because
any serious logical errors will have been removed from the prototype,
leaving only more minor slip-ups in the translation to track down.

  This strategy builds on the earlier discussion of programmability.
Using Python as glue to connect lower-level components has obvious
relevance for constructing prototype systems.  In this way Python can
help you with development, even if end users never come in contact with
Python code at all.  If the performance of the Python version is
adequate and corporate politics allow it, you may not need to do a
translation into C or Java, but it can still be faster to develop a
prototype and then translate it, instead of attempting to produce the
final version immediately.

  One example of this development strategy is Microsoft Merchant
Server. Version 1.0 was written in pure Python, by a company that
subsequently was purchased by Microsoft.  Version 2.0 began to
translate the code into C++, shipping with some C++code and some Python
code.  Version 3.0 didn't contain any Python at all; all the code had
been translated into C++.  Even though the product doesn't contain a
Python interpreter, the Python language has still served a useful
purpose by speeding up development.

  This is a very common use for Python.  Past conference papers have
also described this approach for developing high-level numerical
algorithms; see David M. Beazley and Peter S. Lomdahl's paper "Feeding
a Large-scale Physics Application to Python" in the references for a
good example.  If an algorithm's basic operations are things like "Take
the inverse of this 4000x4000 matrix", and are implemented in some
lower-level language, then Python has almost no additional performance
cost; the extra time required for Python to evaluate an expression like
`m.invert()' is dwarfed by the cost of the actual computation.  It's
particularly good for applications where seemingly endless tweaking is
required to get things right. GUI interfaces and Web sites are prime
examples.

  The Python code is also shorter and faster to write (once you're
familiar with Python), so it's easier to throw it away if you decide
your approach was wrong; if you'd spent two weeks working on it instead
of just two hours, you might waste time trying to patch up what you've
got out of a natural reluctance to admit that those two weeks were
wasted.  Truthfully, those two weeks haven't been wasted, since you've
learnt something about the problem and the technology you're using to
solve it, but it's human nature to view this as a failure of some sort.


File: python-howto-3.2.2.info,  Node: Simplicity and Ease of Understanding,  Next: Java Integration,  Prev: Prototyping,  Up: Reasons to Use Python

1.1.3 Simplicity and Ease of Understanding
------------------------------------------

Python is definitely _not_ a toy language that's only usable for small
tasks.  The language features are general and powerful enough to enable
it to be used for many different purposes.  It's useful at the small
end, for 10- or 20-line scripts, but it also scales up to larger
systems that contain thousands of lines of code.

  However, this expressiveness doesn't come at the cost of an obscure
or tricky syntax.  While Python has some dark corners that can lead to
obscure code, there are relatively few such corners, and proper design
can isolate their use to only a few classes or modules.  It's certainly
possible to write confusing code by using too many features with too
little concern for clarity, but most Python code can look a lot like a
slightly-formalized version of human-understandable pseudocode.

  In _The New Hacker's Dictionary_, Eric S. Raymond gives the following
definition for "compact":

     Compact _adj._  Of a design, describes the valuable property that
     it can all be apprehended at once in one's head. This generally
     means the thing created from the design can be used with greater
     facility and fewer errors than an equivalent tool that is not
     compact. Compactness does not imply triviality or lack of power;
     for example, C is compact and FORTRAN is not, but C is more
     powerful than FORTRAN. Designs become non-compact through
     accreting features and cruft that don't merge cleanly into the
     overall design scheme (thus, some fans of Classic C maintain that
     ANSI C is no longer compact).

     (From <http://www.catb.org/~esr/jargon/html/C/compact.html>)

  In this sense of the word, Python is quite compact, because the
language has just a few ideas, which are used in lots of places.  Take
namespaces, for example.  Import a module with `import math', and you
create a new namespace called `math'.  Classes are also namespaces that
share many of the properties of modules, and have a few of their own;
for example, you can create instances of a class. Instances?  They're
yet another namespace.  Namespaces are currently implemented as Python
dictionaries, so they have the same methods as the standard dictionary
data type: .keys() returns all the keys, and so forth.

  This simplicity arises from Python's development history.  The
language syntax derives from different sources; ABC, a relatively
obscure teaching language, is one primary influence, and Modula-3 is
another.  (For more information about ABC and Modula-3, consult their
respective Web sites at <http://www.cwi.nl/~steven/abc/> and
<http://www.m3.org>.)  Other features have come from C, Icon, Algol-68,
and even Perl.  Python hasn't really innovated very much, but instead
has tried to keep the language small and easy to learn, building on
ideas that have been tried in other languages and found useful.

  Simplicity is a virtue that should not be underestimated.  It lets
you learn the language more quickly, and then rapidly write code - code
that often works the first time you run it.


File: python-howto-3.2.2.info,  Node: Java Integration,  Prev: Simplicity and Ease of Understanding,  Up: Reasons to Use Python

1.1.4 Java Integration
----------------------

If you're working with Java, Jython (<http://www.jython.org/>) is
definitely worth your attention.  Jython is a re-implementation of
Python in Java that compiles Python code into Java bytecodes.  The
resulting environment has very tight, almost seamless, integration with
Java.  It's trivial to access Java classes from Python, and you can
write Python classes that subclass Java classes.  Jython can be used
for prototyping Java applications in much the same way CPython is used,
and it can also be used for test suites for Java code, or embedded in a
Java application to add scripting capabilities.


File: python-howto-3.2.2.info,  Node: Arguments and Rebuttals,  Next: Useful Resources,  Prev: Reasons to Use Python,  Up: Python Advocacy HOWTO

1.2 Arguments and Rebuttals
===========================

Let's say that you've decided upon Python as the best choice for your
application.  How can you convince your management, or your fellow
developers, to use Python?  This section lists some common arguments
against using Python, and provides some possible rebuttals.

  *Python is freely available software that doesn't cost anything. How
good can it be?*

  Very good, indeed.  These days Linux and Apache, two other pieces of
open source software, are becoming more respected as alternatives to
commercial software, but Python hasn't had all the publicity.

  Python has been around for several years, with many users and
developers.  Accordingly, the interpreter has been used by many people,
and has gotten most of the bugs shaken out of it.  While bugs are still
discovered at intervals, they're usually either quite obscure (they'd
have to be, for no one to have run into them before) or they involve
interfaces to external libraries.  The internals of the language itself
are quite stable.

  Having the source code should be viewed as making the software
available for peer review; people can examine the code, suggest (and
implement) improvements, and track down bugs.  To find out more about
the idea of open source code, along with arguments and case studies
supporting it, go to <http://www.opensource.org>.

  *Who's going to support it?*

  Python has a sizable community of developers, and the number is still
growing.  The Internet community surrounding the language is an active
one, and is worth being considered another one of Python's advantages.
Most questions posted to the comp.lang.python newsgroup are quickly
answered by someone.

  Should you need to dig into the source code, you'll find it's clear
and well-organized, so it's not very difficult to write extensions and
track down bugs yourself.  If you'd prefer to pay for support, there
are companies and individuals who offer commercial support for Python.

  *Who uses Python for serious work?*

  Lots of people; one interesting thing about Python is the surprising
diversity of applications that it's been used for.  People are using
Python to:

   * Run Web sites

   * Write GUI interfaces

   * Control number-crunching code on supercomputers

   * Make a commercial application scriptable by embedding the Python
     interpreter inside it

   * Process large XML data sets

   * Build test suites for C or Java code

  Whatever your application domain is, there's probably someone who's
used Python for something similar.  Yet, despite being useable for such
high-end applications, Python's still simple enough to use for little
jobs.

  See <http://wiki.python.org/moin/OrganizationsUsingPython> for a list
of some of the  organizations that use Python.

  *What are the restrictions on Python's use?*

  They're practically nonexistent.  Consult the `Misc/COPYRIGHT' file
in the source distribution, or the section _history-and-license_ for
the full language, but it boils down to three conditions:

   * You have to leave the copyright notice on the software; if you
     don't include the source code in a product, you have to put the
     copyright notice in the supporting documentation.

   * Don't claim that the institutions that have developed Python
     endorse your product in any way.

   * If something goes wrong, you can't sue for damages.  Practically
     all software licenses contain this condition.

  Notice that you don't have to provide source code for anything that
contains Python or is built with it.  Also, the Python interpreter and
accompanying documentation can be modified and redistributed in any way
you like, and you don't have to pay anyone any licensing fees at all.

  *Why should we use an obscure language like Python instead of
well-known language X?*

  I hope this HOWTO, and the documents listed in the final section,
will help convince you that Python isn't obscure, and has a healthily
growing user base.  One word of advice: always present Python's
positive advantages, instead of concentrating on language X's failings.
People want to know why a solution is good, rather than why all the
other solutions are bad.  So instead of attacking a competing solution
on various grounds, simply show how Python's virtues can help.


File: python-howto-3.2.2.info,  Node: Useful Resources,  Prev: Arguments and Rebuttals,  Up: Python Advocacy HOWTO

1.3 Useful Resources
====================

<http://www.pythonology.com/success>
     The Python Success Stories are a collection of stories from
     successful users of Python, with the emphasis on business and
     corporate users.

<http://www.tcl.tk/doc/scripting.html>
     John Ousterhout's white paper on scripting is a good argument for
     the utility of scripting languages, though naturally enough, he
     emphasizes Tcl, the language he developed.  Most of the arguments
     would apply to any scripting language.

<http://www.python.org/workshops/1997-10/proceedings/beazley.html>
     The authors, David M. Beazley and Peter S. Lomdahl,  describe
     their use of Python at Los Alamos National Laboratory. It's
     another good example of how Python can help get real work done.
     This quotation from the paper has been echoed by many people:

          Originally developed as a large monolithic application for
          massively parallel processing systems, we have used Python to
          transform our application into a flexible, highly modular,
          and extremely powerful system for performing simulation, data
          analysis, and visualization. In addition, we describe how
          Python has solved a number of important problems related to
          the development, debugging, deployment, and maintenance of
          scientific software.

<http://pythonjournal.cognizor.com/pyj1/Everitt-Feit_interview98-V1.html>
     This interview with Andy Feit, discussing Infoseek's use of
     Python, can be used to show that choosing Python didn't introduce
     any difficulties into a company's development process, and
     provided some substantial benefits.

<http://www.python.org/workshops/1997-10/proceedings/stein.ps>
     For the 6th Python conference, Greg Stein presented a paper that
     traced Python's adoption and usage at a startup called eShop, and
     later at Microsoft.

<http://www.opensource.org>
     Management may be doubtful of the reliability and usefulness of
     software that wasn't written commercially.  This site presents
     arguments that show how open source software can have considerable
     advantages over closed-source software.

<http://www.faqs.org/docs/Linux-mini/Advocacy.html>
     The Linux Advocacy mini-HOWTO was the inspiration for this
     document, and is also well worth reading for general suggestions
     on winning acceptance for a new technology, such as Linux or
     Python.  In general, you won't make much progress by simply
     attacking existing systems and complaining about their
     inadequacies; this often ends up looking like unfocused whining.
     It's much better to point out some of the many areas where Python
     is an improvement over other systems.


File: python-howto-3.2.2.info,  Node: Porting Python 2 Code to Python 3,  Next: Porting Extension Modules to 3 0,  Prev: Python Advocacy HOWTO,  Up: Top

2 Porting Python 2 Code to Python 3
***********************************

     author: Brett Cannon

Abstract
--------

With Python 3 being the future of Python while Python 2 is still in
active use, it is good to have your project available for both major
releases of Python. This guide is meant to help you choose which
strategy works best for your project to support both Python 2 & 3 along
with how to execute that strategy.

  If you are looking to port an extension module instead of pure Python
code, please see *note Porting Extension Modules to 3.0: e.

* Menu:

* Choosing a Strategy::
* Python 3 and 3to2::
* Python 2 and 2to3::
* Python 2/3 Compatible Source::
* Other Resources::

Choosing a Strategy

* Universal Bits of Advice::

Python 2 and 2to3

* Support Python 2.7: Support Python 2 7.
* Try to Support Python 2.6 and Newer Only: Try to Support Python 2 6 and Newer Only.
* Supporting Python 2.5 and Newer Only: Supporting Python 2 5 and Newer Only.
* Handle Common "Gotchas"::
* Eliminate -3 Warnings::
* Run 2to3::
* Verify & Test::

Try to Support Python 2.6 and Newer Only

* from __future__ import print_function::
* from __future__ import unicode_literals::
* Bytes literals::

Supporting Python 2.5 and Newer Only

* from __future__ import absolute_import::

Handle Common "Gotchas"

* from __future__ import division::
* Specify when opening a file as binary::
* Text files::
* Subclass object::
* Deal With the Bytes/String Dichotomy::
* Indexing bytes objects::
* __str__()/__unicode__(): __str__ /__unicode__.
* Don't Index on Exceptions::
* Don't use __getslice__ & Friends::
* Updating doctests::

Deal With the Bytes/String Dichotomy

* Mark Up Python 2 String Literals::
* Decide what APIs Will Accept::
* Bytes / Unicode Comparison::

Run 2to3

* Manually::
* During Installation::

Python 2/3 Compatible Source

* Follow The Steps for Using 2to3::
* Use six::
* Capturing the Currently Raised Exception::


File: python-howto-3.2.2.info,  Node: Choosing a Strategy,  Next: Python 3 and 3to2,  Up: Porting Python 2 Code to Python 3

2.1 Choosing a Strategy
=======================

When a project makes the decision that it's time to support both Python
2 & 3, a decision needs to be made as to how to go about accomplishing
that goal.  The chosen strategy will depend on how large the project's
existing codebase is and how much divergence you want from your Python
2 codebase from your Python 3 one (e.g., starting a new version with
Python 3).

  If your project is brand-new or does not have a large codebase, then
you may want to consider writing/porting *note all of your code for
Python 3 and use 3to2: 10. to port your code for Python 2.

  If you would prefer to maintain a codebase which is semantically *and*
syntactically compatible with Python 2 & 3 simultaneously, you can write
*note Python 2/3 Compatible Source: 11. While this tends to lead to
somewhat non-idiomatic code, it does mean you keep a rapid development
process for you, the developer.

  Finally, you do have the option of *note using 2to3: 12. to translate
Python 2 code into Python 3 code (with some manual help). This can take
the form of branching your code and using 2to3 to start a Python 3
branch. You can also have users perform the translation as installation
time automatically so that you only have to maintain a Python 2
codebase.

  Regardless of which approach you choose, porting is not as hard or
time-consuming as you might initially think. You can also tackle the
problem piece-meal as a good portion of porting is simply updating your
code to follow current best practices in a Python 2/3 compatible way.

* Menu:

* Universal Bits of Advice::


File: python-howto-3.2.2.info,  Node: Universal Bits of Advice,  Up: Choosing a Strategy

2.1.1 Universal Bits of Advice
------------------------------

Regardless of what strategy you pick, there are a few things you should
consider.

  One is make sure you have a robust test suite. You need to make sure
everything continues to work, just like when you support a new minor
version of Python.  This means making sure your test suite is thorough
and is ported properly between Python 2 & 3. You will also most likely
want to use something like tox(1) to automate testing between both a
Python 2 and Python 3 VM.

  Two, once your project has Python 3 support, make sure to add the
proper classifier on the Cheeseshop(2) (PyPI(3)). To have your project
listed as Python 3 compatible it must have the Python 3 classifier(4)
(from
<http://techspot.zzzeek.org/2011/01/24/zzzeek-s-guide-to-python-3-porting/>):

    setup(
      name='Your Library',
      version='1.0',
      classifiers=[
          # make sure to use :: Python *and* :: Python :: 3 so
          # that pypi can list the package on the python 3 page
          'Programming Language :: Python',
          'Programming Language :: Python :: 3'
      ],
      packages=['yourlibrary'],
      # make sure to add custom_fixers to the MANIFEST.in
      include_package_data=True,
      # ...
    )

Doing so will cause your project to show up in the Python 3 packages
list(5). You will know you set the classifier properly as visiting your
project page on the Cheeseshop will show a Python 3 logo in the
upper-left corner of the page.

  Three, the six(6) project provides a library which helps iron out
differences between Python 2 & 3. If you find there is a sticky point
that is a continual point of contention in your translation or
maintenance of code, consider using a source-compatible solution
relying on six. If you have to create your own Python 2/3 compatible
solution, you can use `sys.version_info[0] >= 3' as a guard.

  Four, read all the approaches. Just because some bit of advice
applies to one approach more than another doesn't mean that some advice
doesn't apply to other strategies.

  Five, drop support for older Python versions if possible. Python
2.5(7) introduced a lot of useful syntax and libraries which have
become idiomatic in Python 3. Python 2.6(8) introduced future
statements which makes compatibility much easier if you are going from
Python 2 to 3.  Python 2.7(9) continues the trend in the stdlib. So
choose the newest version of Python which you believe can be your
minimum support version and work from there.

  ---------- Footnotes ----------

  (1) http://codespeak.net/tox/

  (2) http://pypi.python.org/

  (3) http://pypi.python.org/

  (4) http://pypi.python.org/pypi?:action=browse&c=533

  (5) http://pypi.python.org/pypi?:action=browse&c=533&show=all

  (6) http://packages.python.org/six

  (7) http://www.python.org/2.5.x

  (8) http://www.python.org/2.6.x

  (9) http://www.python.org/2.7.x


File: python-howto-3.2.2.info,  Node: Python 3 and 3to2,  Next: Python 2 and 2to3,  Prev: Choosing a Strategy,  Up: Porting Python 2 Code to Python 3

2.2 Python 3 and 3to2
=====================

If you are starting a new project or your codebase is small enough, you
may want to consider writing your code for Python 3 and backporting to
Python 2 using 3to2(1). Thanks to Python 3 being more strict about
things than Python 2 (e.g., bytes vs. strings), the source translation
can be easier and more straightforward than from Python 2 to 3. Plus it
gives you more direct experience developing in Python 3 which, since it
is the future of Python, is a good thing long-term.

  A drawback of this approach is that 3to2 is a third-party project.
This means that the Python core developers (and thus this guide) can
make no promises about how well 3to2 works at any time. There is
nothing to suggest, though, that 3to2 is not a high-quality project.

  ---------- Footnotes ----------

  (1) https://bitbucket.org/amentajo/lib3to2/overview


File: python-howto-3.2.2.info,  Node: Python 2 and 2to3,  Next: Python 2/3 Compatible Source,  Prev: Python 3 and 3to2,  Up: Porting Python 2 Code to Python 3

2.3 Python 2 and 2to3
=====================

Included with Python since 2.6, the 2to3(1) tool (and `lib2to3' module)
helps with porting Python 2 to Python 3 by performing various source
translations. This is a perfect solution for projects which wish to
branch their Python 3 code from their Python 2 codebase and maintain
them as independent codebases. You can even begin preparing to use this
approach today by writing future-compatible Python code which works
cleanly in Python 2 in conjunction with 2to3; all steps outlined below
will work with Python 2 code up to the point when the actual use of
2to3 occurs.

  Use of 2to3 as an on-demand translation step at install time is also
possible, preventing the need to maintain a separate Python 3 codebase,
but this approach does come with some drawbacks. While users will only
have to pay the translation cost once at installation, you as a
developer will need to pay the cost regularly during development. If
your codebase is sufficiently large enough then the translation step
ends up acting like a compilation step, robbing you of the rapid
development process you are used to with Python.  Obviously the time
required to translate a project will vary, so do an experimental
translation just to see how long it takes to evaluate whether you
prefer this approach compared to using *note Python 2/3 Compatible
Source: 11. or simply keeping a separate Python 3 codebase.

  Below are the typical steps taken by a project which uses a
2to3-based approach to supporting Python 2 & 3.

* Menu:

* Support Python 2.7: Support Python 2 7.
* Try to Support Python 2.6 and Newer Only: Try to Support Python 2 6 and Newer Only.
* Supporting Python 2.5 and Newer Only: Supporting Python 2 5 and Newer Only.
* Handle Common "Gotchas"::
* Eliminate -3 Warnings::
* Run 2to3::
* Verify & Test::

  ---------- Footnotes ----------

  (1) http://docs.python.org/py3k/library/2to3.html


File: python-howto-3.2.2.info,  Node: Support Python 2 7,  Next: Try to Support Python 2 6 and Newer Only,  Up: Python 2 and 2to3

2.3.1 Support Python 2.7
------------------------

As a first step, make sure that your project is compatible with Python
2.7(1).  This is just good to do as Python 2.7 is the last release of
Python 2 and thus will be used for a rather long time. It also allows
for use of the `-3' flag to Python to help discover places in your code
which 2to3 cannot handle but are known to cause issues.

  ---------- Footnotes ----------

  (1) http://www.python.org/2.7.x


File: python-howto-3.2.2.info,  Node: Try to Support Python 2 6 and Newer Only,  Next: Supporting Python 2 5 and Newer Only,  Prev: Support Python 2 7,  Up: Python 2 and 2to3

2.3.2 Try to Support Python 2.6 and Newer Only
----------------------------------------------

While not possible for all projects, if you can support Python 2.6(1)
and newer *only*, your life will be much easier. Various future
statements, stdlib additions, etc. exist only in Python 2.6 and later
which greatly assist in porting to Python 3. But if you project must
keep support for Python 2.5(2) (or even Python 2.4(3)) then it is still
possible to port to Python 3.

  Below are the benefits you gain if you only have to support Python
2.6 and newer. Some of these options are personal choice while others
are *strongly* recommended (the ones that are more for personal choice
are labeled as such).  If you continue to support older versions of
Python then you at least need to watch out for situations that these
solutions fix.

* Menu:

* from __future__ import print_function::
* from __future__ import unicode_literals::
* Bytes literals::

  ---------- Footnotes ----------

  (1) http://www.python.org/2.6.x

  (2) http://www.python.org/2.5.x

  (3) http://www.python.org/2.4.x


File: python-howto-3.2.2.info,  Node: from __future__ import print_function,  Next: from __future__ import unicode_literals,  Up: Try to Support Python 2 6 and Newer Only

2.3.2.1 `from __future__ import print_function'
...............................................

This is a personal choice. 2to3 handles the translation from the print
statement to the print function rather well so this is an optional
step. This future statement does help, though, with getting used to
typing `print('Hello, World')' instead of `print 'Hello, World''.


File: python-howto-3.2.2.info,  Node: from __future__ import unicode_literals,  Next: Bytes literals,  Prev: from __future__ import print_function,  Up: Try to Support Python 2 6 and Newer Only

2.3.2.2 `from __future__ import unicode_literals'
.................................................

Another personal choice. You can always mark what you want to be a
(unicode) string with a `u' prefix to get the same effect. But
regardless of whether you use this future statement or not, you *must*
make sure you know exactly which Python 2 strings you want to be bytes,
and which are to be strings. This means you should, *at minimum* mark
all strings that are meant to be text strings with a `u' prefix if you
do not use this future statement.


File: python-howto-3.2.2.info,  Node: Bytes literals,  Prev: from __future__ import unicode_literals,  Up: Try to Support Python 2 6 and Newer Only

2.3.2.3 Bytes literals
......................

This is a *very* important one. The ability to prefix Python 2 strings
that are meant to contain bytes with a `b' prefix help to very clearly
delineate what is and is not a Python 3 string. When you run 2to3 on
code, all Python 2 strings become Python 3 strings *unless* they are
prefixed with `b'.

  There are some differences between byte literals in Python 2 and
those in Python 3 thanks to the bytes type just being an alias to `str'
in Python 2.  Probably the biggest "gotcha" is that indexing results in
different values. In Python 2, the value of `b'py'[1]' is `'y'', while
in Python 3 it's `121'.  You can avoid this disparity by always slicing
at the size of a single element: `b'py'[1:2]' is `'y'' in Python 2 and
`b'y'' in Python 3 (i.e., close enough).

  You cannot concatenate bytes and strings in Python 3. But since in
Python 2 has bytes aliased to `str', it will succeed: `b'a' + u'b''
works in Python 2, but `b'a' + 'b'' in Python 3 is a `TypeError'. A
similar issue also comes about when doing comparisons between bytes and
strings.


File: python-howto-3.2.2.info,  Node: Supporting Python 2 5 and Newer Only,  Next: Handle Common "Gotchas",  Prev: Try to Support Python 2 6 and Newer Only,  Up: Python 2 and 2to3

2.3.3 Supporting Python 2.5 and Newer Only
------------------------------------------

If you are supporting Python 2.5(1) and newer there are still some
features of Python that you can utilize.

* Menu:

* from __future__ import absolute_import::

  ---------- Footnotes ----------

  (1) http://www.python.org/2.5.x


File: python-howto-3.2.2.info,  Node: from __future__ import absolute_import,  Up: Supporting Python 2 5 and Newer Only

2.3.3.1 `from __future__ import absolute_import'
................................................

Implicit relative imports (e.g., importing `spam.bacon' from within
`spam.eggs' with the statement `import bacon') does not work in Python
3.  This future statement moves away from that and allows the use of
explicit relative imports (e.g., `from . import bacon').

  In Python 2.5(1) you must use the __future__ statement to get to use
explicit relative imports and prevent implicit ones. In Python 2.6(2)
explicit relative imports are available without the statement, but you
still want the __future__ statement to prevent implicit relative
imports. In Python 2.7(3) the __future__ statement is not needed. In
other words, unless you are only supporting Python 2.7 or a version
earlier than Python 2.5, use the __future__ statement.

  ---------- Footnotes ----------

  (1) http://www.python.org/2.5.x

  (2) http://www.python.org/2.6.x

  (3) http://www.python.org/2.7.x


File: python-howto-3.2.2.info,  Node: Handle Common "Gotchas",  Next: Eliminate -3 Warnings,  Prev: Supporting Python 2 5 and Newer Only,  Up: Python 2 and 2to3

2.3.4 Handle Common "Gotchas"
-----------------------------

There are a few things that just consistently come up as sticking
points for people which 2to3 cannot handle automatically or can easily
be done in Python 2 to help modernize your code.

* Menu:

* from __future__ import division::
* Specify when opening a file as binary::
* Text files::
* Subclass object::
* Deal With the Bytes/String Dichotomy::
* Indexing bytes objects::
* __str__()/__unicode__(): __str__ /__unicode__.
* Don't Index on Exceptions::
* Don't use __getslice__ & Friends::
* Updating doctests::


File: python-howto-3.2.2.info,  Node: from __future__ import division,  Next: Specify when opening a file as binary,  Up: Handle Common "Gotchas"

2.3.4.1 `from __future__ import division'
.........................................

While the exact same outcome can be had by using the `-Qnew' argument to
Python, using this future statement lifts the requirement that your
users use the flag to get the expected behavior of division in Python 3
(e.g., `1/2 == 0.5; 1//2 == 0').


File: python-howto-3.2.2.info,  Node: Specify when opening a file as binary,  Next: Text files,  Prev: from __future__ import division,  Up: Handle Common "Gotchas"

2.3.4.2 Specify when opening a file as binary
.............................................

Unless you have been working on Windows, there is a chance you have not
always bothered to add the `b' mode when opening a binary file (e.g.,
`rb' for binary reading).  Under Python 3, binary files and text files
are clearly distinct and mutually incompatible; see the `io' module for
details.  Therefore, you *must* make a decision of whether a file will
be used for binary access (allowing to read and/or write bytes data) or
text access (allowing to read and/or write unicode data).


File: python-howto-3.2.2.info,  Node: Text files,  Next: Subclass object,  Prev: Specify when opening a file as binary,  Up: Handle Common "Gotchas"

2.3.4.3 Text files
..................

Text files created using `open()' under Python 2 return byte strings,
while under Python 3 they return unicode strings.  Depending on your
porting strategy, this can be an issue.

  If you want text files to return unicode strings in Python 2, you
have two possibilities:

   * Under Python 2.6 and higher, use `io.open()'.  Since `io.open()'
     is essentially the same function in both Python 2 and Python 3, it
     will help iron out any issues that might arise.

   * If pre-2.6 compatibility is needed, then you should use
     `codecs.open()' instead.  This will make sure that you get back
     unicode strings in Python 2.


File: python-howto-3.2.2.info,  Node: Subclass object,  Next: Deal With the Bytes/String Dichotomy,  Prev: Text files,  Up: Handle Common "Gotchas"

2.3.4.4 Subclass `object'
.........................

New-style classes have been around since Python 2.2(1). You need to
make sure you are subclassing from `object' to avoid odd edge cases
involving method resolution order, etc. This continues to be totally
valid in Python 3 (although unneeded as all classes implicitly inherit
from `object').

  ---------- Footnotes ----------

  (1) http://www.python.org/2.2.x


File: python-howto-3.2.2.info,  Node: Deal With the Bytes/String Dichotomy,  Next: Indexing bytes objects,  Prev: Subclass object,  Up: Handle Common "Gotchas"

2.3.4.5 Deal With the Bytes/String Dichotomy
............................................

One of the biggest issues people have when porting code to Python 3 is
handling the bytes/string dichotomy. Because Python 2 allowed the `str'
type to hold textual data, people have over the years been rather loose
in their delineation of what `str' instances held text compared to
bytes. In Python 3 you cannot be so care-free anymore and need to
properly handle the difference. The key handling this issue to to make
sure that *every* string literal in your Python 2 code is either
syntactically of functionally marked as either bytes or text data.
After this is done you then need to make sure your APIs are designed to
either handle a specific type or made to be properly polymorphic.

* Menu:

* Mark Up Python 2 String Literals::
* Decide what APIs Will Accept::
* Bytes / Unicode Comparison::


File: python-howto-3.2.2.info,  Node: Mark Up Python 2 String Literals,  Next: Decide what APIs Will Accept,  Up: Deal With the Bytes/String Dichotomy

2.3.4.6 Mark Up Python 2 String Literals
........................................

First thing you must do is designate every single string literal in
Python 2 as either textual or bytes data. If you are only supporting
Python 2.6 or newer, this can be accomplished by marking bytes literals
with a `b' prefix and then designating textual data with a `u' prefix
or using the `unicode_literals' future statement.

  If your project supports versions of Python pre-dating 2.6, then you
should use the six(1) project and its `b()' function to denote bytes
literals. For text literals you can either use six's `u()' function or
use a `u' prefix.

  ---------- Footnotes ----------

  (1) http://packages.python.org/six


File: python-howto-3.2.2.info,  Node: Decide what APIs Will Accept,  Next: Bytes / Unicode Comparison,  Prev: Mark Up Python 2 String Literals,  Up: Deal With the Bytes/String Dichotomy

2.3.4.7 Decide what APIs Will Accept
....................................

In Python 2 it was very easy to accidentally create an API that
accepted both bytes and textual data. But in Python 3, thanks to the
more strict handling of disparate types, this loose usage of bytes and
text together tends to fail.

  Take the dict `{b'a': 'bytes', u'a': 'text'}' in Python 2.6. It
creates the dict `{u'a': 'text'}' since `b'a' == u'a''. But in Python 3
the equivalent dict creates `{b'a': 'bytes', 'a': 'text'}', i.e., no
lost data. Similar issues can crop up when transitioning Python 2 code
to Python 3.

  This means you need to choose what an API is going to accept and
create and consistently stick to that API in both Python 2 and 3.


File: python-howto-3.2.2.info,  Node: Bytes / Unicode Comparison,  Prev: Decide what APIs Will Accept,  Up: Deal With the Bytes/String Dichotomy

2.3.4.8 Bytes / Unicode Comparison
..................................

In Python 3, mixing bytes and unicode is forbidden in most situations;
it will raise a `TypeError' where Python 2 would have attempted an
implicit coercion between types.  However, there is one case where it
doesn't and it can be very misleading:

    >>> b"" == ""
    False

This is because an equality comparison is required by the language to
always succeed (and return `False' for incompatible types).  However,
this also means that code incorrectly ported to Python 3 can display
buggy behaviour if such comparisons are silently executed.  To detect
such situations, Python 3 has a `-b' flag that will display a warning:

    $ python3 -b
    >>> b"" == ""
    __main__:1: BytesWarning: Comparison between bytes and string
    False

To turn the warning into an exception, use the `-bb' flag instead:

    $ python3 -bb
    >>> b"" == ""
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    BytesWarning: Comparison between bytes and string



File: python-howto-3.2.2.info,  Node: Indexing bytes objects,  Next: __str__ /__unicode__,  Prev: Deal With the Bytes/String Dichotomy,  Up: Handle Common "Gotchas"

2.3.4.9 Indexing bytes objects
..............................

Another potentially surprising change is the indexing behaviour of bytes
objects in Python 3:

    >>> b"xyz"[0]
    120

Indeed, Python 3 bytes objects (as well as `bytearray' objects) are
sequences of integers.  But code converted from Python 2 will often
assume that indexing a bytestring produces another bytestring, not an
integer.  To reconcile both behaviours, use slicing:

    >>> b"xyz"[0:1]
    b'x'
    >>> n = 1
    >>> b"xyz"[n:n+1]
    b'y'

The only remaining gotcha is that an out-of-bounds slice returns an
empty bytes object instead of raising `IndexError':

    >>> b"xyz"[3]
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    IndexError: index out of range
    >>> b"xyz"[3:4]
    b''



File: python-howto-3.2.2.info,  Node: __str__ /__unicode__,  Next: Don't Index on Exceptions,  Prev: Indexing bytes objects,  Up: Handle Common "Gotchas"

2.3.4.10 `__str__()'/`__unicode__()'
....................................

In Python 2, objects can specify both a string and unicode
representation of themselves. In Python 3, though, there is only a
string representation. This becomes an issue as people can
inadvertently do things in their `__str__()' methods which have
unpredictable results (e.g., infinite recursion if you happen to use
the `unicode(self).encode('utf8')' idiom as the body of your
`__str__()' method).

  There are two ways to solve this issue. One is to use a custom 2to3
fixer. The blog post at
<http://lucumr.pocoo.org/2011/1/22/forwards-compatible-python/>
specifies how to do this. That will allow 2to3 to change all instances
of `def __unicode(self): ...' to `def __str__(self): ...'. This does
require you define your `__str__()' method in Python 2 before your
`__unicode__()' method.

  The other option is to use a mixin class. This allows you to only
define a `__unicode__()' method for your class and let the mixin derive
`__str__()' for you (code from
<http://lucumr.pocoo.org/2011/1/22/forwards-compatible-python/>):

    import sys

    class UnicodeMixin(object):

      """Mixin class to handle defining the proper __str__/__unicode__
      methods in Python 2 or 3."""

      if sys.version_info[0] >= 3: # Python 3
          def __str__(self):
              return self.__unicode__()
      else:  # Python 2
          def __str__(self):
              return self.__unicode__().encode('utf8')


    class Spam(UnicodeMixin):

      def __unicode__(self):
          return u'spam-spam-bacon-spam'  # 2to3 will remove the 'u' prefix



File: python-howto-3.2.2.info,  Node: Don't Index on Exceptions,  Next: Don't use __getslice__ & Friends,  Prev: __str__ /__unicode__,  Up: Handle Common "Gotchas"

2.3.4.11 Don't Index on Exceptions
..................................

In Python 2, the following worked:

    >>> exc = Exception(1, 2, 3)
    >>> exc.args[1]
    2
    >>> exc[1]  # Python 2 only!
    2

But in Python 3, indexing directly on an exception is an error. You
need to make sure to only index on the `BaseException.args' attribute
which is a sequence containing all arguments passed to the `__init__()'
method.

  Even better is to use the documented attributes the exception
provides.


File: python-howto-3.2.2.info,  Node: Don't use __getslice__ & Friends,  Next: Updating doctests,  Prev: Don't Index on Exceptions,  Up: Handle Common "Gotchas"

2.3.4.12 Don't use `__getslice__' & Friends
...........................................

Been deprecated for a while, but Python 3 finally drops support for
`__getslice__()', etc. Move completely over to `__getitem__()' and
friends.


File: python-howto-3.2.2.info,  Node: Updating doctests,  Prev: Don't use __getslice__ & Friends,  Up: Handle Common "Gotchas"

2.3.4.13 Updating doctests
..........................

2to3(1) will attempt to generate fixes for doctests that it comes
across. It's not perfect, though. If you wrote a monolithic set of
doctests (e.g., a single docstring containing all of your doctests),
you should at least consider breaking the doctests up into smaller
pieces to make it more manageable to fix.  Otherwise it might very well
be worth your time and effort to port your tests to `unittest'.

  ---------- Footnotes ----------

  (1) http://docs.python.org/py3k/library/2to3.html


File: python-howto-3.2.2.info,  Node: Eliminate -3 Warnings,  Next: Run 2to3,  Prev: Handle Common "Gotchas",  Up: Python 2 and 2to3

2.3.5 Eliminate `-3' Warnings
-----------------------------

When you run your application's test suite, run it using the `-3' flag
passed to Python. This will cause various warnings to be raised during
execution about things that 2to3 cannot handle automatically (e.g.,
modules that have been removed). Try to eliminate those warnings to
make your code even more portable to Python 3.


File: python-howto-3.2.2.info,  Node: Run 2to3,  Next: Verify & Test,  Prev: Eliminate -3 Warnings,  Up: Python 2 and 2to3

2.3.6 Run 2to3
--------------

Once you have made your Python 2 code future-compatible with Python 3,
it's time to use 2to3(1) to actually port your code.

* Menu:

* Manually::
* During Installation::

  ---------- Footnotes ----------

  (1) http://docs.python.org/py3k/library/2to3.html


File: python-howto-3.2.2.info,  Node: Manually,  Next: During Installation,  Up: Run 2to3

2.3.6.1 Manually
................

To manually convert source code using 2to3(1), you use the `2to3'
script that is installed with Python 2.6 and later.:

    2to3 <directory or file to convert>

This will cause 2to3 to write out a diff with all of the fixers applied
for the converted source code. If you would like 2to3 to go ahead and
apply the changes you can pass it the `-w' flag:

    2to3 -w <stuff to convert>

There are other flags available to control exactly which fixers are
applied, etc.

  ---------- Footnotes ----------

  (1) http://docs.python.org/py3k/library/2to3.html


File: python-howto-3.2.2.info,  Node: During Installation,  Prev: Manually,  Up: Run 2to3

2.3.6.2 During Installation
...........................

When a user installs your project for Python 3, you can have either
`distutils' or Distribute(1) run 2to3(2) on your behalf.  For
distutils, use the following idiom:

    try:  # Python 3
      from distutils.command.build_py import build_py_2to3 as build_py
    except ImportError:  # Python 2
      from distutils.command.build_py import build_py

    setup(cmdclass = {'build_py': build_py},
      # ...
    )

For Distribute:

    setup(use_2to3=True,
      # ...
    )

This will allow you to not have to distribute a separate Python 3
version of your project. It does require, though, that when you perform
development that you at least build your project and use the built
Python 3 source for testing.

  ---------- Footnotes ----------

  (1) http://packages.python.org/distribute/

  (2) http://docs.python.org/py3k/library/2to3.html


File: python-howto-3.2.2.info,  Node: Verify & Test,  Prev: Run 2to3,  Up: Python 2 and 2to3

2.3.7 Verify & Test
-------------------

At this point you should (hopefully) have your project converted in
such a way that it works in Python 3. Verify it by running your unit
tests and making sure nothing has gone awry. If you miss something then
figure out how to fix it in Python 3, backport to your Python 2 code,
and run your code through 2to3 again to verify the fix transforms
properly.


File: python-howto-3.2.2.info,  Node: Python 2/3 Compatible Source,  Next: Other Resources,  Prev: Python 2 and 2to3,  Up: Porting Python 2 Code to Python 3

2.4 Python 2/3 Compatible Source
================================

While it may seem counter-intuitive, you can write Python code which is
source-compatible between Python 2 & 3. It does lead to code that is not
entirely idiomatic Python (e.g., having to extract the currently raised
exception from `sys.exc_info()[1]'), but it can be run under Python 2
*and* Python 3 without using 2to3(1) as a translation step (although
the tool should be used to help find potential portability problems).
This allows you to continue to have a rapid development process
regardless of whether you are developing under Python 2 or Python 3.
Whether this approach or using *note Python 2 and 2to3: 12. works best
for you will be a per-project decision.

  To get a complete idea of what issues you will need to deal with, see
the What's New in Python 3.0(2). Others have reorganized the data in
other formats such as
<http://docs.pythonsprints.com/python3_porting/py-porting.html> .

  The following are some steps to take to try to support both Python 2
& 3 from the same source code.

* Menu:

* Follow The Steps for Using 2to3::
* Use six::
* Capturing the Currently Raised Exception::

  ---------- Footnotes ----------

  (1) http://docs.python.org/py3k/library/2to3.html

  (2) http://docs.python.org/release/3.0/whatsnew/3.0.html


File: python-howto-3.2.2.info,  Node: Follow The Steps for Using 2to3,  Next: Use six,  Up: Python 2/3 Compatible Source

2.4.1 Follow The Steps for Using 2to3
-------------------------------------

All of the steps outlined in how to *note port Python 2 code with 2to3:
12. apply to creating a Python 2/3 codebase. This includes trying only
support Python 2.6 or newer (the `__future__' statements work in Python
3 without issue), eliminating warnings that are triggered by `-3', etc.

  You should even consider running 2to3(1) over your code (without
committing the changes). This will let you know where potential pain
points are within your code so that you can fix them properly before
they become an issue.

  ---------- Footnotes ----------

  (1) http://docs.python.org/py3k/library/2to3.html


File: python-howto-3.2.2.info,  Node: Use six,  Next: Capturing the Currently Raised Exception,  Prev: Follow The Steps for Using 2to3,  Up: Python 2/3 Compatible Source

2.4.2 Use six
-------------

The six(1) project contains many things to help you write portable
Python code.  You should make sure to read its documentation from
beginning to end and use any and all features it provides. That way you
will minimize any mistakes you might make in writing cross-version code.

  ---------- Footnotes ----------

  (1) http://packages.python.org/six


File: python-howto-3.2.2.info,  Node: Capturing the Currently Raised Exception,  Prev: Use six,  Up: Python 2/3 Compatible Source

2.4.3 Capturing the Currently Raised Exception
----------------------------------------------

One change between Python 2 and 3 that will require changing how you
code (if you support Python 2.5(1) and earlier) is accessing the
currently raised exception.  In Python 2.5 and earlier the syntax to
access the current exception is:

    try:
      raise Exception()
    except Exception, exc:
      # Current exception is 'exc'
      pass

This syntax changed in Python 3 (and backported to Python 2.6(2) and
later) to:

    try:
      raise Exception()
    except Exception as exc:
      # Current exception is 'exc'
      # In Python 3, 'exc' is restricted to the block; Python 2.6 will "leak"
      pass

Because of this syntax change you must change to capturing the current
exception to:

    try:
      raise Exception()
    except Exception:
      import sys
      exc = sys.exc_info()[1]
      # Current exception is 'exc'
      pass

You can get more information about the raised exception from
`sys.exc_info()' than simply the current exception instance, but you
most likely don't need it.

     Note: In Python 3, the traceback is attached to the exception
     instance through the `__traceback__' attribute. If the instance is
     saved in a local variable that persists outside of the `except'
     block, the traceback will create a reference cycle with the
     current frame and its dictionary of local variables.  This will
     delay reclaiming dead resources until the next cyclic _garbage
     collection_ pass.

     In Python 2, this problem only occurs if you save the traceback
     itself (e.g. the third element of the tuple returned by
     `sys.exc_info()') in a variable.

  ---------- Footnotes ----------

  (1) http://www.python.org/2.5.x

  (2) http://www.python.org/2.6.x


File: python-howto-3.2.2.info,  Node: Other Resources,  Prev: Python 2/3 Compatible Source,  Up: Porting Python 2 Code to Python 3

2.5 Other Resources
===================

The authors of the following blog posts, wiki pages, and books deserve
special thanks for making public their tips for porting Python 2 code
to Python 3 (and thus helping provide information for this document):

   * <http://python3porting.com/>

   * <http://docs.pythonsprints.com/python3_porting/py-porting.html>

   *
     <http://techspot.zzzeek.org/2011/01/24/zzzeek-s-guide-to-python-3-porting/>

   *
     <http://dabeaz.blogspot.com/2011/01/porting-py65-and-my-superboard-to.html>

   * <http://lucumr.pocoo.org/2011/1/22/forwards-compatible-python/>

   * <http://lucumr.pocoo.org/2010/2/11/porting-to-python-3-a-guide/>

   * <http://wiki.python.org/moin/PortingPythonToPy3k>

  If you feel there is something missing from this document that should
be added, please email the python-porting(1) mailing list.

  ---------- Footnotes ----------

  (1) http://mail.python.org/mailman/listinfo/python-porting


File: python-howto-3.2.2.info,  Node: Porting Extension Modules to 3 0,  Next: Curses Programming with Python,  Prev: Porting Python 2 Code to Python 3,  Up: Top

3 Porting Extension Modules to 3.0
**********************************

     author: Benjamin Peterson

Abstract
--------

Although changing the C-API was not one of Python 3.0's objectives, the
many Python level changes made leaving 2.x's API intact impossible.  In
fact, some changes such as `int()' and `long()' unification are more
obvious on the C level.  This document endeavors to document
incompatibilities and how they can be worked around.

* Menu:

* Conditional compilation::
* Changes to Object APIs::
* Module initialization and state::
* Other options::


File: python-howto-3.2.2.info,  Node: Conditional compilation,  Next: Changes to Object APIs,  Up: Porting Extension Modules to 3 0

3.1 Conditional compilation
===========================

The easiest way to compile only some code for 3.0 is to check if
`PY_MAJOR_VERSION' is greater than or equal to 3.

    #if PY_MAJOR_VERSION >= 3
    #define IS_PY3K
    #endif

API functions that are not present can be aliased to their equivalents
within conditional blocks.


File: python-howto-3.2.2.info,  Node: Changes to Object APIs,  Next: Module initialization and state,  Prev: Conditional compilation,  Up: Porting Extension Modules to 3 0

3.2 Changes to Object APIs
==========================

Python 3.0 merged together some types with similar functions while
cleanly separating others.

* Menu:

* str/unicode Unification::
* long/int Unification::


File: python-howto-3.2.2.info,  Node: str/unicode Unification,  Next: long/int Unification,  Up: Changes to Object APIs

3.2.1 str/unicode Unification
-----------------------------

Python 3.0's `str()' (`PyString_*' functions in C) type is equivalent to
2.x's `unicode()' (`PyUnicode_*').  The old 8-bit string type has become
`bytes()'.  Python 2.6 and later provide a compatibility header,
`bytesobject.h', mapping `PyBytes' names to `PyString' ones.  For best
compatibility with 3.0, `PyUnicode' should be used for textual data and
`PyBytes' for binary data.  It's also important to remember that
`PyBytes' and `PyUnicode' in 3.0 are not interchangeable like
`PyString' and `PyUnicode' are in 2.x.  The following example shows
best practices with regards to `PyUnicode', `PyString', and `PyBytes'.

    #include "stdlib.h"
    #include "Python.h"
    #include "bytesobject.h"

    /* text example */
    static PyObject *
    say_hello(PyObject *self, PyObject *args) {
        PyObject *name, *result;

        if (!PyArg_ParseTuple(args, "U:say_hello", &name))
            return NULL;

        result = PyUnicode_FromFormat("Hello, %S!", name);
        return result;
    }

    /* just a forward */
    static char * do_encode(PyObject *);

    /* bytes example */
    static PyObject *
    encode_object(PyObject *self, PyObject *args) {
        char *encoded;
        PyObject *result, *myobj;

        if (!PyArg_ParseTuple(args, "O:encode_object", &myobj))
            return NULL;

        encoded = do_encode(myobj);
        if (encoded == NULL)
            return NULL;
        result = PyBytes_FromString(encoded);
        free(encoded);
        return result;
    }



File: python-howto-3.2.2.info,  Node: long/int Unification,  Prev: str/unicode Unification,  Up: Changes to Object APIs

3.2.2 long/int Unification
--------------------------

In Python 3.0, there is only one integer type.  It is called `int()' on
the Python level, but actually corresponds to 2.x's `long()' type.  In
the C-API, `PyInt_*' functions are replaced by their `PyLong_*'
neighbors.  The best course of action here is using the `PyInt_*'
functions aliased to `PyLong_*' found in `intobject.h'.  The abstract
`PyNumber_*' APIs can also be used in some cases.

    #include "Python.h"
    #include "intobject.h"

    static PyObject *
    add_ints(PyObject *self, PyObject *args) {
        int one, two;
        PyObject *result;

        if (!PyArg_ParseTuple(args, "ii:add_ints", &one, &two))
            return NULL;

        return PyInt_FromLong(one + two);
    }



File: python-howto-3.2.2.info,  Node: Module initialization and state,  Next: Other options,  Prev: Changes to Object APIs,  Up: Porting Extension Modules to 3 0

3.3 Module initialization and state
===================================

Python 3.0 has a revamped extension module initialization system.  (See PEP
3121(1).)  Instead of storing module state in globals, they should be
stored in an interpreter specific structure.  Creating modules that act
correctly in both 2.x and 3.0 is tricky.  The following simple example
demonstrates how.

    #include "Python.h"

    struct module_state {
        PyObject *error;
    };

    #if PY_MAJOR_VERSION >= 3
    #define GETSTATE(m) ((struct module_state*)PyModule_GetState(m))
    #else
    #define GETSTATE(m) (&_state)
    static struct module_state _state;
    #endif

    static PyObject *
    error_out(PyObject *m) {
        struct module_state *st = GETSTATE(m);
        PyErr_SetString(st->error, "something bad happened");
        return NULL;
    }

    static PyMethodDef myextension_methods[] = {
        {"error_out", (PyCFunction)error_out, METH_NOARGS, NULL},
        {NULL, NULL}
    };

    #if PY_MAJOR_VERSION >= 3

    static int myextension_traverse(PyObject *m, visitproc visit, void *arg) {
        Py_VISIT(GETSTATE(m)->error);
        return 0;
    }

    static int myextension_clear(PyObject *m) {
        Py_CLEAR(GETSTATE(m)->error);
        return 0;
    }


    static struct PyModuleDef moduledef = {
            PyModuleDef_HEAD_INIT,
            "myextension",
            NULL,
            sizeof(struct module_state),
            myextension_methods,
            NULL,
            myextension_traverse,
            myextension_clear,
            NULL
    };

    #define INITERROR return NULL

    PyObject *
    PyInit_myextension(void)

    #else
    #define INITERROR return

    void
    initmyextension(void)
    #endif
    {
    #if PY_MAJOR_VERSION >= 3
        PyObject *module = PyModule_Create(&moduledef);
    #else
        PyObject *module = Py_InitModule("myextension", myextension_methods);
    #endif

        if (module == NULL)
            INITERROR;
        struct module_state *st = GETSTATE(module);

        st->error = PyErr_NewException("myextension.Error", NULL, NULL);
        if (st->error == NULL) {
            Py_DECREF(module);
            INITERROR;
        }

    #if PY_MAJOR_VERSION >= 3
        return module;
    #endif
    }


  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-3121


File: python-howto-3.2.2.info,  Node: Other options,  Prev: Module initialization and state,  Up: Porting Extension Modules to 3 0

3.4 Other options
=================

If you are writing a new extension module, you might consider
Cython(1).  It translates a Python-like language to C.  The extension
modules it creates are compatible with Python 3.x and 2.x.

  ---------- Footnotes ----------

  (1) http://www.cython.org


File: python-howto-3.2.2.info,  Node: Curses Programming with Python,  Next: Descriptor HowTo Guide,  Prev: Porting Extension Modules to 3 0,  Up: Top

4 Curses Programming with Python
********************************

     Author: A.M. Kuchling, Eric S. Raymond

     Release: 2.03

Abstract
--------

This document describes how to write text-mode programs with Python
2.x, using the `curses' extension module to control the display.

* Menu:

* What is curses?::
* Starting and ending a curses application::
* Windows and Pads::
* Displaying Text::
* User Input::
* For More Information::

What is curses?

* The Python curses module::

Displaying Text

* Attributes and Color::


File: python-howto-3.2.2.info,  Node: What is curses?,  Next: Starting and ending a curses application,  Up: Curses Programming with Python

4.1 What is curses?
===================

The curses library supplies a terminal-independent screen-painting and
keyboard-handling facility for text-based terminals; such terminals
include VT100s, the Linux console, and the simulated terminal provided
by X11 programs such as xterm and rxvt.  Display terminals support
various control codes to perform common operations such as moving the
cursor, scrolling the screen, and erasing areas.  Different terminals
use widely differing codes, and often have their own minor quirks.

  In a world of X displays, one might ask "why bother"?  It's true that
character-cell display terminals are an obsolete technology, but there
are niches in which being able to do fancy things with them are still
valuable.  One is on small-footprint or embedded Unixes that don't
carry an X server.  Another is for tools like OS installers and kernel
configurators that may have to run before X is available.

  The curses library hides all the details of different terminals, and
provides the programmer with an abstraction of a display, containing
multiple non-overlapping windows.  The contents of a window can be
changed in various ways- adding text, erasing it, changing its
appearance-and the curses library will automagically figure out what
control codes need to be sent to the terminal to produce the right
output.

  The curses library was originally written for BSD Unix; the later
System V versions of Unix from AT&T added many enhancements and new
functions. BSD curses is no longer maintained, having been replaced by
ncurses, which is an open-source implementation of the AT&T interface.
If you're using an open-source Unix such as Linux or FreeBSD, your
system almost certainly uses ncurses.  Since most current commercial
Unix versions are based on System V code, all the functions described
here will probably be available.  The older versions of curses carried
by some proprietary Unixes may not support everything, though.

  No one has made a Windows port of the curses module.  On a Windows
platform, try the Console module written by Fredrik Lundh.  The Console
module provides cursor-addressable text output, plus full support for
mouse and keyboard input, and is available from
<http://effbot.org/zone/console-index.htm>.

* Menu:

* The Python curses module::


File: python-howto-3.2.2.info,  Node: The Python curses module,  Up: What is curses?

4.1.1 The Python curses module
------------------------------

Thy Python module is a fairly simple wrapper over the C functions
provided by curses; if you're already familiar with curses programming
in C, it's really easy to transfer that knowledge to Python.  The
biggest difference is that the Python interface makes things simpler,
by merging different C functions such as `addstr()', `mvaddstr()',
`mvwaddstr()', into a single `addstr()' method.  You'll see this
covered in more detail later.

  This HOWTO is simply an introduction to writing text-mode programs
with curses and Python. It doesn't attempt to be a complete guide to
the curses API; for that, see the Python library guide's section on
ncurses, and the C manual pages for ncurses.  It will, however, give
you the basic ideas.


File: python-howto-3.2.2.info,  Node: Starting and ending a curses application,  Next: Windows and Pads,  Prev: What is curses?,  Up: Curses Programming with Python

4.2 Starting and ending a curses application
============================================

Before doing anything, curses must be initialized.  This is done by
calling the `initscr()' function, which will determine the terminal
type, send any required setup codes to the terminal, and create various
internal data structures.  If successful, `initscr()' returns a window
object representing the entire screen; this is usually called `stdscr',
after the name of the corresponding C variable.

    import curses
    stdscr = curses.initscr()

Usually curses applications turn off automatic echoing of keys to the
screen, in order to be able to read keys and only display them under
certain circumstances.  This requires calling the `noecho()' function.

    curses.noecho()

Applications will also commonly need to react to keys instantly, without
requiring the Enter key to be pressed; this is called cbreak mode, as
opposed to the usual buffered input mode.

    curses.cbreak()

Terminals usually return special keys, such as the cursor keys or
navigation keys such as Page Up and Home, as a multibyte escape
sequence.  While you could write your application to expect such
sequences and process them accordingly, curses can do it for you,
returning a special value such as `curses.KEY_LEFT'.  To get curses to
do the job, you'll have to enable keypad mode.

    stdscr.keypad(1)

Terminating a curses application is much easier than starting one.
You'll need to call

    curses.nocbreak(); stdscr.keypad(0); curses.echo()

to reverse the curses-friendly terminal settings. Then call the
`endwin()' function to restore the terminal to its original operating
mode.

    curses.endwin()

A common problem when debugging a curses application is to get your
terminal messed up when the application dies without restoring the
terminal to its previous state.  In Python this commonly happens when
your code is buggy and raises an uncaught exception.  Keys are no
longer be echoed to the screen when you type them, for example, which
makes using the shell difficult.

  In Python you can avoid these complications and make debugging much
easier by importing the module `curses.wrapper'.  It supplies a
`wrapper()' function that takes a callable.  It does the
initializations described above, and also initializes colors if color
support is present.  It then runs your provided callable and finally
deinitializes appropriately.  The callable is called inside a try-catch
clause which catches exceptions, performs curses deinitialization, and
then passes the exception upwards.  Thus, your terminal won't be left
in a funny state on exception.


File: python-howto-3.2.2.info,  Node: Windows and Pads,  Next: Displaying Text,  Prev: Starting and ending a curses application,  Up: Curses Programming with Python

4.3 Windows and Pads
====================

Windows are the basic abstraction in curses.  A window object
represents a rectangular area of the screen, and supports various
methods to display text, erase it, allow the user to input strings, and
so forth.

  The `stdscr' object returned by the `initscr()' function is a window
object that covers the entire screen.  Many programs may need only this
single window, but you might wish to divide the screen into smaller
windows, in order to redraw or clear them separately. The `newwin()'
function creates a new window of a given size, returning the new window
object.

    begin_x = 20 ; begin_y = 7
    height = 5 ; width = 40
    win = curses.newwin(height, width, begin_y, begin_x)

A word about the coordinate system used in curses: coordinates are
always passed in the order _y,x_, and the top-left corner of a window
is coordinate (0,0).  This breaks a common convention for handling
coordinates, where the _x_ coordinate usually comes first.  This is an
unfortunate difference from most other computer applications, but it's
been part of curses since it was first written, and it's too late to
change things now.

  When you call a method to display or erase text, the effect doesn't
immediately show up on the display.  This is because curses was
originally written with slow 300-baud terminal connections in mind;
with these terminals, minimizing the time required to redraw the screen
is very important.  This lets curses accumulate changes to the screen,
and display them in the most efficient manner.  For example, if your
program displays some characters in a window, and then clears the
window, there's no need to send the original characters because they'd
never be visible.

  Accordingly, curses requires that you explicitly tell it to redraw
windows, using the `refresh()' method of window objects.  In practice,
this doesn't really complicate programming with curses much. Most
programs go into a flurry of activity, and then pause waiting for a
keypress or some other action on the part of the user.  All you have to
do is to be sure that the screen has been redrawn before pausing to
wait for user input, by simply calling `stdscr.refresh()' or the
`refresh()' method of some other relevant window.

  A pad is a special case of a window; it can be larger than the actual
display screen, and only a portion of it displayed at a time. Creating
a pad simply requires the pad's height and width, while refreshing a
pad requires giving the coordinates of the on-screen area where a
subsection of the pad will be displayed.

    pad = curses.newpad(100, 100)
    #  These loops fill the pad with letters; this is
    # explained in the next section
    for y in range(0, 100):
        for x in range(0, 100):
            try: pad.addch(y,x, ord('a') + (x*x+y*y) % 26 )
            except curses.error: pass

    #  Displays a section of the pad in the middle of the screen
    pad.refresh( 0,0, 5,5, 20,75)

The `refresh()' call displays a section of the pad in the rectangle
extending from coordinate (5,5) to coordinate (20,75) on the screen;
the upper left corner of the displayed section is coordinate (0,0) on
the pad.  Beyond that difference, pads are exactly like ordinary
windows and support the same methods.

  If you have multiple windows and pads on screen there is a more
efficient way to go, which will prevent annoying screen flicker at
refresh time.  Use the `noutrefresh()' method of each window to update
the data structure representing the desired state of the screen; then
change the physical screen to match the desired state in one go with
the function `doupdate()'.  The normal `refresh()' method calls
`doupdate()' as its last act.


File: python-howto-3.2.2.info,  Node: Displaying Text,  Next: User Input,  Prev: Windows and Pads,  Up: Curses Programming with Python

4.4 Displaying Text
===================

From a C programmer's point of view, curses may sometimes look like a
twisty maze of functions, all subtly different.  For example,
`addstr()' displays a string at the current cursor location in the
`stdscr' window, while `mvaddstr()' moves to a given y,x coordinate
first before displaying the string. `waddstr()' is just like
`addstr()', but allows specifying a window to use, instead of using
`stdscr' by default. `mvwaddstr()' follows similarly.

  Fortunately the Python interface hides all these details; `stdscr' is
a window object like any other, and methods like `addstr()' accept
multiple argument forms.  Usually there are four different forms.

Form                                  Description
------------------------------------------------------------------------------------------ 
_str_ or _ch_                         Display the string _str_ or character _ch_ at the
                                      current position
_str_ or _ch_, _attr_                 Display the string _str_ or character _ch_, using
                                      attribute _attr_ at the current position
_y_, _x_, _str_ or _ch_               Move to position _y,x_ within the window, and
                                      display _str_ or _ch_
_y_, _x_, _str_ or _ch_, _attr_       Move to position _y,x_ within the window, and
                                      display _str_ or _ch_, using attribute _attr_

  Attributes allow displaying text in highlighted forms, such as in
boldface, underline, reverse code, or in color.  They'll be explained
in more detail in the next subsection.

  The `addstr()' function takes a Python string as the value to be
displayed, while the `addch()' functions take a character, which can be
either a Python string of length 1 or an integer.  If it's a string,
you're limited to displaying characters between 0 and 255.  SVr4 curses
provides constants for extension characters; these constants are
integers greater than 255.  For example, `ACS_PLMINUS' is a +/- symbol,
and `ACS_ULCORNER' is the upper left corner of a box (handy for drawing
borders).

  Windows remember where the cursor was left after the last operation,
so if you leave out the _y,x_ coordinates, the string or character will
be displayed wherever the last operation left off.  You can also move
the cursor with the `move(y,x)' method.  Because some terminals always
display a flashing cursor, you may want to ensure that the cursor is
positioned in some location where it won't be distracting; it can be
confusing to have the cursor blinking at some apparently random
location.

  If your application doesn't need a blinking cursor at all, you can
call `curs_set(0)' to make it invisible.  Equivalently, and for
compatibility with older curses versions, there's a `leaveok(bool)'
function.  When _bool_ is true, the curses library will attempt to
suppress the flashing cursor, and you won't need to worry about leaving
it in odd locations.

* Menu:

* Attributes and Color::


File: python-howto-3.2.2.info,  Node: Attributes and Color,  Up: Displaying Text

4.4.1 Attributes and Color
--------------------------

Characters can be displayed in different ways.  Status lines in a
text-based application are commonly shown in reverse video; a text
viewer may need to highlight certain words.  curses supports this by
allowing you to specify an attribute for each cell on the screen.

  An attribute is a integer, each bit representing a different
attribute.  You can try to display text with multiple attribute bits
set, but curses doesn't guarantee that all the possible combinations
are available, or that they're all visually distinct.  That depends on
the ability of the terminal being used, so it's safest to stick to the
most commonly available attributes, listed here.

Attribute                  Description
---------------------------------------------------------------------- 
`A_BLINK'                  Blinking text
`A_BOLD'                   Extra bright or bold text
`A_DIM'                    Half bright text
`A_REVERSE'                Reverse-video text
`A_STANDOUT'               The best highlighting mode available
`A_UNDERLINE'              Underlined text

  So, to display a reverse-video status line on the top line of the
screen, you could code:

    stdscr.addstr(0, 0, "Current mode: Typing mode",
                  curses.A_REVERSE)
    stdscr.refresh()

The curses library also supports color on those terminals that provide
it, The most common such terminal is probably the Linux console,
followed by color xterms.

  To use color, you must call the `start_color()' function soon after
calling `initscr()', to initialize the default color set (the
`curses.wrapper.wrapper()' function does this automatically).  Once
that's done, the `has_colors()' function returns TRUE if the terminal
in use can actually display color.  (Note: curses uses the American
spelling 'color', instead of the Canadian/British spelling 'colour'.
If you're used to the British spelling, you'll have to resign yourself
to misspelling it for the sake of these functions.)

  The curses library maintains a finite number of color pairs,
containing a foreground (or text) color and a background color.  You
can get the attribute value corresponding to a color pair with the
`color_pair()' function; this can be bitwise-OR'ed with other
attributes such as `A_REVERSE', but again, such combinations are not
guaranteed to work on all terminals.

  An example, which displays a line of text using color pair 1:

    stdscr.addstr( "Pretty text", curses.color_pair(1) )
    stdscr.refresh()

As I said before, a color pair consists of a foreground and background
color.  `start_color()' initializes 8 basic colors when it activates
color mode.  They are: 0:black, 1:red, 2:green, 3:yellow, 4:blue,
5:magenta, 6:cyan, and 7:white.  The curses module defines named
constants for each of these colors: `curses.COLOR_BLACK',
`curses.COLOR_RED', and so forth.

  The `init_pair(n, f, b)' function changes the definition of color
pair _n_, to foreground color f and background color b.  Color pair 0
is hard-wired to white on black, and cannot be changed.

  Let's put all this together. To change color 1 to red text on a white
background, you would call:

    curses.init_pair(1, curses.COLOR_RED, curses.COLOR_WHITE)

When you change a color pair, any text already displayed using that
color pair will change to the new colors.  You can also display new
text in this color with:

    stdscr.addstr(0,0, "RED ALERT!", curses.color_pair(1) )

Very fancy terminals can change the definitions of the actual colors to
a given RGB value.  This lets you change color 1, which is usually red,
to purple or blue or any other color you like.  Unfortunately, the
Linux console doesn't support this, so I'm unable to try it out, and
can't provide any examples.  You can check if your terminal can do this
by calling `can_change_color()', which returns TRUE if the capability
is there.  If you're lucky enough to have such a talented terminal,
consult your system's man pages for more information.


File: python-howto-3.2.2.info,  Node: User Input,  Next: For More Information,  Prev: Displaying Text,  Up: Curses Programming with Python

4.5 User Input
==============

The curses library itself offers only very simple input mechanisms.
Python's support adds a text-input widget that makes up some of the
lack.

  The most common way to get input to a window is to use its `getch()'
method.  `getch()' pauses and waits for the user to hit a key,
displaying it if `echo()' has been called earlier.  You can optionally
specify a coordinate to which the cursor should be moved before pausing.

  It's possible to change this behavior with the method `nodelay()'.
After `nodelay(1)', `getch()' for the window becomes non-blocking and
returns `curses.ERR' (a value of -1) when no input is ready.  There's
also a `halfdelay()' function, which can be used to (in effect) set a
timer on each `getch()'; if no input becomes available within a
specified delay (measured in tenths of a second), curses raises an
exception.

  The `getch()' method returns an integer; if it's between 0 and 255, it
represents the ASCII code of the key pressed.  Values greater than 255
are special keys such as Page Up, Home, or the cursor keys. You can
compare the value returned to constants such as `curses.KEY_PPAGE',
`curses.KEY_HOME', or `curses.KEY_LEFT'.  Usually the main loop of your
program will look something like this:

    while True:
        c = stdscr.getch()
        if c == ord('p'): PrintDocument()
        elif c == ord('q'): break  # Exit the while()
        elif c == curses.KEY_HOME: x = y = 0

The `curses.ascii' module supplies ASCII class membership functions that
take either integer or 1-character-string arguments; these may be
useful in writing more readable tests for your command interpreters.
It also supplies conversion functions  that take either integer or
1-character-string arguments and return the same type.  For example,
`curses.ascii.ctrl()' returns the control character corresponding to
its argument.

  There's also a method to retrieve an entire string, `getstr()'.  It
isn't used very often, because its functionality is quite limited; the
only editing keys available are the backspace key and the Enter key,
which terminates the string.  It can optionally be limited to a fixed
number of characters.

    curses.echo()            # Enable echoing of characters

    # Get a 15-character string, with the cursor on the top line
    s = stdscr.getstr(0,0, 15)

The Python `curses.textpad' module supplies something better. With it,
you can turn a window into a text box that supports an Emacs-like set of
keybindings.  Various methods of `Textbox' class support editing with
input validation and gathering the edit results either with or without
trailing spaces.   See the library documentation on `curses.textpad'
for the details.


File: python-howto-3.2.2.info,  Node: For More Information,  Prev: User Input,  Up: Curses Programming with Python

4.6 For More Information
========================

This HOWTO didn't cover some advanced topics, such as screen-scraping or
capturing mouse events from an xterm instance.  But the Python library
page for the curses modules is now pretty complete.  You should browse
it next.

  If you're in doubt about the detailed behavior of any of the ncurses
entry points, consult the manual pages for your curses implementation,
whether it's ncurses or a proprietary Unix vendor's.  The manual pages
will document any quirks, and provide complete lists of all the
functions, attributes, and `ACS_*' characters available to you.

  Because the curses API is so large, some functions aren't supported
in the Python interface, not because they're difficult to implement,
but because no one has needed them yet.  Feel free to add them and then
submit a patch.  Also, we don't yet have support for the menu library
associated with ncurses; feel free to add that.

  If you write an interesting little program, feel free to contribute
it as another demo.  We can always use more of them!

  The ncurses FAQ:
<http://invisible-island.net/ncurses/ncurses.faq.html>


File: python-howto-3.2.2.info,  Node: Descriptor HowTo Guide,  Next: Functional Programming HOWTO,  Prev: Curses Programming with Python,  Up: Top

5 Descriptor HowTo Guide
************************

     Author: Raymond Hettinger

     Contact: <python at rcn dot com>

* Menu:

* Abstract::
* Definition and Introduction::
* Descriptor Protocol::
* Invoking Descriptors::
* Descriptor Example::
* Properties::
* Functions and Methods::
* Static Methods and Class Methods::


File: python-howto-3.2.2.info,  Node: Abstract,  Next: Definition and Introduction,  Up: Descriptor HowTo Guide

5.1 Abstract
============

Defines descriptors, summarizes the protocol, and shows how descriptors
are called.  Examines a custom descriptor and several built-in python
descriptors including functions, properties, static methods, and class
methods.  Shows how each works by giving a pure Python equivalent and a
sample application.

  Learning about descriptors not only provides access to a larger
toolset, it creates a deeper understanding of how Python works and an
appreciation for the elegance of its design.


File: python-howto-3.2.2.info,  Node: Definition and Introduction,  Next: Descriptor Protocol,  Prev: Abstract,  Up: Descriptor HowTo Guide

5.2 Definition and Introduction
===============================

In general, a descriptor is an object attribute with "binding
behavior", one whose attribute access has been overridden by methods in
the descriptor protocol.  Those methods are `__get__()', `__set__()',
and `__delete__()'.  If any of those methods are defined for an object,
it is said to be a descriptor.

  The default behavior for attribute access is to get, set, or delete
the attribute from an object's dictionary.  For instance, `a.x' has a
lookup chain starting with `a.__dict__['x']', then
`type(a).__dict__['x']', and continuing through the base classes of
`type(a)' excluding metaclasses. If the looked-up value is an object
defining one of the descriptor methods, then Python may override the
default behavior and invoke the descriptor method instead.  Where this
occurs in the precedence chain depends on which descriptor methods were
defined.  Note that descriptors are only invoked for new style objects
or classes (a class is new style if it inherits from `object' or
`type').

  Descriptors are a powerful, general purpose protocol.  They are the
mechanism behind properties, methods, static methods, class methods,
and `super()'.  They are used throughout Python itself to implement the
new style classes introduced in version 2.2.  Descriptors simplify the
underlying C-code and offer a flexible set of new tools for everyday
Python programs.


File: python-howto-3.2.2.info,  Node: Descriptor Protocol,  Next: Invoking Descriptors,  Prev: Definition and Introduction,  Up: Descriptor HowTo Guide

5.3 Descriptor Protocol
=======================

`descr.__get__(self, obj, type=None) --> value'

  `descr.__set__(self, obj, value) --> None'

  `descr.__delete__(self, obj) --> None'

  That is all there is to it.  Define any of these methods and an
object is considered a descriptor and can override default behavior
upon being looked up as an attribute.

  If an object defines both `__get__()' and `__set__()', it is
considered a data descriptor.  Descriptors that only define `__get__()'
are called non-data descriptors (they are typically used for methods
but other uses are possible).

  Data and non-data descriptors differ in how overrides are calculated
with respect to entries in an instance's dictionary.  If an instance's
dictionary has an entry with the same name as a data descriptor, the
data descriptor takes precedence.  If an instance's dictionary has an
entry with the same name as a non-data descriptor, the dictionary entry
takes precedence.

  To make a read-only data descriptor, define both `__get__()' and
`__set__()' with the `__set__()' raising an `AttributeError' when
called.  Defining the `__set__()' method with an exception raising
placeholder is enough to make it a data descriptor.


File: python-howto-3.2.2.info,  Node: Invoking Descriptors,  Next: Descriptor Example,  Prev: Descriptor Protocol,  Up: Descriptor HowTo Guide

5.4 Invoking Descriptors
========================

A descriptor can be called directly by its method name.  For example,
`d.__get__(obj)'.

  Alternatively, it is more common for a descriptor to be invoked
automatically upon attribute access.  For example, `obj.d' looks up `d'
in the dictionary of `obj'.  If `d' defines the method `__get__()',
then `d.__get__(obj)' is invoked according to the precedence rules
listed below.

  The details of invocation depend on whether `obj' is an object or a
class.  Either way, descriptors only work for new style objects and
classes.  A class is new style if it is a subclass of `object'.

  For objects, the machinery is in `object.__getattribute__()' which
transforms `b.x' into `type(b).__dict__['x'].__get__(b, type(b))'.  The
implementation works through a precedence chain that gives data
descriptors priority over instance variables, instance variables
priority over non-data descriptors, and assigns lowest priority to
`__getattr__()' if provided.  The full C implementation can be found in
`PyObject_GenericGetAttr()' in Objects/object.c(1).

  For classes, the machinery is in `type.__getattribute__()' which
transforms `B.x' into `B.__dict__['x'].__get__(None, B)'.  In pure
Python, it looks like:

    def __getattribute__(self, key):
        "Emulate type_getattro() in Objects/typeobject.c"
        v = object.__getattribute__(self, key)
        if hasattr(v, '__get__'):
           return v.__get__(None, self)
        return v

The important points to remember are:

   * descriptors are invoked by the `__getattribute__()' method

   * overriding `__getattribute__()' prevents automatic descriptor calls

   * `__getattribute__()' is only available with new style classes and
     objects

   * `object.__getattribute__()' and `type.__getattribute__()' make
     different calls to `__get__()'.

   * data descriptors always override instance dictionaries.

   * non-data descriptors may be overridden by instance dictionaries.

  The object returned by `super()' also has a custom
`__getattribute__()' method for invoking descriptors.  The call
`super(B, obj).m()' searches `obj.__class__.__mro__' for the base class
`A' immediately following `B' and then returns
`A.__dict__['m'].__get__(obj, A)'.  If not a descriptor, `m' is
returned unchanged.  If not in the dictionary, `m' reverts to a search
using `object.__getattribute__()'.

  Note, in Python 2.2, `super(B, obj).m()' would only invoke
`__get__()' if `m' was a data descriptor.  In Python 2.3, non-data
descriptors also get invoked unless an old-style class is involved.
The implementation details are in `super_getattro()' in
Objects/typeobject.c(2) and a pure Python equivalent can be found in
Guido's Tutorial(3).

  The details above show that the mechanism for descriptors is embedded
in the `__getattribute__()' methods for `object', `type', and
`super()'.  Classes inherit this machinery when they derive from
`object' or if they have a meta-class providing similar functionality.
Likewise, classes can turn-off descriptor invocation by overriding
`__getattribute__()'.

  ---------- Footnotes ----------

  (1)
http://svn.python.org/view/python/trunk/Objects/object.c?view=markup

  (2)
http://svn.python.org/view/python/trunk/Objects/typeobject.c?view=markup

  (3) http://www.python.org/2.2.3/descrintro.html#cooperation


File: python-howto-3.2.2.info,  Node: Descriptor Example,  Next: Properties,  Prev: Invoking Descriptors,  Up: Descriptor HowTo Guide

5.5 Descriptor Example
======================

The following code creates a class whose objects are data descriptors
which print a message for each get or set.  Overriding
`__getattribute__()' is alternate approach that could do this for every
attribute.  However, this descriptor is useful for monitoring just a
few chosen attributes:

    class RevealAccess(object):
        """A data descriptor that sets and returns values
           normally and prints a message logging their access.
        """

        def __init__(self, initval=None, name='var'):
            self.val = initval
            self.name = name

        def __get__(self, obj, objtype):
            print('Retrieving', self.name)
            return self.val

        def __set__(self, obj, val):
            print('Updating', self.name)
            self.val = val

    >>> class MyClass(object):
        x = RevealAccess(10, 'var "x"')
        y = 5

    >>> m = MyClass()
    >>> m.x
    Retrieving var "x"
    10
    >>> m.x = 20
    Updating var "x"
    >>> m.x
    Retrieving var "x"
    20
    >>> m.y
    5

The protocol is simple and offers exciting possibilities.  Several use
cases are so common that they have been packaged into individual
function calls.  Properties, bound and unbound methods, static methods,
and class methods are all based on the descriptor protocol.


File: python-howto-3.2.2.info,  Node: Properties,  Next: Functions and Methods,  Prev: Descriptor Example,  Up: Descriptor HowTo Guide

5.6 Properties
==============

Calling `property()' is a succinct way of building a data descriptor
that triggers function calls upon access to an attribute.  Its
signature is:

    property(fget=None, fset=None, fdel=None, doc=None) -> property attribute

The documentation shows a typical use to define a managed attribute `x':

    class C(object):
        def getx(self): return self.__x
        def setx(self, value): self.__x = value
        def delx(self): del self.__x
        x = property(getx, setx, delx, "I'm the 'x' property.")

To see how `property()' is implemented in terms of the descriptor
protocol, here is a pure Python equivalent:

    class Property(object):
        "Emulate PyProperty_Type() in Objects/descrobject.c"

        def __init__(self, fget=None, fset=None, fdel=None, doc=None):
            self.fget = fget
            self.fset = fset
            self.fdel = fdel
            self.__doc__ = doc

        def __get__(self, obj, objtype=None):
            if obj is None:
                return self
            if self.fget is None:
                raise AttributeError, "unreadable attribute"
            return self.fget(obj)

        def __set__(self, obj, value):
            if self.fset is None:
                raise AttributeError, "can't set attribute"
            self.fset(obj, value)

        def __delete__(self, obj):
            if self.fdel is None:
                raise AttributeError, "can't delete attribute"
            self.fdel(obj)

The `property()' builtin helps whenever a user interface has granted
attribute access and then subsequent changes require the intervention
of a method.

  For instance, a spreadsheet class may grant access to a cell value
through `Cell('b10').value'. Subsequent improvements to the program
require the cell to be recalculated on every access; however, the
programmer does not want to affect existing client code accessing the
attribute directly.  The solution is to wrap access to the value
attribute in a property data descriptor:

    class Cell(object):
        . . .
        def getvalue(self, obj):
            "Recalculate cell before returning value"
            self.recalc()
            return obj._value
        value = property(getvalue)



File: python-howto-3.2.2.info,  Node: Functions and Methods,  Next: Static Methods and Class Methods,  Prev: Properties,  Up: Descriptor HowTo Guide

5.7 Functions and Methods
=========================

Python's object oriented features are built upon a function based
environment.  Using non-data descriptors, the two are merged seamlessly.

  Class dictionaries store methods as functions.  In a class
definition, methods are written using `def' and `lambda', the usual
tools for creating functions.  The only difference from regular
functions is that the first argument is reserved for the object
instance.  By Python convention, the instance reference is called
_self_ but may be called _this_ or any other variable name.

  To support method calls, functions include the `__get__()' method for
binding methods during attribute access.  This means that all functions
are non-data descriptors which return bound or unbound methods
depending whether they are invoked from an object or a class.  In pure
python, it works like this:

    class Function(object):
        . . .
        def __get__(self, obj, objtype=None):
            "Simulate func_descr_get() in Objects/funcobject.c"
            return types.MethodType(self, obj, objtype)

Running the interpreter shows how the function descriptor works in
practice:

    >>> class D(object):
         def f(self, x):
              return x

    >>> d = D()
    >>> D.__dict__['f'] # Stored internally as a function
    <function f at 0x00C45070>
    >>> D.f             # Get from a class becomes an unbound method
    <unbound method D.f>
    >>> d.f             # Get from an instance becomes a bound method
    <bound method D.f of <__main__.D object at 0x00B18C90>>

The output suggests that bound and unbound methods are two different
types.  While they could have been implemented that way, the actual C
implementation of `PyMethod_Type' in Objects/classobject.c(1) is a
single object with two different representations depending on whether
the `im_self' field is set or is _NULL_ (the C equivalent of _None_).

  Likewise, the effects of calling a method object depend on the
`im_self' field. If set (meaning bound), the original function (stored
in the `im_func' field) is called as expected with the first argument
set to the instance.  If unbound, all of the arguments are passed
unchanged to the original function. The actual C implementation of
`instancemethod_call()' is only slightly more complex in that it
includes some type checking.

  ---------- Footnotes ----------

  (1)
http://svn.python.org/view/python/trunk/Objects/classobject.c?view=markup


File: python-howto-3.2.2.info,  Node: Static Methods and Class Methods,  Prev: Functions and Methods,  Up: Descriptor HowTo Guide

5.8 Static Methods and Class Methods
====================================

Non-data descriptors provide a simple mechanism for variations on the
usual patterns of binding functions into methods.

  To recap, functions have a `__get__()' method so that they can be
converted to a method when accessed as attributes.  The non-data
descriptor transforms a `obj.f(*args)' call into `f(obj, *args)'.
Calling `klass.f(*args)' becomes `f(*args)'.

  This chart summarizes the binding and its two most useful variants:

      Transformation        Called from an Object      Called from a Class
     ------------------------------------------------------------------------ 
     function              f(obj, *args)              f(*args)
     staticmethod          f(*args)                   f(*args)
     classmethod           f(type(obj), *args)        f(klass, *args)


  Static methods return the underlying function without changes.
Calling either `c.f' or `C.f' is the equivalent of a direct lookup into
`object.__getattribute__(c, "f")' or `object.__getattribute__(C, "f")'.
As a result, the function becomes identically accessible from either an
object or a class.

  Good candidates for static methods are methods that do not reference
the `self' variable.

  For instance, a statistics package may include a container class for
experimental data.  The class provides normal methods for computing the
average, mean, median, and other descriptive statistics that depend on
the data. However, there may be useful functions which are conceptually
related but do not depend on the data.  For instance, `erf(x)' is handy
conversion routine that comes up in statistical work but does not
directly depend on a particular dataset.  It can be called either from
an object or the class:  `s.erf(1.5) --> .9332' or `Sample.erf(1.5) -->
.9332'.

  Since staticmethods return the underlying function with no changes,
the example calls are unexciting:

    >>> class E(object):
         def f(x):
              print(x)
         f = staticmethod(f)

    >>> print(E.f(3))
    3
    >>> print(E().f(3))
    3

Using the non-data descriptor protocol, a pure Python version of
`staticmethod()' would look like this:

    class StaticMethod(object):
     "Emulate PyStaticMethod_Type() in Objects/funcobject.c"

     def __init__(self, f):
          self.f = f

     def __get__(self, obj, objtype=None):
          return self.f

Unlike static methods, class methods prepend the class reference to the
argument list before calling the function.  This format is the same for
whether the caller is an object or a class:

    >>> class E(object):
         def f(klass, x):
              return klass.__name__, x
         f = classmethod(f)

    >>> print(E.f(3))
    ('E', 3)
    >>> print(E().f(3))
    ('E', 3)

This behavior is useful whenever the function only needs to have a class
reference and does not care about any underlying data.  One use for
classmethods is to create alternate class constructors.  In Python 2.3,
the classmethod `dict.fromkeys()' creates a new dictionary from a list
of keys.  The pure Python equivalent is:

    class Dict:
        . . .
        def fromkeys(klass, iterable, value=None):
            "Emulate dict_fromkeys() in Objects/dictobject.c"
            d = klass()
            for key in iterable:
                d[key] = value
            return d
        fromkeys = classmethod(fromkeys)

Now a new dictionary of unique keys can be constructed like this:

    >>> Dict.fromkeys('abracadabra')
    {'a': None, 'r': None, 'b': None, 'c': None, 'd': None}

Using the non-data descriptor protocol, a pure Python version of
`classmethod()' would look like this:

    class ClassMethod(object):
         "Emulate PyClassMethod_Type() in Objects/funcobject.c"

         def __init__(self, f):
              self.f = f

         def __get__(self, obj, klass=None):
              if klass is None:
                   klass = type(obj)
              def newfunc(*args):
                   return self.f(klass, *args)
              return newfunc



File: python-howto-3.2.2.info,  Node: Functional Programming HOWTO,  Next: Logging HOWTO,  Prev: Descriptor HowTo Guide,  Up: Top

6 Functional Programming HOWTO
******************************

     Author: A. M. Kuchling

     Release: 0.31

  In this document, we'll take a tour of Python's features suitable for
implementing programs in a functional style.  After an introduction to
the concepts of functional programming, we'll look at language features
such as _iterator_s and _generator_s and relevant library modules such
as `itertools' and `functools'.

* Menu:

* Introduction::
* Iterators::
* Generator expressions and list comprehensions::
* Generators::
* Built-in functions::
* The itertools module::
* The functools module::
* Small functions and the lambda expression::
* Revision History and Acknowledgements::
* References::

Introduction

* Formal provability::
* Modularity::
* Ease of debugging and testing::
* Composability::

Iterators

* Data Types That Support Iterators::

Generators

* Passing values into a generator::

The itertools module

* Creating new iterators::
* Calling functions on elements::
* Selecting elements::
* Grouping elements::

The functools module

* The operator module::
* The functional module::

References

* General::
* Python-specific::
* Python documentation::


File: python-howto-3.2.2.info,  Node: Introduction,  Next: Iterators,  Up: Functional Programming HOWTO

6.1 Introduction
================

This section explains the basic concept of functional programming; if
you're just interested in learning about Python language features, skip
to the next section.

  Programming languages support decomposing problems in several
different ways:

   * Most programming languages are *procedural*: programs are lists of
     instructions that tell the computer what to do with the program's
     input.  C, Pascal, and even Unix shells are procedural languages.

   * In *declarative* languages, you write a specification that
     describes the problem to be solved, and the language
     implementation figures out how to perform the computation
     efficiently.  SQL is the declarative language you're most likely
     to be familiar with; a SQL query describes the data set you want
     to retrieve, and the SQL engine decides whether to scan tables or
     use indexes, which subclauses should be performed first, etc.

   * *Object-oriented* programs manipulate collections of objects.
     Objects have internal state and support methods that query or
     modify this internal state in some way. Smalltalk and Java are
     object-oriented languages.  C++ and Python are languages that
     support object-oriented programming, but don't force the use of
     object-oriented features.

   * *Functional* programming decomposes a problem into a set of
     functions.  Ideally, functions only take inputs and produce
     outputs, and don't have any internal state that affects the output
     produced for a given input.  Well-known functional languages
     include the ML family (Standard ML, OCaml, and other variants) and
     Haskell.

  The designers of some computer languages choose to emphasize one
particular approach to programming.  This often makes it difficult to
write programs that use a different approach.  Other languages are
multi-paradigm languages that support several different approaches.
Lisp, C++, and Python are multi-paradigm; you can write programs or
libraries that are largely procedural, object-oriented, or functional
in all of these languages.  In a large program, different sections
might be written using different approaches; the GUI might be
object-oriented while the processing logic is procedural or functional,
for example.

  In a functional program, input flows through a set of functions. Each
function operates on its input and produces some output.  Functional
style discourages functions with side effects that modify internal
state or make other changes that aren't visible in the function's
return value.  Functions that have no side effects at all are called
*purely functional*.  Avoiding side effects means not using data
structures that get updated as a program runs; every function's output
must only depend on its input.

  Some languages are very strict about purity and don't even have
assignment statements such as `a=3' or `c = a + b', but it's difficult
to avoid all side effects.  Printing to the screen or writing to a disk
file are side effects, for example.  For example, in Python a call to
the `print()' or `time.sleep()' function both return no useful value;
they're only called for their side effects of sending some text to the
screen or pausing execution for a second.

  Python programs written in functional style usually won't go to the
extreme of avoiding all I/O or all assignments; instead, they'll
provide a functional-appearing interface but will use non-functional
features internally.  For example, the implementation of a function
will still use assignments to local variables, but won't modify global
variables or have other side effects.

  Functional programming can be considered the opposite of
object-oriented programming.  Objects are little capsules containing
some internal state along with a collection of method calls that let
you modify this state, and programs consist of making the right set of
state changes.  Functional programming wants to avoid state changes as
much as possible and works with data flowing between functions.  In
Python you might combine the two approaches by writing functions that
take and return instances representing objects in your application
(e-mail messages, transactions, etc.).

  Functional design may seem like an odd constraint to work under.  Why
should you avoid objects and side effects?  There are theoretical and
practical advantages to the functional style:

   * Formal provability.

   * Modularity.

   * Composability.

   * Ease of debugging and testing.

* Menu:

* Formal provability::
* Modularity::
* Ease of debugging and testing::
* Composability::


File: python-howto-3.2.2.info,  Node: Formal provability,  Next: Modularity,  Up: Introduction

6.1.1 Formal provability
------------------------

A theoretical benefit is that it's easier to construct a mathematical
proof that a functional program is correct.

  For a long time researchers have been interested in finding ways to
mathematically prove programs correct.  This is different from testing
a program on numerous inputs and concluding that its output is usually
correct, or reading a program's source code and concluding that the
code looks right; the goal is instead a rigorous proof that a program
produces the right result for all possible inputs.

  The technique used to prove programs correct is to write down
*invariants*, properties of the input data and of the program's
variables that are always true.  For each line of code, you then show
that if invariants X and Y are true *before* the line is executed, the
slightly different invariants X' and Y' are true *after* the line is
executed.  This continues until you reach the end of the program, at
which point the invariants should match the desired conditions on the
program's output.

  Functional programming's avoidance of assignments arose because
assignments are difficult to handle with this technique; assignments
can break invariants that were true before the assignment without
producing any new invariants that can be propagated onward.

  Unfortunately, proving programs correct is largely impractical and
not relevant to Python software. Even trivial programs require proofs
that are several pages long; the proof of correctness for a moderately
complicated program would be enormous, and few or none of the programs
you use daily (the Python interpreter, your XML parser, your web
browser) could be proven correct.  Even if you wrote down or generated
a proof, there would then be the question of verifying the proof; maybe
there's an error in it, and you wrongly believe you've proved the
program correct.


File: python-howto-3.2.2.info,  Node: Modularity,  Next: Ease of debugging and testing,  Prev: Formal provability,  Up: Introduction

6.1.2 Modularity
----------------

A more practical benefit of functional programming is that it forces
you to break apart your problem into small pieces.  Programs are more
modular as a result.  It's easier to specify and write a small function
that does one thing than a large function that performs a complicated
transformation.  Small functions are also easier to read and to check
for errors.


File: python-howto-3.2.2.info,  Node: Ease of debugging and testing,  Next: Composability,  Prev: Modularity,  Up: Introduction

6.1.3 Ease of debugging and testing
-----------------------------------

Testing and debugging a functional-style program is easier.

  Debugging is simplified because functions are generally small and
clearly specified.  When a program doesn't work, each function is an
interface point where you can check that the data are correct.  You can
look at the intermediate inputs and outputs to quickly isolate the
function that's responsible for a bug.

  Testing is easier because each function is a potential subject for a
unit test.  Functions don't depend on system state that needs to be
replicated before running a test; instead you only have to synthesize
the right input and then check that the output matches expectations.


File: python-howto-3.2.2.info,  Node: Composability,  Prev: Ease of debugging and testing,  Up: Introduction

6.1.4 Composability
-------------------

As you work on a functional-style program, you'll write a number of
functions with varying inputs and outputs.  Some of these functions
will be unavoidably specialized to a particular application, but others
will be useful in a wide variety of programs.  For example, a function
that takes a directory path and returns all the XML files in the
directory, or a function that takes a filename and returns its
contents, can be applied to many different situations.

  Over time you'll form a personal library of utilities.  Often you'll
assemble new programs by arranging existing functions in a new
configuration and writing a few functions specialized for the current
task.


File: python-howto-3.2.2.info,  Node: Iterators,  Next: Generator expressions and list comprehensions,  Prev: Introduction,  Up: Functional Programming HOWTO

6.2 Iterators
=============

I'll start by looking at a Python language feature that's an important
foundation for writing functional-style programs: iterators.

  An iterator is an object representing a stream of data; this object
returns the data one element at a time.  A Python iterator must support
a method called `__next__()' that takes no arguments and always returns
the next element of the stream.  If there are no more elements in the
stream, `__next__()' must raise the `StopIteration' exception.
Iterators don't have to be finite, though; it's perfectly reasonable to
write an iterator that produces an infinite stream of data.

  The built-in `iter()' function takes an arbitrary object and tries to
return an iterator that will return the object's contents or elements,
raising `TypeError' if the object doesn't support iteration.  Several
of Python's built-in data types support iteration, the most common
being lists and dictionaries.  An object is called an *iterable* object
if you can get an iterator for it.

  You can experiment with the iteration interface manually:

    >>> L = [1,2,3]
    >>> it = iter(L)
    >>> it
    <...iterator object at ...>
    >>> it.__next__()
    1
    >>> next(it)
    2
    >>> next(it)
    3
    >>> next(it)
    Traceback (most recent call last):
      File "<stdin>", line 1, in ?
    StopIteration
    >>>

Python expects iterable objects in several different contexts, the most
important being the `for' statement.  In the statement `for X in Y', Y
must be an iterator or some object for which `iter()' can create an
iterator.  These two statements are equivalent:

    for i in iter(obj):
        print(i)

    for i in obj:
        print(i)

Iterators can be materialized as lists or tuples by using the `list()'
or `tuple()' constructor functions:

    >>> L = [1,2,3]
    >>> iterator = iter(L)
    >>> t = tuple(iterator)
    >>> t
    (1, 2, 3)

Sequence unpacking also supports iterators: if you know an iterator
will return N elements, you can unpack them into an N-tuple:

    >>> L = [1,2,3]
    >>> iterator = iter(L)
    >>> a,b,c = iterator
    >>> a,b,c
    (1, 2, 3)

Built-in functions such as `max()' and `min()' can take a single
iterator argument and will return the largest or smallest element.  The
`"in"' and `"not in"' operators also support iterators: `X in iterator'
is true if X is found in the stream returned by the iterator.  You'll
run into obvious problems if the iterator is infinite; `max()',
`min()', and `"not in"' will never return, and if the element X never
appears in the stream, the `"in"' operator won't return either.

  Note that you can only go forward in an iterator; there's no way to
get the previous element, reset the iterator, or make a copy of it.
Iterator objects can optionally provide these additional capabilities,
but the iterator protocol only specifies the `next()' method.
Functions may therefore consume all of the iterator's output, and if
you need to do something different with the same stream, you'll have to
create a new iterator.

* Menu:

* Data Types That Support Iterators::


File: python-howto-3.2.2.info,  Node: Data Types That Support Iterators,  Up: Iterators

6.2.1 Data Types That Support Iterators
---------------------------------------

We've already seen how lists and tuples support iterators.  In fact,
any Python sequence type, such as strings, will automatically support
creation of an iterator.

  Calling `iter()' on a dictionary returns an iterator that will loop
over the dictionary's keys:

    >>> m = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,
    ...      'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}
    >>> for key in m:
    ...     print(key, m[key])
    Mar 3
    Feb 2
    Aug 8
    Sep 9
    Apr 4
    Jun 6
    Jul 7
    Jan 1
    May 5
    Nov 11
    Dec 12
    Oct 10

Note that the order is essentially random, because it's based on the
hash ordering of the objects in the dictionary.

  Applying `iter()' to a dictionary always loops over the keys, but
dictionaries have methods that return other iterators.  If you want to
iterate over values or key/value pairs, you can explicitly call the
`values()' or `items()' methods to get an appropriate iterator.

  The `dict()' constructor can accept an iterator that returns a finite
stream of `(key, value)' tuples:

    >>> L = [('Italy', 'Rome'), ('France', 'Paris'), ('US', 'Washington DC')]
    >>> dict(iter(L))
    {'Italy': 'Rome', 'US': 'Washington DC', 'France': 'Paris'}

Files also support iteration by calling the `readline()' method until
there are no more lines in the file.  This means you can read each line
of a file like this:

    for line in file:
        # do something for each line
        ...

Sets can take their contents from an iterable and let you iterate over
the set's elements:

    S = {2, 3, 5, 7, 11, 13}
    for i in S:
        print(i)



File: python-howto-3.2.2.info,  Node: Generator expressions and list comprehensions,  Next: Generators,  Prev: Iterators,  Up: Functional Programming HOWTO

6.3 Generator expressions and list comprehensions
=================================================

Two common operations on an iterator's output are 1) performing some
operation for every element, 2) selecting a subset of elements that
meet some condition.  For example, given a list of strings, you might
want to strip off trailing whitespace from each line or extract all the
strings containing a given substring.

  List comprehensions and generator expressions (short form:
"listcomps" and "genexps") are a concise notation for such operations,
borrowed from the functional programming language Haskell
(<http://www.haskell.org/>).  You can strip all the whitespace from a
stream of strings with the following code:

    line_list = ['  line 1\n', 'line 2  \n', ...]

    # Generator expression -- returns iterator
    stripped_iter = (line.strip() for line in line_list)

    # List comprehension -- returns list
    stripped_list = [line.strip() for line in line_list]

You can select only certain elements by adding an `"if"' condition:

    stripped_list = [line.strip() for line in line_list
                     if line != ""]

With a list comprehension, you get back a Python list; `stripped_list'
is a list containing the resulting lines, not an iterator.  Generator
expressions return an iterator that computes the values as necessary,
not needing to materialize all the values at once.  This means that
list comprehensions aren't useful if you're working with iterators that
return an infinite stream or a very large amount of data.  Generator
expressions are preferable in these situations.

  Generator expressions are surrounded by parentheses ("()") and list
comprehensions are surrounded by square brackets ("[]").  Generator
expressions have the form:

    ( expression for expr in sequence1
                 if condition1
                 for expr2 in sequence2
                 if condition2
                 for expr3 in sequence3 ...
                 if condition3
                 for exprN in sequenceN
                 if conditionN )

Again, for a list comprehension only the outside brackets are different
(square brackets instead of parentheses).

  The elements of the generated output will be the successive values of
`expression'.  The `if' clauses are all optional; if present,
`expression' is only evaluated and added to the result when `condition'
is true.

  Generator expressions always have to be written inside parentheses,
but the parentheses signalling a function call also count.  If you want
to create an iterator that will be immediately passed to a function you
can write:

    obj_total = sum(obj.count for obj in list_all_objects())

The `for...in' clauses contain the sequences to be iterated over.  The
sequences do not have to be the same length, because they are iterated
over from left to right, *not* in parallel.  For each element in
`sequence1', `sequence2' is looped over from the beginning.
`sequence3' is then looped over for each resulting pair of elements
from `sequence1' and `sequence2'.

  To put it another way, a list comprehension or generator expression is
equivalent to the following Python code:

    for expr1 in sequence1:
        if not (condition1):
            continue   # Skip this element
        for expr2 in sequence2:
            if not (condition2):
                continue    # Skip this element
            ...
            for exprN in sequenceN:
                 if not (conditionN):
                     continue   # Skip this element

                 # Output the value of
                 # the expression.

This means that when there are multiple `for...in' clauses but no `if'
clauses, the length of the resulting output will be equal to the
product of the lengths of all the sequences.  If you have two lists of
length 3, the output list is 9 elements long:

    >>> seq1 = 'abc'
    >>> seq2 = (1,2,3)
    >>> [(x,y) for x in seq1 for y in seq2]
    [('a', 1), ('a', 2), ('a', 3),
     ('b', 1), ('b', 2), ('b', 3),
     ('c', 1), ('c', 2), ('c', 3)]

To avoid introducing an ambiguity into Python's grammar, if
`expression' is creating a tuple, it must be surrounded with
parentheses.  The first list comprehension below is a syntax error,
while the second one is correct:

    # Syntax error
    [ x,y for x in seq1 for y in seq2]
    # Correct
    [ (x,y) for x in seq1 for y in seq2]



File: python-howto-3.2.2.info,  Node: Generators,  Next: Built-in functions,  Prev: Generator expressions and list comprehensions,  Up: Functional Programming HOWTO

6.4 Generators
==============

Generators are a special class of functions that simplify the task of
writing iterators.  Regular functions compute a value and return it,
but generators return an iterator that returns a stream of values.

  You're doubtless familiar with how regular function calls work in
Python or C.  When you call a function, it gets a private namespace
where its local variables are created.  When the function reaches a
`return' statement, the local variables are destroyed and the value is
returned to the caller.  A later call to the same function creates a
new private namespace and a fresh set of local variables. But, what if
the local variables weren't thrown away on exiting a function?  What if
you could later resume the function where it left off?  This is what
generators provide; they can be thought of as resumable functions.

  Here's the simplest example of a generator function:

    def generate_ints(N):
        for i in range(N):
            yield i

Any function containing a `yield' keyword is a generator function; this
is detected by Python's _bytecode_ compiler which compiles the function
specially as a result.

  When you call a generator function, it doesn't return a single value;
instead it returns a generator object that supports the iterator
protocol.  On executing the `yield' expression, the generator outputs
the value of `i', similar to a `return' statement.  The big difference
between `yield' and a `return' statement is that on reaching a `yield'
the generator's state of execution is suspended and local variables are
preserved.  On the next call to the generator's `.__next__()' method,
the function will resume executing.

  Here's a sample usage of the `generate_ints()' generator:

    >>> gen = generate_ints(3)
    >>> gen
    <generator object generate_ints at ...>
    >>> next(gen)
    0
    >>> next(gen)
    1
    >>> next(gen)
    2
    >>> next(gen)
    Traceback (most recent call last):
      File "stdin", line 1, in ?
      File "stdin", line 2, in generate_ints
    StopIteration

You could equally write `for i in generate_ints(5)', or `a,b,c =
generate_ints(3)'.

  Inside a generator function, the `return' statement can only be used
without a value, and signals the end of the procession of values; after
executing a `return' the generator cannot return any further values.
`return' with a value, such as `return 5', is a syntax error inside a
generator function.  The end of the generator's results can also be
indicated by raising `StopIteration' manually, or by just letting the
flow of execution fall off the bottom of the function.

  You could achieve the effect of generators manually by writing your
own class and storing all the local variables of the generator as
instance variables.  For example, returning a list of integers could be
done by setting `self.count' to 0, and having the `__next__()' method
increment `self.count' and return it.  However, for a moderately
complicated generator, writing a corresponding class can be much
messier.

  The test suite included with Python's library, `test_generators.py',
contains a number of more interesting examples.  Here's one generator
that implements an in-order traversal of a tree using generators
recursively.

    # A recursive generator that generates Tree leaves in in-order.
    def inorder(t):
        if t:
            for x in inorder(t.left):
                yield x

            yield t.label

            for x in inorder(t.right):
                yield x

Two other examples in `test_generators.py' produce solutions for the
N-Queens problem (placing N queens on an NxN chess board so that no
queen threatens another) and the Knight's Tour (finding a route that
takes a knight to every square of an NxN chessboard without visiting
any square twice).

* Menu:

* Passing values into a generator::


File: python-howto-3.2.2.info,  Node: Passing values into a generator,  Up: Generators

6.4.1 Passing values into a generator
-------------------------------------

In Python 2.4 and earlier, generators only produced output.  Once a
generator's code was invoked to create an iterator, there was no way to
pass any new information into the function when its execution is
resumed.  You could hack together this ability by making the generator
look at a global variable or by passing in some mutable object that
callers then modify, but these approaches are messy.

  In Python 2.5 there's a simple way to pass values into a generator.
`yield' became an expression, returning a value that can be assigned to
a variable or otherwise operated on:

    val = (yield i)

I recommend that you *always* put parentheses around a `yield'
expression when you're doing something with the returned value, as in
the above example.  The parentheses aren't always necessary, but it's
easier to always add them instead of having to remember when they're
needed.

  (PEP 342 explains the exact rules, which are that a
`yield'-expression must always be parenthesized except when it occurs
at the top-level expression on the right-hand side of an assignment.
This means you can write `val = yield i' but have to use parentheses
when there's an operation, as in `val = (yield i) + 12'.)

  Values are sent into a generator by calling its `send(value)' method.
This method resumes the generator's code and the `yield' expression
returns the specified value.  If the regular `__next__()' method is
called, the `yield' returns `None'.

  Here's a simple counter that increments by 1 and allows changing the
value of the internal counter.

    def counter (maximum):
        i = 0
        while i < maximum:
            val = (yield i)
            # If value provided, change counter
            if val is not None:
                i = val
            else:
                i += 1

And here's an example of changing the counter:

    >>> it = counter(10)
    >>> next(it)
    0
    >>> next(it)
    1
    >>> it.send(8)
    8
    >>> next(it)
    9
    >>> next(it)
    Traceback (most recent call last):
      File "t.py", line 15, in ?
        it.next()
    StopIteration

Because `yield' will often be returning `None', you should always check
for this case.  Don't just use its value in expressions unless you're
sure that the `send()' method will be the only method used resume your
generator function.

  In addition to `send()', there are two other new methods on
generators:

   * `throw(type, value=None, traceback=None)' is used to raise an
     exception inside the generator; the exception is raised by the
     `yield' expression where the generator's execution is paused.

   * `close()' raises a `GeneratorExit' exception inside the generator
     to terminate the iteration.  On receiving this exception, the
     generator's code must either raise `GeneratorExit' or
     `StopIteration'; catching the exception and doing anything else is
     illegal and will trigger a `RuntimeError'.  `close()' will also be
     called by Python's garbage collector when the generator is
     garbage-collected.

     If you need to run cleanup code when a `GeneratorExit' occurs, I
     suggest using a `try: ... finally:' suite instead of catching
     `GeneratorExit'.

  The cumulative effect of these changes is to turn generators from
one-way producers of information into both producers and consumers.

  Generators also become *coroutines*, a more generalized form of
subroutines.  Subroutines are entered at one point and exited at
another point (the top of the function, and a `return' statement), but
coroutines can be entered, exited, and resumed at many different points
(the `yield' statements).


File: python-howto-3.2.2.info,  Node: Built-in functions,  Next: The itertools module,  Prev: Generators,  Up: Functional Programming HOWTO

6.5 Built-in functions
======================

Let's look in more detail at built-in functions often used with
iterators.

  Two of Python's built-in functions, `map()' and `filter()' duplicate
the features of generator expressions:

`map(f, iterA, iterB, ...)' returns an iterator over the sequence
     `f(iterA[0], iterB[0]), f(iterA[1], iterB[1]), f(iterA[2],
     iterB[2]), ...'.

         >>> def upper(s):
         ...     return s.upper()


         >>> list(map(upper, ['sentence', 'fragment']))
         ['SENTENCE', 'FRAGMENT']
         >>> [upper(s) for s in ['sentence', 'fragment']]
         ['SENTENCE', 'FRAGMENT']



  You can of course achieve the same effect with a list comprehension.

  `filter(predicate, iter)' returns an iterator over all the sequence
elements that meet a certain condition, and is similarly duplicated by
list comprehensions.  A *predicate* is a function that returns the
truth value of some condition; for use with `filter()', the predicate
must take a single value.

    >>> def is_even(x):
    ...     return (x % 2) == 0


    >>> list(filter(is_even, range(10)))
    [0, 2, 4, 6, 8]

This can also be written as a list comprehension:

    >>> list(x for x in range(10) if is_even(x))
    [0, 2, 4, 6, 8]

`enumerate(iter)' counts off the elements in the iterable, returning
2-tuples containing the count and each element.

    >>> for item in enumerate(['subject', 'verb', 'object']):
    ...     print(item)
    (0, 'subject')
    (1, 'verb')
    (2, 'object')

`enumerate()' is often used when looping through a list and recording
the indexes at which certain conditions are met:

    f = open('data.txt', 'r')
    for i, line in enumerate(f):
        if line.strip() == '':
            print('Blank line at line #%i' % i)

`sorted(iterable, [key=None], [reverse=False])' collects all the
elements of the iterable into a list, sorts the list, and returns the
sorted result.  The `key', and `reverse' arguments are passed through
to the constructed list's `.sort()' method.

    >>> import random
    >>> # Generate 8 random numbers between [0, 10000)
    >>> rand_list = random.sample(range(10000), 8)
    >>> rand_list
    [769, 7953, 9828, 6431, 8442, 9878, 6213, 2207]
    >>> sorted(rand_list)
    [769, 2207, 6213, 6431, 7953, 8442, 9828, 9878]
    >>> sorted(rand_list, reverse=True)
    [9878, 9828, 8442, 7953, 6431, 6213, 2207, 769]

(For a more detailed discussion of sorting, see the Sorting mini-HOWTO
in the Python wiki at <http://wiki.python.org/moin/HowTo/Sorting>.)

  The `any(iter)' and `all(iter)' built-ins look at the truth values of
an iterable's contents.  `any()' returns True if any element in the
iterable is a true value, and `all()' returns True if all of the
elements are true values:

    >>> any([0,1,0])
    True
    >>> any([0,0,0])
    False
    >>> any([1,1,1])
    True
    >>> all([0,1,0])
    False
    >>> all([0,0,0])
    False
    >>> all([1,1,1])
    True

`zip(iterA, iterB, ...)' takes one element from each iterable and
returns them in a tuple:

    zip(['a', 'b', 'c'], (1, 2, 3)) =>
      ('a', 1), ('b', 2), ('c', 3)

It doesn't construct an in-memory list and exhaust all the input
iterators before returning; instead tuples are constructed and returned
only if they're requested.  (The technical term for this behaviour is
lazy evaluation(1).)

  This iterator is intended to be used with iterables that are all of
the same length.  If the iterables are of different lengths, the
resulting stream will be the same length as the shortest iterable.

    zip(['a', 'b'], (1, 2, 3)) =>
      ('a', 1), ('b', 2)

You should avoid doing this, though, because an element may be taken
from the longer iterators and discarded.  This means you can't go on to
use the iterators further because you risk skipping a discarded element.

  ---------- Footnotes ----------

  (1) http://en.wikipedia.org/wiki/Lazy_evaluation


File: python-howto-3.2.2.info,  Node: The itertools module,  Next: The functools module,  Prev: Built-in functions,  Up: Functional Programming HOWTO

6.6 The itertools module
========================

The `itertools' module contains a number of commonly-used iterators as
well as functions for combining several iterators.  This section will
introduce the module's contents by showing small examples.

  The module's functions fall into a few broad classes:

   * Functions that create a new iterator based on an existing iterator.

   * Functions for treating an iterator's elements as function
     arguments.

   * Functions for selecting portions of an iterator's output.

   * A function for grouping an iterator's output.

* Menu:

* Creating new iterators::
* Calling functions on elements::
* Selecting elements::
* Grouping elements::


File: python-howto-3.2.2.info,  Node: Creating new iterators,  Next: Calling functions on elements,  Up: The itertools module

6.6.1 Creating new iterators
----------------------------

`itertools.count(n)' returns an infinite stream of integers, increasing
by 1 each time.  You can optionally supply the starting number, which
defaults to 0:

    itertools.count() =>
      0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...
    itertools.count(10) =>
      10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...

`itertools.cycle(iter)' saves a copy of the contents of a provided
iterable and returns a new iterator that returns its elements from
first to last.  The new iterator will repeat these elements infinitely.

    itertools.cycle([1,2,3,4,5]) =>
      1, 2, 3, 4, 5, 1, 2, 3, 4, 5, ...

`itertools.repeat(elem, [n])' returns the provided element `n' times, or
returns the element endlessly if `n' is not provided.

    itertools.repeat('abc') =>
      abc, abc, abc, abc, abc, abc, abc, abc, abc, abc, ...
    itertools.repeat('abc', 5) =>
      abc, abc, abc, abc, abc

`itertools.chain(iterA, iterB, ...)' takes an arbitrary number of
iterables as input, and returns all the elements of the first iterator,
then all the elements of the second, and so on, until all of the
iterables have been exhausted.

    itertools.chain(['a', 'b', 'c'], (1, 2, 3)) =>
      a, b, c, 1, 2, 3

`itertools.islice(iter, [start], stop, [step])' returns a stream that's
a slice of the iterator.  With a single `stop' argument, it will return
the first `stop' elements.  If you supply a starting index, you'll get
`stop-start' elements, and if you supply a value for `step', elements
will be skipped accordingly.  Unlike Python's string and list slicing,
you can't use negative values for `start', `stop', or `step'.

    itertools.islice(range(10), 8) =>
      0, 1, 2, 3, 4, 5, 6, 7
    itertools.islice(range(10), 2, 8) =>
      2, 3, 4, 5, 6, 7
    itertools.islice(range(10), 2, 8, 2) =>
      2, 4, 6

`itertools.tee(iter, [n])' replicates an iterator; it returns `n'
independent iterators that will all return the contents of the source
iterator.  If you don't supply a value for `n', the default is 2.
Replicating iterators requires saving some of the contents of the
source iterator, so this can consume significant memory if the iterator
is large and one of the new iterators is consumed more than the others.

    itertools.tee( itertools.count() ) =>
       iterA, iterB

    where iterA ->
       0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...

    and   iterB ->
       0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...



File: python-howto-3.2.2.info,  Node: Calling functions on elements,  Next: Selecting elements,  Prev: Creating new iterators,  Up: The itertools module

6.6.2 Calling functions on elements
-----------------------------------

The `operator' module contains a set of functions corresponding to
Python's operators.  Some examples are `operator.add(a, b)' (adds two
values), `operator.ne(a, b)' (same as `a!=b'), and
`operator.attrgetter('id')' (returns a callable that fetches the `"id"'
attribute).

  `itertools.starmap(func, iter)' assumes that the iterable will return
a stream of tuples, and calls `f()' using these tuples as the arguments:

    itertools.starmap(os.path.join,
                      [('/usr', 'bin', 'java'), ('/bin', 'python'),
                       ('/usr', 'bin', 'perl'),('/usr', 'bin', 'ruby')])
    =>
      /usr/bin/java, /bin/python, /usr/bin/perl, /usr/bin/ruby



File: python-howto-3.2.2.info,  Node: Selecting elements,  Next: Grouping elements,  Prev: Calling functions on elements,  Up: The itertools module

6.6.3 Selecting elements
------------------------

Another group of functions chooses a subset of an iterator's elements
based on a predicate.

  `itertools.filterfalse(predicate, iter)' is the opposite, returning
all elements for which the predicate returns false:

    itertools.filterfalse(is_even, itertools.count()) =>
      1, 3, 5, 7, 9, 11, 13, 15, ...

`itertools.takewhile(predicate, iter)' returns elements for as long as
the predicate returns true.  Once the predicate returns false, the
iterator will signal the end of its results.

    def less_than_10(x):
        return (x < 10)

    itertools.takewhile(less_than_10, itertools.count()) =>
      0, 1, 2, 3, 4, 5, 6, 7, 8, 9

    itertools.takewhile(is_even, itertools.count()) =>
      0

`itertools.dropwhile(predicate, iter)' discards elements while the
predicate returns true, and then returns the rest of the iterable's
results.

    itertools.dropwhile(less_than_10, itertools.count()) =>
      10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...

    itertools.dropwhile(is_even, itertools.count()) =>
      1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...



File: python-howto-3.2.2.info,  Node: Grouping elements,  Prev: Selecting elements,  Up: The itertools module

6.6.4 Grouping elements
-----------------------

The last function I'll discuss, `itertools.groupby(iter,
key_func=None)', is the most complicated.  `key_func(elem)' is a
function that can compute a key value for each element returned by the
iterable.  If you don't supply a key function, the key is simply each
element itself.

  `groupby()' collects all the consecutive elements from the underlying
iterable that have the same key value, and returns a stream of 2-tuples
containing a key value and an iterator for the elements with that key.

    city_list = [('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL'),
                 ('Anchorage', 'AK'), ('Nome', 'AK'),
                 ('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ'),
                 ...
                ]

    def get_state (city_state):
        return city_state[1]

    itertools.groupby(city_list, get_state) =>
      ('AL', iterator-1),
      ('AK', iterator-2),
      ('AZ', iterator-3), ...

    where
    iterator-1 =>
      ('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL')
    iterator-2 =>
      ('Anchorage', 'AK'), ('Nome', 'AK')
    iterator-3 =>
      ('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ')

`groupby()' assumes that the underlying iterable's contents will
already be sorted based on the key.  Note that the returned iterators
also use the underlying iterable, so you have to consume the results of
iterator-1 before requesting iterator-2 and its corresponding key.


File: python-howto-3.2.2.info,  Node: The functools module,  Next: Small functions and the lambda expression,  Prev: The itertools module,  Up: Functional Programming HOWTO

6.7 The functools module
========================

The `functools' module in Python 2.5 contains some higher-order
functions.  A *higher-order function* takes one or more functions as
input and returns a new function.  The most useful tool in this module
is the `functools.partial()' function.

  For programs written in a functional style, you'll sometimes want to
construct variants of existing functions that have some of the
parameters filled in.  Consider a Python function `f(a, b, c)'; you may
wish to create a new function `g(b, c)' that's equivalent to `f(1, b,
c)'; you're filling in a value for one of `f()''s parameters.  This is
called "partial function application".

  The constructor for `partial' takes the arguments `(function, arg1,
arg2, ... kwarg1=value1, kwarg2=value2)'.  The resulting object is
callable, so you can just call it to invoke `function' with the
filled-in arguments.

  Here's a small but realistic example:

    import functools

    def log (message, subsystem):
        "Write the contents of 'message' to the specified subsystem."
        print('%s: %s' % (subsystem, message))
        ...

    server_log = functools.partial(log, subsystem='server')
    server_log('Unable to open socket')

`functools.reduce(func, iter, [initial_value])' cumulatively performs an
operation on all the iterable's elements and, therefore, can't be
applied to infinite iterables.  (Note it is not in `builtins', but in
the `functools' module.)  `func' must be a function that takes two
elements and returns a single value.  `functools.reduce()' takes the
first two elements A and B returned by the iterator and calculates
`func(A, B)'.  It then requests the third element, C, calculates
`func(func(A, B), C)', combines this result with the fourth element
returned, and continues until the iterable is exhausted.  If the
iterable returns no values at all, a `TypeError' exception is raised.
If the initial value is supplied, it's used as a starting point and
`func(initial_value, A)' is the first calculation.

    >>> import operator, functools
    >>> functools.reduce(operator.concat, ['A', 'BB', 'C'])
    'ABBC'
    >>> functools.reduce(operator.concat, [])
    Traceback (most recent call last):
      ...
    TypeError: reduce() of empty sequence with no initial value
    >>> functools.reduce(operator.mul, [1,2,3], 1)
    6
    >>> functools.reduce(operator.mul, [], 1)
    1

If you use `operator.add()' with `functools.reduce()', you'll add up
all the elements of the iterable.  This case is so common that there's
a special built-in called `sum()' to compute it:

    >>> import functools
    >>> functools.reduce(operator.add, [1,2,3,4], 0)
    10
    >>> sum([1,2,3,4])
    10
    >>> sum([])
    0

For many uses of `functools.reduce()', though, it can be clearer to
just write the obvious `for' loop:

    import functools
    # Instead of:
    product = functools.reduce(operator.mul, [1,2,3], 1)

    # You can write:
    product = 1
    for i in [1,2,3]:
        product *= i


* Menu:

* The operator module::
* The functional module::


File: python-howto-3.2.2.info,  Node: The operator module,  Next: The functional module,  Up: The functools module

6.7.1 The operator module
-------------------------

The `operator' module was mentioned earlier.  It contains a set of
functions corresponding to Python's operators.  These functions are
often useful in functional-style code because they save you from
writing trivial functions that perform a single operation.

  Some of the functions in this module are:

   * Math operations: `add()', `sub()', `mul()', `floordiv()', `abs()',
     ...

   * Logical operations: `not_()', `truth()'.

   * Bitwise operations: `and_()', `or_()', `invert()'.

   * Comparisons: `eq()', `ne()', `lt()', `le()', `gt()', and `ge()'.

   * Object identity: `is_()', `is_not()'.

  Consult the operator module's documentation for a complete list.


File: python-howto-3.2.2.info,  Node: The functional module,  Prev: The operator module,  Up: The functools module

6.7.2 The functional module
---------------------------

Collin Winter's functional module(1) provides a number of more advanced
tools for functional programming. It also reimplements several Python
built-ins, trying to make them more intuitive to those used to
functional programming in other languages.

  This section contains an introduction to some of the most important
functions in `functional'; full documentation can be found at the
project's website(2).

  `compose(outer, inner, unpack=False)'

  The `compose()' function implements function composition.  In other
words, it returns a wrapper around the `outer' and `inner' callables,
such that the return value from `inner' is fed directly to `outer'.
That is,

    >>> def add(a, b):
    ...     return a + b
    ...
    >>> def double(a):
    ...     return 2 * a
    ...
    >>> compose(double, add)(5, 6)
    22

is equivalent to

    >>> double(add(5, 6))
    22

The `unpack' keyword is provided to work around the fact that Python
functions are not always fully curried(3).  By default, it is expected
that the `inner' function will return a single object and that the
`outer' function will take a single argument. Setting the `unpack'
argument causes `compose' to expect a tuple from `inner' which will be
expanded before being passed to `outer'. Put simply,

    compose(f, g)(5, 6)

is equivalent to:

    f(g(5, 6))

while

    compose(f, g, unpack=True)(5, 6)

is equivalent to:

    f(*g(5, 6))

Even though `compose()' only accepts two functions, it's trivial to
build up a version that will compose any number of functions. We'll use
`functools.reduce()', `compose()' and `partial()' (the last of which is
provided by both `functional' and `functools').

    from functional import compose, partial
    import functools


    multi_compose = partial(functools.reduce, compose)

We can also use `map()', `compose()' and `partial()' to craft a version
of `"".join(...)' that converts its arguments to string:

    from functional import compose, partial

    join = compose("".join, partial(map, str))

`flip(func)'

  `flip()' wraps the callable in `func' and causes it to receive its
non-keyword arguments in reverse order.

    >>> def triple(a, b, c):
    ...     return (a, b, c)
    ...
    >>> triple(5, 6, 7)
    (5, 6, 7)
    >>>
    >>> flipped_triple = flip(triple)
    >>> flipped_triple(5, 6, 7)
    (7, 6, 5)

`foldl(func, start, iterable)'

  `foldl()' takes a binary function, a starting value (usually some
kind of 'zero'), and an iterable.  The function is applied to the
starting value and the first element of the list, then the result of
that and the second element of the list, then the result of that and
the third element of the list, and so on.

  This means that a call such as:

    foldl(f, 0, [1, 2, 3])

is equivalent to:

    f(f(f(0, 1), 2), 3)

`foldl()' is roughly equivalent to the following recursive function:

    def foldl(func, start, seq):
        if len(seq) == 0:
            return start

        return foldl(func, func(start, seq[0]), seq[1:])

Speaking of equivalence, the above `foldl' call can be expressed in
terms of the built-in `functools.reduce()' like so:

    import functools
    functools.reduce(f, [1, 2, 3], 0)

We can use `foldl()', `operator.concat()' and `partial()' to write a
cleaner, more aesthetically-pleasing version of Python's `"".join(...)'
idiom:

    from functional import foldl, partial from operator import concat

    join = partial(foldl, concat, "")


  ---------- Footnotes ----------

  (1) http://oakwinter.com/code/functional/

  (2) http://oakwinter.com/code/functional/documentation/

  (3) http://en.wikipedia.org/wiki/Currying


File: python-howto-3.2.2.info,  Node: Small functions and the lambda expression,  Next: Revision History and Acknowledgements,  Prev: The functools module,  Up: Functional Programming HOWTO

6.8 Small functions and the lambda expression
=============================================

When writing functional-style programs, you'll often need little
functions that act as predicates or that combine elements in some way.

  If there's a Python built-in or a module function that's suitable,
you don't need to define a new function at all:

    stripped_lines = [line.strip() for line in lines]
    existing_files = filter(os.path.exists, file_list)

If the function you need doesn't exist, you need to write it.  One way
to write small functions is to use the `lambda' statement.  `lambda'
takes a number of parameters and an expression combining these
parameters, and creates a small function that returns the value of the
expression:

    lowercase = lambda x: x.lower()

    print_assign = lambda name, value: name + '=' + str(value)

    adder = lambda x, y: x+y

An alternative is to just use the `def' statement and define a function
in the usual way:

    def lowercase(x):
        return x.lower()

    def print_assign(name, value):
        return name + '=' + str(value)

    def adder(x,y):
        return x + y

Which alternative is preferable?  That's a style question; my usual
course is to avoid using `lambda'.

  One reason for my preference is that `lambda' is quite limited in the
functions it can define.  The result has to be computable as a single
expression, which means you can't have multiway `if... elif... else'
comparisons or `try... except' statements.  If you try to do too much
in a `lambda' statement, you'll end up with an overly complicated
expression that's hard to read.  Quick, what's the following code doing?

    import functools
    total = functools.reduce(lambda a, b: (0, a[1] + b[1]), items)[1]

You can figure it out, but it takes time to disentangle the expression
to figure out what's going on.  Using a short nested `def' statements
makes things a little bit better:

    import functools
    def combine (a, b):
        return 0, a[1] + b[1]

    total = functools.reduce(combine, items)[1]

But it would be best of all if I had simply used a `for' loop:

    total = 0
    for a, b in items:
        total += b

Or the `sum()' built-in and a generator expression:

    total = sum(b for a,b in items)

Many uses of `functools.reduce()' are clearer when written as `for'
loops.

  Fredrik Lundh once suggested the following set of rules for
refactoring uses of `lambda':

  1. Write a lambda function.

  2. Write a comment explaining what the heck that lambda does.

  3. Study the comment for a while, and think of a name that captures
     the essence of the comment.

  4. Convert the lambda to a def statement, using that name.

  5. Remove the comment.

  I really like these rules, but you're free to disagree about whether
this lambda-free style is better.


File: python-howto-3.2.2.info,  Node: Revision History and Acknowledgements,  Next: References,  Prev: Small functions and the lambda expression,  Up: Functional Programming HOWTO

6.9 Revision History and Acknowledgements
=========================================

The author would like to thank the following people for offering
suggestions, corrections and assistance with various drafts of this
article: Ian Bicking, Nick Coghlan, Nick Efford, Raymond Hettinger, Jim
Jewett, Mike Krell, Leandro Lameiro, Jussi Salmela, Collin Winter,
Blake Winton.

  Version 0.1: posted June 30 2006.

  Version 0.11: posted July 1 2006.  Typo fixes.

  Version 0.2: posted July 10 2006.  Merged genexp and listcomp
sections into one.  Typo fixes.

  Version 0.21: Added more references suggested on the tutor mailing
list.

  Version 0.30: Adds a section on the `functional' module written by
Collin Winter; adds short section on the operator module; a few other
edits.


File: python-howto-3.2.2.info,  Node: References,  Prev: Revision History and Acknowledgements,  Up: Functional Programming HOWTO

6.10 References
===============

* Menu:

* General::
* Python-specific::
* Python documentation::


File: python-howto-3.2.2.info,  Node: General,  Next: Python-specific,  Up: References

6.10.1 General
--------------

*Structure and Interpretation of Computer Programs*, by Harold Abelson
and Gerald Jay Sussman with Julie Sussman.  Full text at
<http://mitpress.mit.edu/sicp/>.  In this classic textbook of computer
science, chapters 2 and 3 discuss the use of sequences and streams to
organize the data flow inside a program.  The book uses Scheme for its
examples, but many of the design approaches described in these chapters
are applicable to functional-style Python code.

  <http://www.defmacro.org/ramblings/fp.html>: A general introduction
to functional programming that uses Java examples and has a lengthy
historical introduction.

  <http://en.wikipedia.org/wiki/Functional_programming>: General
Wikipedia entry describing functional programming.

  <http://en.wikipedia.org/wiki/Coroutine>: Entry for coroutines.

  <http://en.wikipedia.org/wiki/Currying>: Entry for the concept of
currying.


File: python-howto-3.2.2.info,  Node: Python-specific,  Next: Python documentation,  Prev: General,  Up: References

6.10.2 Python-specific
----------------------

<http://gnosis.cx/TPiP/>: The first chapter of David Mertz's book `Text
Processing in Python' discusses functional programming for text
processing, in the section titled "Utilizing Higher-Order Functions in
Text Processing".

  Mertz also wrote a 3-part series of articles on functional programming
for IBM's DeveloperWorks site; see part 1(1), part 2(2), and part 3(3),

  ---------- Footnotes ----------

  (1) http://www-128.ibm.com/developerworks/library/l-prog.html

  (2) http://www-128.ibm.com/developerworks/library/l-prog2.html

  (3) http://www-128.ibm.com/developerworks/linux/library/l-prog3.html


File: python-howto-3.2.2.info,  Node: Python documentation,  Prev: Python-specific,  Up: References

6.10.3 Python documentation
---------------------------

Documentation for the `itertools' module.

  Documentation for the `operator' module.

  PEP 289(1): "Generator Expressions"

  PEP 342(2): "Coroutines via Enhanced Generators" describes the new
generator features in Python 2.5.

  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-0289

  (2) http://www.python.org/dev/peps/pep-0342


File: python-howto-3.2.2.info,  Node: Logging HOWTO,  Next: Logging Cookbook,  Prev: Functional Programming HOWTO,  Up: Top

7 Logging HOWTO
***************

     Author: Vinay Sajip <vinay_sajip at red-dove dot com>

* Menu:

* Basic Logging Tutorial::
* Advanced Logging Tutorial::
* Logging Levels::
* Useful Handlers::
* Exceptions raised during logging::
* Using arbitrary objects as messages::
* Optimization::

Basic Logging Tutorial

* When to use logging::
* A simple example::
* Logging to a file::
* Logging from multiple modules::
* Logging variable data::
* Changing the format of displayed messages::
* Displaying the date/time in messages::
* Next Steps::

Advanced Logging Tutorial

* Loggers::
* Handlers::
* Formatters::
* Configuring Logging::
* What happens if no configuration is provided::
* Configuring Logging for a Library::

Logging Levels

* Custom Levels::


File: python-howto-3.2.2.info,  Node: Basic Logging Tutorial,  Next: Advanced Logging Tutorial,  Up: Logging HOWTO

7.1 Basic Logging Tutorial
==========================

Logging is a means of tracking events that happen when some software
runs. The software's developer adds logging calls to their code to
indicate that certain events have occurred. An event is described by a
descriptive message which can optionally contain variable data (i.e.
data that is potentially different for each occurrence of the event).
Events also have an importance which the developer ascribes to the
event; the importance can also be called the _level_ or _severity_.

* Menu:

* When to use logging::
* A simple example::
* Logging to a file::
* Logging from multiple modules::
* Logging variable data::
* Changing the format of displayed messages::
* Displaying the date/time in messages::
* Next Steps::


File: python-howto-3.2.2.info,  Node: When to use logging,  Next: A simple example,  Up: Basic Logging Tutorial

7.1.1 When to use logging
-------------------------

Logging provides a set of convenience functions for simple logging
usage. These are `debug()', `info()', `warning()', `error()' and
`critical()'. To determine when to use logging, see the table below,
which states, for each of a set of common tasks, the best tool to use
for it.

Task you want to perform                  The best tool for the task
------------------------------------------------------------------------------------- 
Display console output for ordinary       `print()'
usage of a command line script or program 
Report events that occur during normal    `logging.info()' (or `logging.debug()'
operation of a program (e.g.  for status  for very detailed output for diagnostic
monitoring or fault investigation)        purposes)
Issue a warning regarding a particular    `warnings.warn()' in library code if the
runtime event                             issue is avoidable and the client
                                          application should be modified to
                                          eliminate the warning
                                          
                                            `logging.warning()' if there is nothing
                                          the client application can do about the
                                          situation, but the event should still be
                                          noted
Report an error regarding a particular    Raise an exception
runtime event                             
Report suppression of an error without    `logging.error()', `logging.exception()'
raising an exception (e.g.  error         or `logging.critical()' as appropriate
handler in a long-running server process) for the specific error and application
                                          domain

  The logging functions are named after the level or severity of the
events they are used to track. The standard levels and their
applicability are described below (in increasing order of severity):

Level              When it's used
--------------------------------------------------------------------- 
`DEBUG'            Detailed information, typically of interest only
                   when diagnosing problems.
`INFO'             Confirmation that things are working as expected.
`WARNING'          An indication that something unexpected
                   happened, or indicative of some problem in the
                   near future (e.g. 'disk space low').  The
                   software is still working as expected.
`ERROR'            Due to a more serious problem, the software has
                   not been able to perform some function.
`CRITICAL'         A serious error, indicating that the program
                   itself may be unable to continue running.

  The default level is `WARNING', which means that only events of this
level and above will be tracked, unless the logging package is
configured to do otherwise.

  Events that are tracked can be handled in different ways. The
simplest way of handling tracked events is to print them to the
console. Another common way is to write them to a disk file.


File: python-howto-3.2.2.info,  Node: A simple example,  Next: Logging to a file,  Prev: When to use logging,  Up: Basic Logging Tutorial

7.1.2 A simple example
----------------------

A very simple example is:

    import logging
    logging.warning('Watch out!') # will print a message to the console
    logging.info('I told you so') # will not print anything

If you type these lines into a script and run it, you'll see:

    WARNING:root:Watch out!

printed out on the console. The `INFO' message doesn't appear because
the default level is `WARNING'. The printed message includes the
indication of the level and the description of the event provided in
the logging call, i.e.  'Watch out!'. Don't worry about the 'root' part
for now: it will be explained later. The actual output can be formatted
quite flexibly if you need that; formatting options will also be
explained later.


File: python-howto-3.2.2.info,  Node: Logging to a file,  Next: Logging from multiple modules,  Prev: A simple example,  Up: Basic Logging Tutorial

7.1.3 Logging to a file
-----------------------

A very common situation is that of recording logging events in a file,
so let's look at that next:

    import logging
    logging.basicConfig(filename='example.log',level=logging.DEBUG)
    logging.debug('This message should go to the log file')
    logging.info('So should this')
    logging.warning('And this, too')

And now if we open the file and look at what we have, we should find
the log messages:

    DEBUG:root:This message should go to the log file
    INFO:root:So should this
    WARNING:root:And this, too

This example also shows how you can set the logging level which acts as
the threshold for tracking. In this case, because we set the threshold
to `DEBUG', all of the messages were printed.

  If you want to set the logging level from a command-line option such
as:

    --log=INFO

and you have the value of the parameter passed for `--log' in some
variable _loglevel_, you can use:

    getattr(logging, loglevel.upper())

to get the value which you'll pass to `basicConfig()' via the _level_
argument. You may want to error check any user input value, perhaps as
in the following example:

    # assuming loglevel is bound to the string value obtained from the
    # command line argument. Convert to upper case to allow the user to
    # specify --log=DEBUG or --log=debug
    numeric_level = getattr(logging, loglevel.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError('Invalid log level: %s' % loglevel)
    logging.basicConfig(level=numeric_level, ...)

The call to `basicConfig()' should come _before_ any calls to `debug()',
`info()' etc. As it's intended as a one-off simple configuration
facility, only the first call will actually do anything: subsequent
calls are effectively no-ops.

  If you run the above script several times, the messages from
successive runs are appended to the file _example.log_. If you want
each run to start afresh, not remembering the messages from earlier
runs, you can specify the _filemode_ argument, by changing the call in
the above example to:

    logging.basicConfig(filename='example.log', filemode='w', level=logging.DEBUG)

The output will be the same as before, but the log file is no longer
appended to, so the messages from earlier runs are lost.


File: python-howto-3.2.2.info,  Node: Logging from multiple modules,  Next: Logging variable data,  Prev: Logging to a file,  Up: Basic Logging Tutorial

7.1.4 Logging from multiple modules
-----------------------------------

If your program consists of multiple modules, here's an example of how
you could organize logging in it:

    # myapp.py
    import logging
    import mylib

    def main():
        logging.basicConfig(filename='myapp.log', level=logging.INFO)
        logging.info('Started')
        mylib.do_something()
        logging.info('Finished')

    if __name__ == '__main__':
        main()


    # mylib.py
    import logging

    def do_something():
        logging.info('Doing something')

If you run _myapp.py_, you should see this in _myapp.log_:

    INFO:root:Started
    INFO:root:Doing something
    INFO:root:Finished

which is hopefully what you were expecting to see. You can generalize
this to multiple modules, using the pattern in _mylib.py_. Note that
for this simple usage pattern, you won't know, by looking in the log
file, _where_ in your application your messages came from, apart from
looking at the event description. If you want to track the location of
your messages, you'll need to refer to the documentation beyond the
tutorial level - see *note Advanced Logging Tutorial: 79.


File: python-howto-3.2.2.info,  Node: Logging variable data,  Next: Changing the format of displayed messages,  Prev: Logging from multiple modules,  Up: Basic Logging Tutorial

7.1.5 Logging variable data
---------------------------

To log variable data, use a format string for the event description
message and append the variable data as arguments. For example:

    import logging
    logging.warning('%s before you %s', 'Look', 'leap!')

will display:

    WARNING:root:Look before you leap!

As you can see, merging of variable data into the event description
message uses the old, %-style of string formatting. This is for
backwards compatibility: the logging package pre-dates newer formatting
options such as `str.format()' and `string.Template'. These newer
formatting options _are_ supported, but exploring them is outside the
scope of this tutorial.


File: python-howto-3.2.2.info,  Node: Changing the format of displayed messages,  Next: Displaying the date/time in messages,  Prev: Logging variable data,  Up: Basic Logging Tutorial

7.1.6 Changing the format of displayed messages
-----------------------------------------------

To change the format which is used to display messages, you need to
specify the format you want to use:

    import logging
    logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)
    logging.debug('This message should appear on the console')
    logging.info('So should this')
    logging.warning('And this, too')

which would print:

    DEBUG:This message should appear on the console
    INFO:So should this
    WARNING:And this, too

Notice that the 'root' which appeared in earlier examples has
disappeared. For a full set of things that can appear in format
strings, you can refer to the documentation for _logrecord-attributes_,
but for simple usage, you just need the _levelname_ (severity),
_message_ (event description, including variable data) and perhaps to
display when the event occurred. This is described in the next section.


File: python-howto-3.2.2.info,  Node: Displaying the date/time in messages,  Next: Next Steps,  Prev: Changing the format of displayed messages,  Up: Basic Logging Tutorial

7.1.7 Displaying the date/time in messages
------------------------------------------

To display the date and time of an event, you would place '%(asctime)s'
in your format string:

    import logging
    logging.basicConfig(format='%(asctime)s %(message)s')
    logging.warning('is when this event was logged.')

which should print something like this:

    2010-12-12 11:41:42,612 is when this event was logged.

The default format for date/time display (shown above) is ISO8601. If
you need more control over the formatting of the date/time, provide a
_datefmt_ argument to `basicConfig', as in this example:

    import logging
    logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')
    logging.warning('is when this event was logged.')

which would display something like this:

    12/12/2010 11:46:36 AM is when this event was logged.

The format of the _datefmt_ argument is the same as supported by
`time.strftime()'.


File: python-howto-3.2.2.info,  Node: Next Steps,  Prev: Displaying the date/time in messages,  Up: Basic Logging Tutorial

7.1.8 Next Steps
----------------

That concludes the basic tutorial. It should be enough to get you up and
running with logging. There's a lot more that the logging package
offers, but to get the best out of it, you'll need to invest a little
more of your time in reading the following sections. If you're ready
for that, grab some of your favourite beverage and carry on.

  If your logging needs are simple, then use the above examples to
incorporate logging into your own scripts, and if you run into problems
or don't understand something, please post a question on the
comp.lang.python Usenet group (available at
<http://groups.google.com/group/comp.lang.python>) and you should
receive help before too long.

  Still here? You can carry on reading the next few sections, which
provide a slightly more advanced/in-depth tutorial than the basic one
above. After that, you can take a look at the *note Logging Cookbook:
7e.


File: python-howto-3.2.2.info,  Node: Advanced Logging Tutorial,  Next: Logging Levels,  Prev: Basic Logging Tutorial,  Up: Logging HOWTO

7.2 Advanced Logging Tutorial
=============================

The logging library takes a modular approach and offers several
categories of components: loggers, handlers, filters, and formatters.

   * Loggers expose the interface that application code directly uses.

   * Handlers send the log records (created by loggers) to the
     appropriate destination.

   * Filters provide a finer grained facility for determining which log
     records to output.

   * Formatters specify the layout of log records in the final output.

  Logging is performed by calling methods on instances of the `Logger'
class (hereafter called _loggers_). Each instance has a name, and they
are conceptually arranged in a namespace hierarchy using dots (periods)
as separators. For example, a logger named 'scan' is the parent of
loggers 'scan.text', 'scan.html' and 'scan.pdf'. Logger names can be
anything you want, and indicate the area of an application in which a
logged message originates.

  A good convention to use when naming loggers is to use a module-level
logger, in each module which uses logging, named as follows:

    logger = logging.getLogger(__name__)

This means that logger names track the package/module hierarchy, and
it's intuitively obvious where events are logged just from the logger
name.

  The root of the hierarchy of loggers is called the root logger.
That's the logger used by the functions `debug()', `info()',
`warning()', `error()' and `critical()', which just call the same-named
method of the root logger. The functions and the methods have the same
signatures. The root logger's name is printed as 'root' in the logged
output.

  It is, of course, possible to log messages to different destinations.
Support is included in the package for writing log messages to files,
HTTP GET/POST locations, email via SMTP, generic sockets, queues, or
OS-specific logging mechanisms such as syslog or the Windows NT event
log. Destinations are served by _handler_ classes. You can create your
own log destination class if you have special requirements not met by
any of the built-in handler classes.

  By default, no destination is set for any logging messages. You can
specify a destination (such as console or file) by using
`basicConfig()' as in the tutorial examples. If you call the functions
`debug()', `info()', `warning()', `error()' and `critical()', they will
check to see if no destination is set; and if one is not set, they will
set a destination of the console (`sys.stderr') and a default format
for the displayed message before delegating to the root logger to do
the actual message output.

  The default format set by `basicConfig()' for messages is:

    severity:logger name:message

You can change this by passing a format string to `basicConfig()' with
the _format_ keyword argument. For all options regarding how a format
string is constructed, see _formatter-objects_.

* Menu:

* Loggers::
* Handlers::
* Formatters::
* Configuring Logging::
* What happens if no configuration is provided::
* Configuring Logging for a Library::


File: python-howto-3.2.2.info,  Node: Loggers,  Next: Handlers,  Up: Advanced Logging Tutorial

7.2.1 Loggers
-------------

`Logger' objects have a threefold job.  First, they expose several
methods to application code so that applications can log messages at
runtime.  Second, logger objects determine which log messages to act
upon based upon severity (the default filtering facility) or filter
objects.  Third, logger objects pass along relevant log messages to all
interested log handlers.

  The most widely used methods on logger objects fall into two
categories: configuration and message sending.

  These are the most common configuration methods:

   * `Logger.setLevel()' specifies the lowest-severity log message a
     logger will handle, where debug is the lowest built-in severity
     level and critical is the highest built-in severity.  For example,
     if the severity level is INFO, the logger will handle only INFO,
     WARNING, ERROR, and CRITICAL messages and will ignore DEBUG
     messages.

   * `Logger.addHandler()' and `Logger.removeHandler()' add and remove
     handler objects from the logger object.  Handlers are covered in
     more detail in *note Handlers: 81.

   * `Logger.addFilter()' and `Logger.removeFilter()' add and remove
     filter objects from the logger object.  Filters are covered in
     more detail in _filter_.

  You don't need to always call these methods on every logger you
create. See the last two paragraphs in this section.

  With the logger object configured, the following methods create log
messages:

   * `Logger.debug()', `Logger.info()', `Logger.warning()',
     `Logger.error()', and `Logger.critical()' all create log records
     with a message and a level that corresponds to their respective
     method names. The message is actually a format string, which may
     contain the standard string substitution syntax of `%s', `%d',
     `%f', and so on.  The rest of their arguments is a list of objects
     that correspond with the substitution fields in the message.  With
     regard to `**kwargs', the logging methods care only about a
     keyword of `exc_info' and use it to determine whether to log
     exception information.

   * `Logger.exception()' creates a log message similar to
     `Logger.error()'.  The difference is that `Logger.exception()'
     dumps a stack trace along with it.  Call this method only from an
     exception handler.

   * `Logger.log()' takes a log level as an explicit argument.  This is
     a little more verbose for logging messages than using the log
     level convenience methods listed above, but this is how to log at
     custom log levels.

  `getLogger()' returns a reference to a logger instance with the
specified name if it is provided, or `root' if not.  The names are
period-separated hierarchical structures.  Multiple calls to
`getLogger()' with the same name will return a reference to the same
logger object.  Loggers that are further down in the hierarchical list
are children of loggers higher up in the list.  For example, given a
logger with a name of `foo', loggers with names of `foo.bar',
`foo.bar.baz', and `foo.bam' are all descendants of `foo'.

  Loggers have a concept of _effective level_. If a level is not
explicitly set on a logger, the level of its parent is used instead as
its effective level.  If the parent has no explicit level set, _its_
parent is examined, and so on - all ancestors are searched until an
explicitly set level is found. The root logger always has an explicit
level set (`WARNING' by default). When deciding whether to process an
event, the effective level of the logger is used to determine whether
the event is passed to the logger's handlers.

  Child loggers propagate messages up to the handlers associated with
their ancestor loggers. Because of this, it is unnecessary to define
and configure handlers for all the loggers an application uses. It is
sufficient to configure handlers for a top-level logger and create
child loggers as needed.  (You can, however, turn off propagation by
setting the _propagate_ attribute of a logger to _False_.)


File: python-howto-3.2.2.info,  Node: Handlers,  Next: Formatters,  Prev: Loggers,  Up: Advanced Logging Tutorial

7.2.2 Handlers
--------------

`Handler' objects are responsible for dispatching the appropriate log
messages (based on the log messages' severity) to the handler's
specified destination.  Logger objects can add zero or more handler
objects to themselves with an `addHandler()' method.  As an example
scenario, an application may want to send all log messages to a log
file, all log messages of error or higher to stdout, and all messages
of critical to an email address.  This scenario requires three
individual handlers where each handler is responsible for sending
messages of a specific severity to a specific location.

  The standard library includes quite a few handler types (see *note
Useful Handlers: 83.); the tutorials use mainly `StreamHandler' and
`FileHandler' in its examples.

  There are very few methods in a handler for application developers to
concern themselves with.  The only handler methods that seem relevant
for application developers who are using the built-in handler objects
(that is, not creating custom handlers) are the following configuration
methods:

   * The `Handler.setLevel()' method, just as in logger objects,
     specifies the lowest severity that will be dispatched to the
     appropriate destination.  Why are there two `setLevel()' methods?
     The level set in the logger determines which severity of messages
     it will pass to its handlers.  The level set in each handler
     determines which messages that handler will send on.

   * `setFormatter()' selects a Formatter object for this handler to
     use.

   * `addFilter()' and `removeFilter()' respectively configure and
     deconfigure filter objects on handlers.

  Application code should not directly instantiate and use instances of
`Handler'.  Instead, the `Handler' class is a base class that defines
the interface that all handlers should have and establishes some
default behavior that child classes can use (or override).


File: python-howto-3.2.2.info,  Node: Formatters,  Next: Configuring Logging,  Prev: Handlers,  Up: Advanced Logging Tutorial

7.2.3 Formatters
----------------

Formatter objects configure the final order, structure, and contents of
the log message.  Unlike the base `logging.Handler' class, application
code may instantiate formatter classes, although you could likely
subclass the formatter if your application needs special behavior.  The
constructor takes three optional arguments - a message format string, a
date format string and a style indicator.

 -- Method: logging.Formatter.__init__ (fmt=None, datefmt=None,
          style='%')

  If there is no message format string, the default is to use the raw
message.  If there is no date format string, the default date format is:

    %Y-%m-%d %H:%M:%S

with the milliseconds tacked on at the end. The `style' is one of `%',
'{' or '$'. If one of these is not specified, then '%' will be used.

  If the `style' is '%', the message format string uses `%(<dictionary
key>)s' styled string substitution; the possible keys are documented in
_logrecord-attributes_. If the style is '{', the message format string
is assumed to be compatible with `str.format()' (using keyword
arguments), while if the style is '$' then the message format string
should conform to what is expected by `string.Template.substitute()'.

  Changed in version 3.2: Added the `style' parameter.

  The following message format string will log the time in a
human-readable format, the severity of the message, and the contents of
the message, in that order:

    '%(asctime)s - %(levelname)s - %(message)s'

Formatters use a user-configurable function to convert the creation
time of a record to a tuple. By default, `time.localtime()' is used; to
change this for a particular formatter instance, set the `converter'
attribute of the instance to a function with the same signature as
`time.localtime()' or `time.gmtime()'. To change it for all formatters,
for example if you want all logging times to be shown in GMT, set the
`converter' attribute in the Formatter class (to `time.gmtime' for GMT
display).


File: python-howto-3.2.2.info,  Node: Configuring Logging,  Next: What happens if no configuration is provided,  Prev: Formatters,  Up: Advanced Logging Tutorial

7.2.4 Configuring Logging
-------------------------

Programmers can configure logging in three ways:

  1. Creating loggers, handlers, and formatters explicitly using Python
     code that calls the configuration methods listed above.

  2. Creating a logging config file and reading it using the
     `fileConfig()' function.

  3. Creating a dictionary of configuration information and passing it
     to the `dictConfig()' function.

  For the reference documentation on the last two options, see
_logging-config-api_.  The following example configures a very simple
logger, a console handler, and a simple formatter using Python code:

    import logging

    # create logger
    logger = logging.getLogger('simple_example')
    logger.setLevel(logging.DEBUG)

    # create console handler and set level to debug
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)

    # create formatter
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # add formatter to ch
    ch.setFormatter(formatter)

    # add ch to logger
    logger.addHandler(ch)

    # 'application' code
    logger.debug('debug message')
    logger.info('info message')
    logger.warn('warn message')
    logger.error('error message')
    logger.critical('critical message')

Running this module from the command line produces the following output:

    $ python simple_logging_module.py
    2005-03-19 15:10:26,618 - simple_example - DEBUG - debug message
    2005-03-19 15:10:26,620 - simple_example - INFO - info message
    2005-03-19 15:10:26,695 - simple_example - WARNING - warn message
    2005-03-19 15:10:26,697 - simple_example - ERROR - error message
    2005-03-19 15:10:26,773 - simple_example - CRITICAL - critical message

The following Python module creates a logger, handler, and formatter
nearly identical to those in the example listed above, with the only
difference being the names of the objects:

    import logging
    import logging.config

    logging.config.fileConfig('logging.conf')

    # create logger
    logger = logging.getLogger('simpleExample')

    # 'application' code
    logger.debug('debug message')
    logger.info('info message')
    logger.warn('warn message')
    logger.error('error message')
    logger.critical('critical message')

Here is the logging.conf file:

    [loggers]
    keys=root,simpleExample

    [handlers]
    keys=consoleHandler

    [formatters]
    keys=simpleFormatter

    [logger_root]
    level=DEBUG
    handlers=consoleHandler

    [logger_simpleExample]
    level=DEBUG
    handlers=consoleHandler
    qualname=simpleExample
    propagate=0

    [handler_consoleHandler]
    class=StreamHandler
    level=DEBUG
    formatter=simpleFormatter
    args=(sys.stdout,)

    [formatter_simpleFormatter]
    format=%(asctime)s - %(name)s - %(levelname)s - %(message)s
    datefmt=

The output is nearly identical to that of the non-config-file-based
example:

    $ python simple_logging_config.py
    2005-03-19 15:38:55,977 - simpleExample - DEBUG - debug message
    2005-03-19 15:38:55,979 - simpleExample - INFO - info message
    2005-03-19 15:38:56,054 - simpleExample - WARNING - warn message
    2005-03-19 15:38:56,055 - simpleExample - ERROR - error message
    2005-03-19 15:38:56,130 - simpleExample - CRITICAL - critical message

You can see that the config file approach has a few advantages over the
Python code approach, mainly separation of configuration and code and
the ability of noncoders to easily modify the logging properties.

  Note that the class names referenced in config files need to be
either relative to the logging module, or absolute values which can be
resolved using normal import mechanisms. Thus, you could use either
`WatchedFileHandler' (relative to the logging module) or
`mypackage.mymodule.MyHandler' (for a class defined in package
`mypackage' and module `mymodule', where `mypackage' is available on
the Python import path).

  In Python 3.2, a new means of configuring logging has been
introduced, using dictionaries to hold configuration information. This
provides a superset of the functionality of the config-file-based
approach outlined above, and is the recommended configuration method
for new applications and deployments. Because a Python dictionary is
used to hold configuration information, and since you can populate that
dictionary using different means, you have more options for
configuration. For example, you can use a configuration file in JSON
format, or, if you have access to YAML processing functionality, a file
in YAML format, to populate the configuration dictionary. Or, of
course, you can construct the dictionary in Python code, receive it in
pickled form over a socket, or use whatever approach makes sense for
your application.

  Here's an example of the same configuration as above, in YAML format
for the new dictionary-based approach:

    version: 1
    formatters:
      simple:
        format: format=%(asctime)s - %(name)s - %(levelname)s - %(message)s
    handlers:
      console:
        class: logging.StreamHandler
        level: DEBUG
        formatter: simple
        stream: ext://sys.stdout
    loggers:
      simpleExample:
        level: DEBUG
        handlers: [console]
        propagate: no
    root:
      level: DEBUG
      handlers: [console]

For more information about logging using a dictionary, see
_logging-config-api_.


File: python-howto-3.2.2.info,  Node: What happens if no configuration is provided,  Next: Configuring Logging for a Library,  Prev: Configuring Logging,  Up: Advanced Logging Tutorial

7.2.5 What happens if no configuration is provided
--------------------------------------------------

If no logging configuration is provided, it is possible to have a
situation where a logging event needs to be output, but no handlers can
be found to output the event. The behaviour of the logging package in
these circumstances is dependent on the Python version.

  For versions of Python prior to 3.2, the behaviour is as follows:

   * If _logging.raiseExceptions_ is _False_ (production mode), the
     event is silently dropped.

   * If _logging.raiseExceptions_ is _True_ (development mode), a
     message 'No handlers could be found for logger X.Y.Z' is printed
     once.

  In Python 3.2 and later, the behaviour is as follows:

   * The event is output using a 'handler of last resort', stored in
     `logging.lastResort'. This internal handler is not associated with
     any logger, and acts like a `StreamHandler' which writes the event
     description message to the current value of `sys.stderr' (therefore
     respecting any redirections which may be in effect). No formatting
     is done on the message - just the bare event description message
     is printed.  The handler's level is set to `WARNING', so all
     events at this and greater severities will be output.

  To obtain the pre-3.2 behaviour, `logging.lastResort' can be set to
_None_.


File: python-howto-3.2.2.info,  Node: Configuring Logging for a Library,  Prev: What happens if no configuration is provided,  Up: Advanced Logging Tutorial

7.2.6 Configuring Logging for a Library
---------------------------------------

When developing a library which uses logging, you should take care to
document how the library uses logging - for example, the names of
loggers used. Some consideration also needs to be given to its logging
configuration.  If the using application does not use logging, and
library code makes logging calls, then (as described in the previous
section) events of severity `WARNING' and greater will be printed to
`sys.stderr'. This is regarded as the best default behaviour.

  If for some reason you _don't_ want these messages printed in the
absence of any logging configuration, you can attach a do-nothing
handler to the top-level logger for your library. This avoids the
message being printed, since a handler will be always be found for the
library's events: it just doesn't produce any output. If the library
user configures logging for application use, presumably that
configuration will add some handlers, and if levels are suitably
configured then logging calls made in library code will send output to
those handlers, as normal.

  A do-nothing handler is included in the logging package:
`NullHandler' (since Python 3.1). An instance of this handler could be
added to the top-level logger of the logging namespace used by the
library (_if_ you want to prevent your library's logged events being
output to `sys.stderr' in the absence of logging configuration). If all
logging by a library _foo_ is done using loggers with names matching
'foo.x', 'foo.x.y', etc. then the code:

    import logging
    logging.getLogger('foo').addHandler(logging.NullHandler())

should have the desired effect. If an organisation produces a number of
libraries, then the logger name specified can be 'orgname.foo' rather
than just 'foo'.

  *PLEASE NOTE:* It is strongly advised that you _do not add any
handlers other than_ `NullHandler' _to your library's loggers_. This is
because the configuration of handlers is the prerogative of the
application developer who uses your library. The application developer
knows their target audience and what handlers are most appropriate for
their application: if you add handlers 'under the hood', you might well
interfere with their ability to carry out unit tests and deliver logs
which suit their requirements.


File: python-howto-3.2.2.info,  Node: Logging Levels,  Next: Useful Handlers,  Prev: Advanced Logging Tutorial,  Up: Logging HOWTO

7.3 Logging Levels
==================

The numeric values of logging levels are given in the following table.
These are primarily of interest if you want to define your own levels,
and need them to have specific values relative to the predefined
levels. If you define a level with the same numeric value, it
overwrites the predefined value; the predefined name is lost.

Level              Numeric value
--------------------------------------- 
`CRITICAL'         50
`ERROR'            40
`WARNING'          30
`INFO'             20
`DEBUG'            10
`NOTSET'           0

  Levels can also be associated with loggers, being set either by the
developer or through loading a saved logging configuration. When a
logging method is called on a logger, the logger compares its own level
with the level associated with the method call. If the logger's level
is higher than the method call's, no logging message is actually
generated. This is the basic mechanism controlling the verbosity of
logging output.

  Logging messages are encoded as instances of the `LogRecord' class.
When a logger decides to actually log an event, a `LogRecord' instance
is created from the logging message.

  Logging messages are subjected to a dispatch mechanism through the
use of _handlers_, which are instances of subclasses of the `Handler'
class. Handlers are responsible for ensuring that a logged message (in
the form of a `LogRecord') ends up in a particular location (or set of
locations) which is useful for the target audience for that message
(such as end users, support desk staff, system administrators,
developers). Handlers are passed `LogRecord' instances intended for
particular destinations. Each logger can have zero, one or more
handlers associated with it (via the `addHandler()' method of
`Logger'). In addition to any handlers directly associated with a
logger, _all handlers associated with all ancestors of the logger_ are
called to dispatch the message (unless the _propagate_ flag for a
logger is set to a false value, at which point the passing to ancestor
handlers stops).

  Just as for loggers, handlers can have levels associated with them. A
handler's level acts as a filter in the same way as a logger's level
does. If a handler decides to actually dispatch an event, the `emit()'
method is used to send the message to its destination. Most
user-defined subclasses of `Handler' will need to override this
`emit()'.

* Menu:

* Custom Levels::


File: python-howto-3.2.2.info,  Node: Custom Levels,  Up: Logging Levels

7.3.1 Custom Levels
-------------------

Defining your own levels is possible, but should not be necessary, as
the existing levels have been chosen on the basis of practical
experience.  However, if you are convinced that you need custom levels,
great care should be exercised when doing this, and it is possibly _a
very bad idea to define custom levels if you are developing a library_.
That's because if multiple library authors all define their own custom
levels, there is a chance that the logging output from such multiple
libraries used together will be difficult for the using developer to
control and/or interpret, because a given numeric value might mean
different things for different libraries.


File: python-howto-3.2.2.info,  Node: Useful Handlers,  Next: Exceptions raised during logging,  Prev: Logging Levels,  Up: Logging HOWTO

7.4 Useful Handlers
===================

In addition to the base `Handler' class, many useful subclasses are
provided:

  1. `StreamHandler' instances send messages to streams (file-like
     objects).

  2. `FileHandler' instances send messages to disk files.

  3. `BaseRotatingHandler' is the base class for handlers that rotate
     log files at a certain point. It is not meant to be  instantiated
     directly. Instead, use `RotatingFileHandler' or
     `TimedRotatingFileHandler'.

  4. `RotatingFileHandler' instances send messages to disk files, with
     support for maximum log file sizes and log file rotation.

  5. `TimedRotatingFileHandler' instances send messages to disk files,
     rotating the log file at certain timed intervals.

  6. `SocketHandler' instances send messages to TCP/IP sockets.

  7. `DatagramHandler' instances send messages to UDP sockets.

  8. `SMTPHandler' instances send messages to a designated email
     address.

  9. `SysLogHandler' instances send messages to a Unix syslog daemon,
     possibly on a remote machine.

 10. `NTEventLogHandler' instances send messages to a Windows
     NT/2000/XP event log.

 11. `MemoryHandler' instances send messages to a buffer in memory,
     which is flushed whenever specific criteria are met.

 12. `HTTPHandler' instances send messages to an HTTP server using
     either `GET' or `POST' semantics.

 13. `WatchedFileHandler' instances watch the file they are logging to.
     If the file changes, it is closed and reopened using the file
     name. This handler is only useful on Unix-like systems; Windows
     does not support the underlying mechanism used.

 14. `QueueHandler' instances send messages to a queue, such as those
     implemented in the `queue' or `multiprocessing' modules.

 15. `NullHandler' instances do nothing with error messages. They are
     used by library developers who want to use logging, but want to
     avoid the 'No handlers could be found for logger XXX' message
     which can be displayed if the library user has not configured
     logging. See *note Configuring Logging for a Library: 88. for more
     information.

  New in version 3.1: The `NullHandler' class.

  New in version 3.2: The `QueueHandler' class.

  The `NullHandler', `StreamHandler' and `FileHandler' classes are
defined in the core logging package. The other handlers are defined in
a sub- module, `logging.handlers'. (There is also another sub-module,
`logging.config', for configuration functionality.)

  Logged messages are formatted for presentation through instances of
the `Formatter' class. They are initialized with a format string
suitable for use with the % operator and a dictionary.

  For formatting multiple messages in a batch, instances of
`BufferingFormatter' can be used. In addition to the format string
(which is applied to each message in the batch), there is provision for
header and trailer format strings.

  When filtering based on logger level and/or handler level is not
enough, instances of `Filter' can be added to both `Logger' and
`Handler' instances (through their `addFilter()' method). Before
deciding to process a message further, both loggers and handlers
consult all their filters for permission. If any filter returns a false
value, the message is not processed further.

  The basic `Filter' functionality allows filtering by specific logger
name. If this feature is used, messages sent to the named logger and its
children are allowed through the filter, and all others dropped.


File: python-howto-3.2.2.info,  Node: Exceptions raised during logging,  Next: Using arbitrary objects as messages,  Prev: Useful Handlers,  Up: Logging HOWTO

7.5 Exceptions raised during logging
====================================

The logging package is designed to swallow exceptions which occur while
logging in production. This is so that errors which occur while
handling logging events - such as logging misconfiguration, network or
other similar errors - do not cause the application using logging to
terminate prematurely.

  `SystemExit' and `KeyboardInterrupt' exceptions are never swallowed.
Other exceptions which occur during the `emit()' method of a `Handler'
subclass are passed to its `handleError()' method.

  The default implementation of `handleError()' in `Handler' checks to
see if a module-level variable, `raiseExceptions', is set. If set, a
traceback is printed to `sys.stderr'. If not set, the exception is
swallowed.

  *Note_* The default value of `raiseExceptions' is `True'. This is
because during development, you typically want to be notified of any
exceptions that occur. It's advised that you set `raiseExceptions' to
`False' for production usage.


File: python-howto-3.2.2.info,  Node: Using arbitrary objects as messages,  Next: Optimization,  Prev: Exceptions raised during logging,  Up: Logging HOWTO

7.6 Using arbitrary objects as messages
=======================================

In the preceding sections and examples, it has been assumed that the
message passed when logging the event is a string. However, this is not
the only possibility. You can pass an arbitrary object as a message,
and its `__str__()' method will be called when the logging system needs
to convert it to a string representation. In fact, if you want to, you
can avoid computing a string representation altogether - for example,
the `SocketHandler' emits an event by pickling it and sending it over
the wire.


File: python-howto-3.2.2.info,  Node: Optimization,  Prev: Using arbitrary objects as messages,  Up: Logging HOWTO

7.7 Optimization
================

Formatting of message arguments is deferred until it cannot be avoided.
However, computing the arguments passed to the logging method can also
be expensive, and you may want to avoid doing it if the logger will
just throw away your event. To decide what to do, you can call the
`isEnabledFor()' method which takes a level argument and returns true
if the event would be created by the Logger for that level of call. You
can write code like this:

    if logger.isEnabledFor(logging.DEBUG):
        logger.debug('Message with %s, %s', expensive_func1(),
                                            expensive_func2())

so that if the logger's threshold is set above `DEBUG', the calls to
`expensive_func1()' and `expensive_func2()' are never made.

  There are other optimizations which can be made for specific
applications which need more precise control over what logging
information is collected. Here's a list of things you can do to avoid
processing during logging which you don't need:

What you don't want to collect                      How to avoid collecting it
------------------------------------------------------------------------------------------------- 
Information about where calls were made from.       Set `logging._srcfile' to `None'.
Threading information.                              Set `logging.logThreads' to `0'.
Process information.                                Set `logging.logProcesses' to `0'.

  Also note that the core logging module only includes the basic
handlers. If you don't import `logging.handlers' and `logging.config',
they won't take up any memory.

See also
........

Module `logging'
     API reference for the logging module.

Module `logging.config'
     Configuration API for the logging module.

Module `logging.handlers'
     Useful handlers included with the logging module.

  *note A logging cookbook: 7e.


File: python-howto-3.2.2.info,  Node: Logging Cookbook,  Next: Regular Expression HOWTO,  Prev: Logging HOWTO,  Up: Top

8 Logging Cookbook
******************

     Author: Vinay Sajip <vinay_sajip at red-dove dot com>

  This page contains a number of recipes related to logging, which have
been found useful in the past.

* Menu:

* Using logging in multiple modules::
* Multiple handlers and formatters::
* Logging to multiple destinations::
* Configuration server example::
* Dealing with handlers that block::
* Sending and receiving logging events across a network::
* Adding contextual information to your logging output::
* Logging to a single file from multiple processes::
* Using file rotation::
* Subclassing QueueHandler - a ZeroMQ example::
* Subclassing QueueListener - a ZeroMQ example::


File: python-howto-3.2.2.info,  Node: Using logging in multiple modules,  Next: Multiple handlers and formatters,  Up: Logging Cookbook

8.1 Using logging in multiple modules
=====================================

Multiple calls to `logging.getLogger('someLogger')' return a reference
to the same logger object.  This is true not only within the same
module, but also across modules as long as it is in the same Python
interpreter process.  It is true for references to the same object;
additionally, application code can define and configure a parent logger
in one module and create (but not configure) a child logger in a
separate module, and all logger calls to the child will pass up to the
parent.  Here is a main module:

    import logging
    import auxiliary_module

    # create logger with 'spam_application'
    logger = logging.getLogger('spam_application')
    logger.setLevel(logging.DEBUG)
    # create file handler which logs even debug messages
    fh = logging.FileHandler('spam.log')
    fh.setLevel(logging.DEBUG)
    # create console handler with a higher log level
    ch = logging.StreamHandler()
    ch.setLevel(logging.ERROR)
    # create formatter and add it to the handlers
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    fh.setFormatter(formatter)
    ch.setFormatter(formatter)
    # add the handlers to the logger
    logger.addHandler(fh)
    logger.addHandler(ch)

    logger.info('creating an instance of auxiliary_module.Auxiliary')
    a = auxiliary_module.Auxiliary()
    logger.info('created an instance of auxiliary_module.Auxiliary')
    logger.info('calling auxiliary_module.Auxiliary.do_something')
    a.do_something()
    logger.info('finished auxiliary_module.Auxiliary.do_something')
    logger.info('calling auxiliary_module.some_function()')
    auxiliary_module.some_function()
    logger.info('done with auxiliary_module.some_function()')

Here is the auxiliary module:

    import logging

    # create logger
    module_logger = logging.getLogger('spam_application.auxiliary')

    class Auxiliary:
        def __init__(self):
            self.logger = logging.getLogger('spam_application.auxiliary.Auxiliary')
            self.logger.info('creating an instance of Auxiliary')
        def do_something(self):
            self.logger.info('doing something')
            a = 1 + 1
            self.logger.info('done doing something')

    def some_function():
        module_logger.info('received a call to "some_function"')

The output looks like this:

    2005-03-23 23:47:11,663 - spam_application - INFO -
       creating an instance of auxiliary_module.Auxiliary
    2005-03-23 23:47:11,665 - spam_application.auxiliary.Auxiliary - INFO -
       creating an instance of Auxiliary
    2005-03-23 23:47:11,665 - spam_application - INFO -
       created an instance of auxiliary_module.Auxiliary
    2005-03-23 23:47:11,668 - spam_application - INFO -
       calling auxiliary_module.Auxiliary.do_something
    2005-03-23 23:47:11,668 - spam_application.auxiliary.Auxiliary - INFO -
       doing something
    2005-03-23 23:47:11,669 - spam_application.auxiliary.Auxiliary - INFO -
       done doing something
    2005-03-23 23:47:11,670 - spam_application - INFO -
       finished auxiliary_module.Auxiliary.do_something
    2005-03-23 23:47:11,671 - spam_application - INFO -
       calling auxiliary_module.some_function()
    2005-03-23 23:47:11,672 - spam_application.auxiliary - INFO -
       received a call to 'some_function'
    2005-03-23 23:47:11,673 - spam_application - INFO -
       done with auxiliary_module.some_function()



File: python-howto-3.2.2.info,  Node: Multiple handlers and formatters,  Next: Logging to multiple destinations,  Prev: Using logging in multiple modules,  Up: Logging Cookbook

8.2 Multiple handlers and formatters
====================================

Loggers are plain Python objects.  The `addHandler()' method has no
minimum or maximum quota for the number of handlers you may add.
Sometimes it will be beneficial for an application to log all messages
of all severities to a text file while simultaneously logging errors or
above to the console.  To set this up, simply configure the appropriate
handlers.  The logging calls in the application code will remain
unchanged.  Here is a slight modification to the previous simple
module-based configuration example:

    import logging

    logger = logging.getLogger('simple_example')
    logger.setLevel(logging.DEBUG)
    # create file handler which logs even debug messages
    fh = logging.FileHandler('spam.log')
    fh.setLevel(logging.DEBUG)
    # create console handler with a higher log level
    ch = logging.StreamHandler()
    ch.setLevel(logging.ERROR)
    # create formatter and add it to the handlers
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    ch.setFormatter(formatter)
    fh.setFormatter(formatter)
    # add the handlers to logger
    logger.addHandler(ch)
    logger.addHandler(fh)

    # 'application' code
    logger.debug('debug message')
    logger.info('info message')
    logger.warn('warn message')
    logger.error('error message')
    logger.critical('critical message')

Notice that the 'application' code does not care about multiple
handlers.  All that changed was the addition and configuration of a new
handler named _fh_.

  The ability to create new handlers with higher- or lower-severity
filters can be very helpful when writing and testing an application.
Instead of using many `print' statements for debugging, use
`logger.debug': Unlike the print statements, which you will have to
delete or comment out later, the logger.debug statements can remain
intact in the source code and remain dormant until you need them again.
At that time, the only change that needs to happen is to modify the
severity level of the logger and/or handler to debug.


File: python-howto-3.2.2.info,  Node: Logging to multiple destinations,  Next: Configuration server example,  Prev: Multiple handlers and formatters,  Up: Logging Cookbook

8.3 Logging to multiple destinations
====================================

Let's say you want to log to console and file with different message
formats and in differing circumstances. Say you want to log messages
with levels of DEBUG and higher to file, and those messages at level
INFO and higher to the console.  Let's also assume that the file should
contain timestamps, but the console messages should not. Here's how you
can achieve this:

    import logging

    # set up logging to file - see previous section for more details
    logging.basicConfig(level=logging.DEBUG,
                        format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',
                        datefmt='%m-%d %H:%M',
                        filename='/temp/myapp.log',
                        filemode='w')
    # define a Handler which writes INFO messages or higher to the sys.stderr
    console = logging.StreamHandler()
    console.setLevel(logging.INFO)
    # set a format which is simpler for console use
    formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')
    # tell the handler to use this format
    console.setFormatter(formatter)
    # add the handler to the root logger
    logging.getLogger('').addHandler(console)

    # Now, we can log to the root logger, or any other logger. First the root...
    logging.info('Jackdaws love my big sphinx of quartz.')

    # Now, define a couple of other loggers which might represent areas in your
    # application:

    logger1 = logging.getLogger('myapp.area1')
    logger2 = logging.getLogger('myapp.area2')

    logger1.debug('Quick zephyrs blow, vexing daft Jim.')
    logger1.info('How quickly daft jumping zebras vex.')
    logger2.warning('Jail zesty vixen who grabbed pay from quack.')
    logger2.error('The five boxing wizards jump quickly.')

When you run this, on the console you will see

    root        : INFO     Jackdaws love my big sphinx of quartz.
    myapp.area1 : INFO     How quickly daft jumping zebras vex.
    myapp.area2 : WARNING  Jail zesty vixen who grabbed pay from quack.
    myapp.area2 : ERROR    The five boxing wizards jump quickly.

and in the file you will see something like

    10-22 22:19 root         INFO     Jackdaws love my big sphinx of quartz.
    10-22 22:19 myapp.area1  DEBUG    Quick zephyrs blow, vexing daft Jim.
    10-22 22:19 myapp.area1  INFO     How quickly daft jumping zebras vex.
    10-22 22:19 myapp.area2  WARNING  Jail zesty vixen who grabbed pay from quack.
    10-22 22:19 myapp.area2  ERROR    The five boxing wizards jump quickly.

As you can see, the DEBUG message only shows up in the file. The other
messages are sent to both destinations.

  This example uses console and file handlers, but you can use any
number and combination of handlers you choose.


File: python-howto-3.2.2.info,  Node: Configuration server example,  Next: Dealing with handlers that block,  Prev: Logging to multiple destinations,  Up: Logging Cookbook

8.4 Configuration server example
================================

Here is an example of a module using the logging configuration server:

    import logging
    import logging.config
    import time
    import os

    # read initial config file
    logging.config.fileConfig('logging.conf')

    # create and start listener on port 9999
    t = logging.config.listen(9999)
    t.start()

    logger = logging.getLogger('simpleExample')

    try:
        # loop through logging calls to see the difference
        # new configurations make, until Ctrl+C is pressed
        while True:
            logger.debug('debug message')
            logger.info('info message')
            logger.warn('warn message')
            logger.error('error message')
            logger.critical('critical message')
            time.sleep(5)
    except KeyboardInterrupt:
        # cleanup
        logging.config.stopListening()
        t.join()

And here is a script that takes a filename and sends that file to the
server, properly preceded with the binary-encoded length, as the new
logging configuration:

    #!/usr/bin/env python
    import socket, sys, struct

    with open(sys.argv[1], 'rb') as f:
        data_to_send = f.read()

    HOST = 'localhost'
    PORT = 9999
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    print('connecting...')
    s.connect((HOST, PORT))
    print('sending config...')
    s.send(struct.pack('>L', len(data_to_send)))
    s.send(data_to_send)
    s.close()
    print('complete')



File: python-howto-3.2.2.info,  Node: Dealing with handlers that block,  Next: Sending and receiving logging events across a network,  Prev: Configuration server example,  Up: Logging Cookbook

8.5 Dealing with handlers that block
====================================

Sometimes you have to get your logging handlers to do their work without
blocking the thread youre logging from. This is common in Web
applications, though of course it also occurs in other scenarios.

  A common culprit which demonstrates sluggish behaviour is the
`SMTPHandler': sending emails can take a long time, for a number of
reasons outside the developers control (for example, a poorly
performing mail or network infrastructure). But almost any network-based
handler can block: Even a `SocketHandler' operation may do a DNS query
under the hood which is too slow (and this query can be deep in the
socket library code, below the Python layer, and outside your control).

  One solution is to use a two-part approach. For the first part,
attach only a `QueueHandler' to those loggers which are accessed from
performance-critical threads. They simply write to their queue, which
can be sized to a large enough capacity or initialized with no upper
bound to their size. The write to the queue will typically be accepted
quickly, though you will probably need to catch the `queue.Full'
exception as a precaution in your code. If you are a library developer
who has performance-critical threads in their code, be sure to document
this (together with a suggestion to attach only `QueueHandlers' to your
loggers) for the benefit of other developers who will use your code.

  The second part of the solution is `QueueListener', which has been
designed as the counterpart to `QueueHandler'.  A `QueueListener' is
very simple: its passed a queue and some handlers, and it fires up an
internal thread which listens to its queue for LogRecords sent from
`QueueHandlers' (or any other source of `LogRecords', for that matter).
The `LogRecords' are removed from the queue and passed to the handlers
for processing.

  The advantage of having a separate `QueueListener' class is that you
can use the same instance to service multiple `QueueHandlers'. This is
more resource-friendly than, say, having threaded versions of the
existing handler classes, which would eat up one thread per handler for
no particular benefit.

  An example of using these two classes follows (imports omitted):

    que = queue.Queue(-1) # no limit on size
    queue_handler = QueueHandler(que)
    handler = logging.StreamHandler()
    listener = QueueListener(que, handler)
    root = logging.getLogger()
    root.addHandler(queue_handler)
    formatter = logging.Formatter('%(threadName)s: %(message)s')
    handler.setFormatter(formatter)
    listener.start()
    # The log output will display the thread which generated
    # the event (the main thread) rather than the internal
    # thread which monitors the internal queue. This is what
    # you want to happen.
    root.warning('Look out!')
    listener.stop()

which, when run, will produce:

    MainThread: Look out!



File: python-howto-3.2.2.info,  Node: Sending and receiving logging events across a network,  Next: Adding contextual information to your logging output,  Prev: Dealing with handlers that block,  Up: Logging Cookbook

8.6 Sending and receiving logging events across a network
=========================================================

Let's say you want to send logging events across a network, and handle
them at the receiving end. A simple way of doing this is attaching a
`SocketHandler' instance to the root logger at the sending end:

    import logging, logging.handlers

    rootLogger = logging.getLogger('')
    rootLogger.setLevel(logging.DEBUG)
    socketHandler = logging.handlers.SocketHandler('localhost',
                        logging.handlers.DEFAULT_TCP_LOGGING_PORT)
    # don't bother with a formatter, since a socket handler sends the event as
    # an unformatted pickle
    rootLogger.addHandler(socketHandler)

    # Now, we can log to the root logger, or any other logger. First the root...
    logging.info('Jackdaws love my big sphinx of quartz.')

    # Now, define a couple of other loggers which might represent areas in your
    # application:

    logger1 = logging.getLogger('myapp.area1')
    logger2 = logging.getLogger('myapp.area2')

    logger1.debug('Quick zephyrs blow, vexing daft Jim.')
    logger1.info('How quickly daft jumping zebras vex.')
    logger2.warning('Jail zesty vixen who grabbed pay from quack.')
    logger2.error('The five boxing wizards jump quickly.')

At the receiving end, you can set up a receiver using the `socketserver'
module. Here is a basic working example:

    import pickle
    import logging
    import logging.handlers
    import socketserver
    import struct


    class LogRecordStreamHandler(socketserver.StreamRequestHandler):
        """Handler for a streaming logging request.

        This basically logs the record using whatever logging policy is
        configured locally.
        """

        def handle(self):
            """
            Handle multiple requests - each expected to be a 4-byte length,
            followed by the LogRecord in pickle format. Logs the record
            according to whatever policy is configured locally.
            """
            while True:
                chunk = self.connection.recv(4)
                if len(chunk) < 4:
                    break
                slen = struct.unpack('>L', chunk)[0]
                chunk = self.connection.recv(slen)
                while len(chunk) < slen:
                    chunk = chunk + self.connection.recv(slen - len(chunk))
                obj = self.unPickle(chunk)
                record = logging.makeLogRecord(obj)
                self.handleLogRecord(record)

        def unPickle(self, data):
            return pickle.loads(data)

        def handleLogRecord(self, record):
            # if a name is specified, we use the named logger rather than the one
            # implied by the record.
            if self.server.logname is not None:
                name = self.server.logname
            else:
                name = record.name
            logger = logging.getLogger(name)
            # N.B. EVERY record gets logged. This is because Logger.handle
            # is normally called AFTER logger-level filtering. If you want
            # to do filtering, do it at the client end to save wasting
            # cycles and network bandwidth!
            logger.handle(record)

    class LogRecordSocketReceiver(socketserver.ThreadingTCPServer):
        """
        Simple TCP socket-based logging receiver suitable for testing.
        """

        allow_reuse_address = 1

        def __init__(self, host='localhost',
                     port=logging.handlers.DEFAULT_TCP_LOGGING_PORT,
                     handler=LogRecordStreamHandler):
            socketserver.ThreadingTCPServer.__init__(self, (host, port), handler)
            self.abort = 0
            self.timeout = 1
            self.logname = None

        def serve_until_stopped(self):
            import select
            abort = 0
            while not abort:
                rd, wr, ex = select.select([self.socket.fileno()],
                                           [], [],
                                           self.timeout)
                if rd:
                    self.handle_request()
                abort = self.abort

    def main():
        logging.basicConfig(
            format='%(relativeCreated)5d %(name)-15s %(levelname)-8s %(message)s')
        tcpserver = LogRecordSocketReceiver()
        print('About to start TCP server...')
        tcpserver.serve_until_stopped()

    if __name__ == '__main__':
        main()

First run the server, and then the client. On the client side, nothing
is printed on the console; on the server side, you should see something
like:

    About to start TCP server...
       59 root            INFO     Jackdaws love my big sphinx of quartz.
       59 myapp.area1     DEBUG    Quick zephyrs blow, vexing daft Jim.
       69 myapp.area1     INFO     How quickly daft jumping zebras vex.
       69 myapp.area2     WARNING  Jail zesty vixen who grabbed pay from quack.
       69 myapp.area2     ERROR    The five boxing wizards jump quickly.

Note that there are some security issues with pickle in some scenarios.
If these affect you, you can use an alternative serialization scheme by
overriding the `makePickle()' method and implementing your alternative
there, as well as adapting the above script to use your alternative
serialization.


File: python-howto-3.2.2.info,  Node: Adding contextual information to your logging output,  Next: Logging to a single file from multiple processes,  Prev: Sending and receiving logging events across a network,  Up: Logging Cookbook

8.7 Adding contextual information to your logging output
========================================================

Sometimes you want logging output to contain contextual information in
addition to the parameters passed to the logging call. For example, in a
networked application, it may be desirable to log client-specific
information in the log (e.g. remote client's username, or IP address).
Although you could use the _extra_ parameter to achieve this, it's not
always convenient to pass the information in this way. While it might
be tempting to create `Logger' instances on a per-connection basis,
this is not a good idea because these instances are not garbage
collected. While this is not a problem in practice, when the number of
`Logger' instances is dependent on the level of granularity you want to
use in logging an application, it could be hard to manage if the number
of `Logger' instances becomes effectively unbounded.

* Menu:

* Using LoggerAdapters to impart contextual information::
* Using Filters to impart contextual information::


File: python-howto-3.2.2.info,  Node: Using LoggerAdapters to impart contextual information,  Next: Using Filters to impart contextual information,  Up: Adding contextual information to your logging output

8.7.1 Using LoggerAdapters to impart contextual information
-----------------------------------------------------------

An easy way in which you can pass contextual information to be output
along with logging event information is to use the `LoggerAdapter'
class.  This class is designed to look like a `Logger', so that you can
call `debug()', `info()', `warning()', `error()', `exception()',
`critical()' and `log()'. These methods have the same signatures as
their counterparts in `Logger', so you can use the two types of
instances interchangeably.

  When you create an instance of `LoggerAdapter', you pass it a
`Logger' instance and a dict-like object which contains your contextual
information. When you call one of the logging methods on an instance of
`LoggerAdapter', it delegates the call to the underlying instance of
`Logger' passed to its constructor, and arranges to pass the contextual
information in the delegated call. Here's a snippet from the code of
`LoggerAdapter':

    def debug(self, msg, *args, **kwargs):
        """
        Delegate a debug call to the underlying logger, after adding
        contextual information from this adapter instance.
        """
        msg, kwargs = self.process(msg, kwargs)
        self.logger.debug(msg, *args, **kwargs)

The `process()' method of `LoggerAdapter' is where the contextual
information is added to the logging output. It's passed the message and
keyword arguments of the logging call, and it passes back (potentially)
modified versions of these to use in the call to the underlying logger.
The default implementation of this method leaves the message alone, but
inserts an 'extra' key in the keyword argument whose value is the
dict-like object passed to the constructor. Of course, if you had
passed an 'extra' keyword argument in the call to the adapter, it will
be silently overwritten.

  The advantage of using 'extra' is that the values in the dict-like
object are merged into the `LogRecord' instance's __dict__, allowing
you to use customized strings with your `Formatter' instances which
know about the keys of the dict-like object. If you need a different
method, e.g. if you want to prepend or append the contextual
information to the message string, you just need to subclass
`LoggerAdapter' and override `process()' to do what you need. Here's an
example script which uses this class, which also illustrates what
dict-like behaviour is needed from an arbitrary 'dict-like' object for
use in the constructor:

    import logging

    class ConnInfo:
        """
        An example class which shows how an arbitrary class can be used as
        the 'extra' context information repository passed to a LoggerAdapter.
        """

        def __getitem__(self, name):
            """
            To allow this instance to look like a dict.
            """
            from random import choice
            if name == 'ip':
                result = choice(['127.0.0.1', '192.168.0.1'])
            elif name == 'user':
                result = choice(['jim', 'fred', 'sheila'])
            else:
                result = self.__dict__.get(name, '?')
            return result

        def __iter__(self):
            """
            To allow iteration over keys, which will be merged into
            the LogRecord dict before formatting and output.
            """
            keys = ['ip', 'user']
            keys.extend(self.__dict__.keys())
            return keys.__iter__()

    if __name__ == '__main__':
        from random import choice
        levels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.CRITICAL)
        a1 = logging.LoggerAdapter(logging.getLogger('a.b.c'),
                                   { 'ip' : '123.231.231.123', 'user' : 'sheila' })
        logging.basicConfig(level=logging.DEBUG,
                            format='%(asctime)-15s %(name)-5s %(levelname)-8s IP: %(ip)-15s User: %(user)-8s %(message)s')
        a1.debug('A debug message')
        a1.info('An info message with %s', 'some parameters')
        a2 = logging.LoggerAdapter(logging.getLogger('d.e.f'), ConnInfo())
        for x in range(10):
            lvl = choice(levels)
            lvlname = logging.getLevelName(lvl)
            a2.log(lvl, 'A message at %s level with %d %s', lvlname, 2, 'parameters')

When this script is run, the output should look something like this:

    2008-01-18 14:49:54,023 a.b.c DEBUG    IP: 123.231.231.123 User: sheila   A debug message
    2008-01-18 14:49:54,023 a.b.c INFO     IP: 123.231.231.123 User: sheila   An info message with some parameters
    2008-01-18 14:49:54,023 d.e.f CRITICAL IP: 192.168.0.1     User: jim      A message at CRITICAL level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f INFO     IP: 192.168.0.1     User: jim      A message at INFO level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f WARNING  IP: 192.168.0.1     User: sheila   A message at WARNING level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f ERROR    IP: 127.0.0.1       User: fred     A message at ERROR level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f ERROR    IP: 127.0.0.1       User: sheila   A message at ERROR level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f WARNING  IP: 192.168.0.1     User: sheila   A message at WARNING level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f WARNING  IP: 192.168.0.1     User: jim      A message at WARNING level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f INFO     IP: 192.168.0.1     User: fred     A message at INFO level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f WARNING  IP: 192.168.0.1     User: sheila   A message at WARNING level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f WARNING  IP: 127.0.0.1       User: jim      A message at WARNING level with 2 parameters



File: python-howto-3.2.2.info,  Node: Using Filters to impart contextual information,  Prev: Using LoggerAdapters to impart contextual information,  Up: Adding contextual information to your logging output

8.7.2 Using Filters to impart contextual information
----------------------------------------------------

You can also add contextual information to log output using a
user-defined `Filter'. `Filter' instances are allowed to modify the
`LogRecords' passed to them, including adding additional attributes
which can then be output using a suitable format string, or if needed a
custom `Formatter'.

  For example in a web application, the request being processed (or at
least, the interesting parts of it) can be stored in a threadlocal
(`threading.local') variable, and then accessed from a `Filter' to add,
say, information from the request - say, the remote IP address and
remote user's username - to the `LogRecord', using the attribute names
'ip' and 'user' as in the `LoggerAdapter' example above. In that case,
the same format string can be used to get similar output to that shown
above. Here's an example script:

    import logging
    from random import choice

    class ContextFilter(logging.Filter):
        """
        This is a filter which injects contextual information into the log.

        Rather than use actual contextual information, we just use random
        data in this demo.
        """

        USERS = ['jim', 'fred', 'sheila']
        IPS = ['123.231.231.123', '127.0.0.1', '192.168.0.1']

        def filter(self, record):

            record.ip = choice(ContextFilter.IPS)
            record.user = choice(ContextFilter.USERS)
            return True

    if __name__ == '__main__':
       levels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.CRITICAL)
       logging.basicConfig(level=logging.DEBUG,
                           format='%(asctime)-15s %(name)-5s %(levelname)-8s IP: %(ip)-15s User: %(user)-8s %(message)s')
       a1 = logging.getLogger('a.b.c')
       a2 = logging.getLogger('d.e.f')

       f = ContextFilter()
       a1.addFilter(f)
       a2.addFilter(f)
       a1.debug('A debug message')
       a1.info('An info message with %s', 'some parameters')
       for x in range(10):
           lvl = choice(levels)
           lvlname = logging.getLevelName(lvl)
           a2.log(lvl, 'A message at %s level with %d %s', lvlname, 2, 'parameters')

which, when run, produces something like:

    2010-09-06 22:38:15,292 a.b.c DEBUG    IP: 123.231.231.123 User: fred     A debug message
    2010-09-06 22:38:15,300 a.b.c INFO     IP: 192.168.0.1     User: sheila   An info message with some parameters
    2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1       User: sheila   A message at CRITICAL level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f ERROR    IP: 127.0.0.1       User: jim      A message at ERROR level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f DEBUG    IP: 127.0.0.1       User: sheila   A message at DEBUG level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f ERROR    IP: 123.231.231.123 User: fred     A message at ERROR level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 192.168.0.1     User: jim      A message at CRITICAL level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1       User: sheila   A message at CRITICAL level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f DEBUG    IP: 192.168.0.1     User: jim      A message at DEBUG level with 2 parameters
    2010-09-06 22:38:15,301 d.e.f ERROR    IP: 127.0.0.1       User: sheila   A message at ERROR level with 2 parameters
    2010-09-06 22:38:15,301 d.e.f DEBUG    IP: 123.231.231.123 User: fred     A message at DEBUG level with 2 parameters
    2010-09-06 22:38:15,301 d.e.f INFO     IP: 123.231.231.123 User: fred     A message at INFO level with 2 parameters



File: python-howto-3.2.2.info,  Node: Logging to a single file from multiple processes,  Next: Using file rotation,  Prev: Adding contextual information to your logging output,  Up: Logging Cookbook

8.8 Logging to a single file from multiple processes
====================================================

Although logging is thread-safe, and logging to a single file from
multiple threads in a single process _is_ supported, logging to a
single file from _multiple processes_ is _not_ supported, because there
is no standard way to serialize access to a single file across multiple
processes in Python. If you need to log to a single file from multiple
processes, one way of doing this is to have all the processes log to a
`SocketHandler', and have a separate process which implements a socket
server which reads from the socket and logs to file. (If you prefer,
you can dedicate one thread in one of the existing processes to perform
this function.) The following section documents this approach in more
detail and includes a working socket receiver which can be used as a
starting point for you to adapt in your own applications.

  If you are using a recent version of Python which includes the
`multiprocessing' module, you could write your own handler which uses
the `Lock' class from this module to serialize access to the file from
your processes. The existing `FileHandler' and subclasses do not make
use of `multiprocessing' at present, though they may do so in the
future.  Note that at present, the `multiprocessing' module does not
provide working lock functionality on all platforms (see
<http://bugs.python.org/issue3770>).

  Alternatively, you can use a `Queue' and a `QueueHandler' to send all
logging events to one of the processes in your multi-process
application.  The following example script demonstrates how you can do
this; in the example a separate listener process listens for events
sent by other processes and logs them according to its own logging
configuration. Although the example only demonstrates one way of doing
it (for example, you may want to use a listener thread rather than a
separate listener process - the implementation would be analogous) it
does allow for completely different logging configurations for the
listener and the other processes in your application, and can be used as
the basis for code meeting your own specific requirements:

    # You'll need these imports in your own code
    import logging
    import logging.handlers
    import multiprocessing

    # Next two import lines for this demo only
    from random import choice, random
    import time

    #
    # Because you'll want to define the logging configurations for listener and workers, the
    # listener and worker process functions take a configurer parameter which is a callable
    # for configuring logging for that process. These functions are also passed the queue,
    # which they use for communication.
    #
    # In practice, you can configure the listener however you want, but note that in this
    # simple example, the listener does not apply level or filter logic to received records.
    # In practice, you would probably want to do this logic in the worker processes, to avoid
    # sending events which would be filtered out between processes.
    #
    # The size of the rotated files is made small so you can see the results easily.
    def listener_configurer():
        root = logging.getLogger()
        h = logging.handlers.RotatingFileHandler('mptest.log', 'a', 300, 10)
        f = logging.Formatter('%(asctime)s %(processName)-10s %(name)s %(levelname)-8s %(message)s')
        h.setFormatter(f)
        root.addHandler(h)

    # This is the listener process top-level loop: wait for logging events
    # (LogRecords)on the queue and handle them, quit when you get a None for a
    # LogRecord.
    def listener_process(queue, configurer):
        configurer()
        while True:
            try:
                record = queue.get()
                if record is None: # We send this as a sentinel to tell the listener to quit.
                    break
                logger = logging.getLogger(record.name)
                logger.handle(record) # No level or filter logic applied - just do it!
            except (KeyboardInterrupt, SystemExit):
                raise
            except:
                import sys, traceback
                print >> sys.stderr, 'Whoops! Problem:'
                traceback.print_exc(file=sys.stderr)

    # Arrays used for random selections in this demo

    LEVELS = [logging.DEBUG, logging.INFO, logging.WARNING,
              logging.ERROR, logging.CRITICAL]

    LOGGERS = ['a.b.c', 'd.e.f']

    MESSAGES = [
        'Random message #1',
        'Random message #2',
        'Random message #3',
    ]

    # The worker configuration is done at the start of the worker process run.
    # Note that on Windows you can't rely on fork semantics, so each process
    # will run the logging configuration code when it starts.
    def worker_configurer(queue):
        h = logging.handlers.QueueHandler(queue) # Just the one handler needed
        root = logging.getLogger()
        root.addHandler(h)
        root.setLevel(logging.DEBUG) # send all messages, for demo; no other level or filter logic applied.

    # This is the worker process top-level loop, which just logs ten events with
    # random intervening delays before terminating.
    # The print messages are just so you know it's doing something!
    def worker_process(queue, configurer):
        configurer(queue)
        name = multiprocessing.current_process().name
        print('Worker started: %s' % name)
        for i in range(10):
            time.sleep(random())
            logger = logging.getLogger(choice(LOGGERS))
            level = choice(LEVELS)
            message = choice(MESSAGES)
            logger.log(level, message)
        print('Worker finished: %s' % name)

    # Here's where the demo gets orchestrated. Create the queue, create and start
    # the listener, create ten workers and start them, wait for them to finish,
    # then send a None to the queue to tell the listener to finish.
    def main():
        queue = multiprocessing.Queue(-1)
        listener = multiprocessing.Process(target=listener_process,
                                           args=(queue, listener_configurer))
        listener.start()
        workers = []
        for i in range(10):
            worker = multiprocessing.Process(target=worker_process,
                                           args=(queue, worker_configurer))
            workers.append(worker)
            worker.start()
        for w in workers:
            w.join()
        queue.put_nowait(None)
        listener.join()

    if __name__ == '__main__':
        main()

A variant of the above script keeps the logging in the main process, in
a separate thread:

    import logging
    import logging.config
    import logging.handlers
    from multiprocessing import Process, Queue
    import random
    import threading
    import time

    def logger_thread(q):
        while True:
            record = q.get()
            if record is None:
                break
            logger = logging.getLogger(record.name)
            logger.handle(record)


    def worker_process(q):
        qh = logging.handlers.QueueHandler(q)
        root = logging.getLogger()
        root.setLevel(logging.DEBUG)
        root.addHandler(qh)
        levels = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,
                  logging.CRITICAL]
        loggers = ['foo', 'foo.bar', 'foo.bar.baz',
                   'spam', 'spam.ham', 'spam.ham.eggs']
        for i in range(100):
            lvl = random.choice(levels)
            logger = logging.getLogger(random.choice(loggers))
            logger.log(lvl, 'Message no. %d', i)

    if __name__ == '__main__':
        q = Queue()
        d = {
            'version': 1,
            'formatters': {
                'detailed': {
                    'class': 'logging.Formatter',
                    'format': '%(asctime)s %(name)-15s %(levelname)-8s %(processName)-10s %(message)s'
                }
            },
            'handlers': {
                'console': {
                    'class': 'logging.StreamHandler',
                    'level': 'INFO',
                },
                'file': {
                    'class': 'logging.FileHandler',
                    'filename': 'mplog.log',
                    'mode': 'w',
                    'formatter': 'detailed',
                },
                'foofile': {
                    'class': 'logging.FileHandler',
                    'filename': 'mplog-foo.log',
                    'mode': 'w',
                    'formatter': 'detailed',
                },
                'errors': {
                    'class': 'logging.FileHandler',
                    'filename': 'mplog-errors.log',
                    'mode': 'w',
                    'level': 'ERROR',
                    'formatter': 'detailed',
                },
            },
            'loggers': {
                'foo': {
                    'handlers' : ['foofile']
                }
            },
            'root': {
                'level': 'DEBUG',
                'handlers': ['console', 'file', 'errors']
            },
        }
        workers = []
        for i in range(5):
            wp = Process(target=worker_process, name='worker %d' % (i + 1), args=(q,))
            workers.append(wp)
            wp.start()
        logging.config.dictConfig(d)
        lp = threading.Thread(target=logger_thread, args=(q,))
        lp.start()
        # At this point, the main process could do some useful work of its own
        # Once it's done that, it can wait for the workers to terminate...
        for wp in workers:
            wp.join()
        # And now tell the logging thread to finish up, too
        q.put(None)
        lp.join()

This variant shows how you can e.g. apply configuration for particular
loggers - e.g. the `foo' logger has a special handler which stores all
events in the `foo' subsystem in a file `mplog-foo.log'. This will be
used by the logging machinery in the main process (even though the
logging events are generated in the worker processes) to direct the
messages to the appropriate destinations.


File: python-howto-3.2.2.info,  Node: Using file rotation,  Next: Subclassing QueueHandler - a ZeroMQ example,  Prev: Logging to a single file from multiple processes,  Up: Logging Cookbook

8.9 Using file rotation
=======================

Sometimes you want to let a log file grow to a certain size, then open
a new file and log to that. You may want to keep a certain number of
these files, and when that many files have been created, rotate the
files so that the number of files and the size of the files both remain
bounded. For this usage pattern, the logging package provides a
`RotatingFileHandler':

    import glob
    import logging
    import logging.handlers

    LOG_FILENAME = 'logging_rotatingfile_example.out'

    # Set up a specific logger with our desired output level
    my_logger = logging.getLogger('MyLogger')
    my_logger.setLevel(logging.DEBUG)

    # Add the log message handler to the logger
    handler = logging.handlers.RotatingFileHandler(
                  LOG_FILENAME, maxBytes=20, backupCount=5)

    my_logger.addHandler(handler)

    # Log some messages
    for i in range(20):
        my_logger.debug('i = %d' % i)

    # See what files are created
    logfiles = glob.glob('%s*' % LOG_FILENAME)

    for filename in logfiles:
        print(filename)

The result should be 6 separate files, each with part of the log
history for the application:

    logging_rotatingfile_example.out
    logging_rotatingfile_example.out.1
    logging_rotatingfile_example.out.2
    logging_rotatingfile_example.out.3
    logging_rotatingfile_example.out.4
    logging_rotatingfile_example.out.5

The most current file is always `logging_rotatingfile_example.out', and
each time it reaches the size limit it is renamed with the suffix `.1'.
Each of the existing backup files is renamed to increment the suffix
(`.1' becomes `.2', etc.)  and the `.6' file is erased.

  Obviously this example sets the log length much much too small as an
extreme example.  You would want to set _maxBytes_ to an appropriate
value.


File: python-howto-3.2.2.info,  Node: Subclassing QueueHandler - a ZeroMQ example,  Next: Subclassing QueueListener - a ZeroMQ example,  Prev: Using file rotation,  Up: Logging Cookbook

8.10 Subclassing QueueHandler - a ZeroMQ example
================================================

You can use a `QueueHandler' subclass to send messages to other kinds
of queues, for example a ZeroMQ 'publish' socket. In the example
below,the socket is created separately and passed to the handler (as
its 'queue'):

    import zmq # using pyzmq, the Python binding for ZeroMQ
    import json # for serializing records portably

    ctx = zmq.Context()
    sock = zmq.Socket(ctx, zmq.PUB) # or zmq.PUSH, or other suitable value
    sock.bind('tcp://*:5556') # or wherever

    class ZeroMQSocketHandler(QueueHandler):
        def enqueue(self, record):
            data = json.dumps(record.__dict__)
            self.queue.send(data)

    handler = ZeroMQSocketHandler(sock)

Of course there are other ways of organizing this, for example passing
in the data needed by the handler to create the socket:

    class ZeroMQSocketHandler(QueueHandler):
        def __init__(self, uri, socktype=zmq.PUB, ctx=None):
            self.ctx = ctx or zmq.Context()
            socket = zmq.Socket(self.ctx, socktype)
            socket.bind(uri)
            QueueHandler.__init__(self, socket)

        def enqueue(self, record):
            data = json.dumps(record.__dict__)
            self.queue.send(data)

        def close(self):
            self.queue.close()



File: python-howto-3.2.2.info,  Node: Subclassing QueueListener - a ZeroMQ example,  Prev: Subclassing QueueHandler - a ZeroMQ example,  Up: Logging Cookbook

8.11 Subclassing QueueListener - a ZeroMQ example
=================================================

You can also subclass `QueueListener' to get messages from other kinds
of queues, for example a ZeroMQ 'subscribe' socket. Here's an example:

    class ZeroMQSocketListener(QueueListener):
        def __init__(self, uri, *handlers, **kwargs):
            self.ctx = kwargs.get('ctx') or zmq.Context()
            socket = zmq.Socket(self.ctx, zmq.SUB)
            socket.setsockopt(zmq.SUBSCRIBE, '') # subscribe to everything
            socket.connect(uri)

        def dequeue(self):
            msg = self.queue.recv()
            return logging.makeLogRecord(json.loads(msg))


See also
........

Module `logging'
     API reference for the logging module.

Module `logging.config'
     Configuration API for the logging module.

Module `logging.handlers'
     Useful handlers included with the logging module.

  *note A basic logging tutorial: 73.

  *note A more advanced logging tutorial: 79.


File: python-howto-3.2.2.info,  Node: Regular Expression HOWTO,  Next: Socket Programming HOWTO,  Prev: Logging Cookbook,  Up: Top

9 Regular Expression HOWTO
**************************

     Author: A.M. Kuchling <<amk@amk.ca>>

Abstract
--------

This document is an introductory tutorial to using regular expressions
in Python with the `re' module.  It provides a gentler introduction
than the corresponding section in the Library Reference.

* Menu:

* Introduction: Introduction<2>.
* Simple Patterns::
* Using Regular Expressions::
* More Pattern Power::
* Modifying Strings::
* Common Problems::
* Feedback::


File: python-howto-3.2.2.info,  Node: Introduction<2>,  Next: Simple Patterns,  Up: Regular Expression HOWTO

9.1 Introduction
================

Regular expressions (called REs, or regexes, or regex patterns) are
essentially a tiny, highly specialized programming language embedded
inside Python and made available through the `re' module. Using this
little language, you specify the rules for the set of possible strings
that you want to match; this set might contain English sentences, or
e-mail addresses, or TeX commands, or anything you like.  You can then
ask questions such as "Does this string match the pattern?", or "Is
there a match for the pattern anywhere in this string?".  You can also
use REs to modify a string or to split it apart in various ways.

  Regular expression patterns are compiled into a series of bytecodes
which are then executed by a matching engine written in C.  For
advanced use, it may be necessary to pay careful attention to how the
engine will execute a given RE, and write the RE in a certain way in
order to produce bytecode that runs faster.  Optimization isn't covered
in this document, because it requires that you have a good
understanding of the matching engine's internals.

  The regular expression language is relatively small and restricted,
so not all possible string processing tasks can be done using regular
expressions.  There are also tasks that _can_ be done with regular
expressions, but the expressions turn out to be very complicated.  In
these cases, you may be better off writing Python code to do the
processing; while Python code will be slower than an elaborate regular
expression, it will also probably be more understandable.


File: python-howto-3.2.2.info,  Node: Simple Patterns,  Next: Using Regular Expressions,  Prev: Introduction<2>,  Up: Regular Expression HOWTO

9.2 Simple Patterns
===================

We'll start by learning about the simplest possible regular
expressions.  Since regular expressions are used to operate on strings,
we'll begin with the most common task: matching characters.

  For a detailed explanation of the computer science underlying regular
expressions (deterministic and non-deterministic finite automata), you
can refer to almost any textbook on writing compilers.

* Menu:

* Matching Characters::
* Repeating Things::


File: python-howto-3.2.2.info,  Node: Matching Characters,  Next: Repeating Things,  Up: Simple Patterns

9.2.1 Matching Characters
-------------------------

Most letters and characters will simply match themselves.  For example,
the regular expression `test' will match the string `test' exactly.
(You can enable a case-insensitive mode that would let this RE match
`Test' or `TEST' as well; more about this later.)

  There are exceptions to this rule; some characters are special
_metacharacters_, and don't match themselves.  Instead, they signal that
some out-of-the-ordinary thing should be matched, or they affect other
portions of the RE by repeating them or changing their meaning.  Much
of this document is devoted to discussing various metacharacters and
what they do.

  Here's a complete list of the metacharacters; their meanings will be
discussed in the rest of this HOWTO.

    . ^ $ * + ? { } [ ] \ | ( )

The first metacharacters we'll look at are `[' and `]'. They're used for
specifying a character class, which is a set of characters that you
wish to match.  Characters can be listed individually, or a range of
characters can be indicated by giving two characters and separating
them by a `'-''.  For example, `[abc]' will match any of the characters
`a', `b', or `c'; this is the same as `[a-c]', which uses a range to
express the same set of characters.  If you wanted to match only
lowercase letters, your RE would be `[a-z]'.

  Metacharacters are not active inside classes.  For example, `[akm$]'
will match any of the characters `'a'', `'k'', `'m'', or `'$''; `'$'' is
usually a metacharacter, but inside a character class it's stripped of
its special nature.

  You can match the characters not listed within the class by
_complementing_ the set.  This is indicated by including a `'^'' as the
first character of the class; `'^'' outside a character class will
simply match the `'^'' character.  For example, `[^5]' will match any
character except `'5''.

  Perhaps the most important metacharacter is the backslash, `\'.   As
in Python string literals, the backslash can be followed by various
characters to signal various special sequences.  It's also used to
escape all the metacharacters so you can still match them in patterns;
for example, if you need to match a `[' or  `\', you can precede them
with a backslash to remove their special meaning: `\[' or `\\'.

  Some of the special sequences beginning with `'\'' represent
predefined sets of characters that are often useful, such as the set of
digits, the set of letters, or the set of anything that isn't
whitespace.  The following predefined special sequences are a subset of
those available. The equivalent classes are for bytes patterns. For a
complete list of sequences and expanded class definitions for Unicode
string patterns, see the last part of _Regular Expression Syntax_.

`\d'
     Matches any decimal digit; this is equivalent to the class `[0-9]'.

`\D'
     Matches any non-digit character; this is equivalent to the class
     `[^0-9]'.

`\s'
     Matches any whitespace character; this is equivalent to the class
     `[ \t\n\r\f\v]'.

`\S'
     Matches any non-whitespace character; this is equivalent to the
     class `[^ \t\n\r\f\v]'.

`\w'
     Matches any alphanumeric character; this is equivalent to the class
     `[a-zA-Z0-9_]'.

`\W'
     Matches any non-alphanumeric character; this is equivalent to the
     class `[^a-zA-Z0-9_]'.

  These sequences can be included inside a character class.  For
example, `[\s,.]' is a character class that will match any whitespace
character, or `','' or `'.''.

  The final metacharacter in this section is `.'.  It matches anything
except a newline character, and there's an alternate mode (`re.DOTALL')
where it will match even a newline.  `'.'' is often used where you want
to match "any character".


File: python-howto-3.2.2.info,  Node: Repeating Things,  Prev: Matching Characters,  Up: Simple Patterns

9.2.2 Repeating Things
----------------------

Being able to match varying sets of characters is the first thing
regular expressions can do that isn't already possible with the methods
available on strings.  However, if that was the only additional
capability of regexes, they wouldn't be much of an advance. Another
capability is that you can specify that portions of the RE must be
repeated a certain number of times.

  The first metacharacter for repeating things that we'll look at is
`*'.  `*' doesn't match the literal character `*'; instead, it
specifies that the previous character can be matched zero or more
times, instead of exactly once.

  For example, `ca*t' will match `ct' (0 `a' characters), `cat' (1 `a'),
`caaat' (3 `a' characters), and so forth.  The RE engine has various
internal limitations stemming from the size of C's `int' type that will
prevent it from matching over 2 billion `a' characters; you probably
don't have enough memory to construct a string that large, so you
shouldn't run into that limit.

  Repetitions such as `*' are _greedy_; when repeating a RE, the
matching engine will try to repeat it as many times as possible. If
later portions of the pattern don't match, the matching engine will
then back up and try again with few repetitions.

  A step-by-step example will make this more obvious.  Let's consider
the expression `a[bcd]*b'.  This matches the letter `'a'', zero or more
letters from the class `[bcd]', and finally ends with a `'b''.  Now
imagine matching this RE against the string `abcbd'.

Step       Matched         Explanation
----------------------------------------------------------------- 
1          `a'             The `a' in the RE matches.
2          `abcbd'         The engine matches `[bcd]*', going
                           as far as it can, which is to the
                           end of the string.
3          _Failure_       The engine tries to match `b', but
                           the current position is at the end
                           of the string, so it fails.
4          `abcb'          Back up, so that  `[bcd]*' matches
                           one less character.
5          _Failure_       Try `b' again, but the current
                           position is at the last character,
                           which is a `'d''.
6          `abc'           Back up again, so that `[bcd]*' is
                           only matching `bc'.
6          `abcb'          Try `b' again.  This time the
                           character at the current position is
                           `'b'', so it succeeds.

  The end of the RE has now been reached, and it has matched `abcb'.
This demonstrates how the matching engine goes as far as it can at
first, and if no match is found it will then progressively back up and
retry the rest of the RE again and again.  It will back up until it has
tried zero matches for `[bcd]*', and if that subsequently fails, the
engine will conclude that the string doesn't match the RE at all.

  Another repeating metacharacter is `+', which matches one or more
times.  Pay careful attention to the difference between `*' and `+';
`*' matches _zero_ or more times, so whatever's being repeated may not
be present at all, while `+' requires at least _one_ occurrence.  To
use a similar example, `ca+t' will match `cat' (1 `a'), `caaat' (3
`a''s), but won't match `ct'.

  There are two more repeating qualifiers.  The question mark
character, `?', matches either once or zero times; you can think of it
as marking something as being optional.  For example, `home-?brew'
matches either `homebrew' or `home-brew'.

  The most complicated repeated qualifier is `{m,n}', where _m_ and _n_
are decimal integers.  This qualifier means there must be at least _m_
repetitions, and at most _n_.  For example, `a/{1,3}b' will match
`a/b', `a//b', and `a///b'.  It won't match `ab', which has no slashes,
or `a////b', which has four.

  You can omit either _m_ or _n_; in that case, a reasonable value is
assumed for the missing value.  Omitting _m_ is interpreted as a lower
limit of 0, while omitting _n_ results in an upper bound of infinity --
actually, the upper bound is the 2-billion limit mentioned earlier, but
that might as well be infinity.

  Readers of a reductionist bent may notice that the three other
qualifiers can all be expressed using this notation.  `{0,}' is the
same as `*', `{1,}' is equivalent to `+', and `{0,1}' is the same as
`?'.  It's better to use `*', `+', or `?' when you can, simply because
they're shorter and easier to read.


File: python-howto-3.2.2.info,  Node: Using Regular Expressions,  Next: More Pattern Power,  Prev: Simple Patterns,  Up: Regular Expression HOWTO

9.3 Using Regular Expressions
=============================

Now that we've looked at some simple regular expressions, how do we
actually use them in Python?  The `re' module provides an interface to
the regular expression engine, allowing you to compile REs into objects
and then perform matches with them.

* Menu:

* Compiling Regular Expressions::
* The Backslash Plague::
* Performing Matches::
* Module-Level Functions::
* Compilation Flags::


File: python-howto-3.2.2.info,  Node: Compiling Regular Expressions,  Next: The Backslash Plague,  Up: Using Regular Expressions

9.3.1 Compiling Regular Expressions
-----------------------------------

Regular expressions are compiled into pattern objects, which have
methods for various operations such as searching for pattern matches or
performing string substitutions.

    >>> import re
    >>> p = re.compile('ab*')
    >>> p
    <_sre.SRE_Pattern object at 0x...>

`re.compile()' also accepts an optional _flags_ argument, used to enable
various special features and syntax variations.  We'll go over the
available settings later, but for now a single example will do:

    >>> p = re.compile('ab*', re.IGNORECASE)

The RE is passed to `re.compile()' as a string.  REs are handled as
strings because regular expressions aren't part of the core Python
language, and no special syntax was created for expressing them.
(There are applications that don't need REs at all, so there's no need
to bloat the language specification by including them.) Instead, the
`re' module is simply a C extension module included with Python, just
like the `socket' or `zlib' modules.

  Putting REs in strings keeps the Python language simpler, but has one
disadvantage which is the topic of the next section.


File: python-howto-3.2.2.info,  Node: The Backslash Plague,  Next: Performing Matches,  Prev: Compiling Regular Expressions,  Up: Using Regular Expressions

9.3.2 The Backslash Plague
--------------------------

As stated earlier, regular expressions use the backslash character
(`'\'') to indicate special forms or to allow special characters to be
used without invoking their special meaning. This conflicts with
Python's usage of the same character for the same purpose in string
literals.

  Let's say you want to write a RE that matches the string `\section',
which might be found in a LaTeX file.  To figure out what to write in
the program code, start with the desired string to be matched.  Next,
you must escape any backslashes and other metacharacters by preceding
them with a backslash, resulting in the string `\\section'.  The
resulting string that must be passed to `re.compile()' must be
`\\section'.  However, to express this as a Python string literal, both
backslashes must be escaped _again_.

Characters              Stage
----------------------------------------------------------------------- 
`\section'              Text string to be matched
`\\section'             Escaped backslash for `re.compile()'
`"\\\\section"'         Escaped backslashes for a string literal

  In short, to match a literal backslash, one has to write `'\\\\'' as
the RE string, because the regular expression must be `\\', and each
backslash must be expressed as `\\' inside a regular Python string
literal.  In REs that feature backslashes repeatedly, this leads to
lots of repeated backslashes and makes the resulting strings difficult
to understand.

  The solution is to use Python's raw string notation for regular
expressions; backslashes are not handled in any special way in a string
literal prefixed with `'r'', so `r"\n"' is a two-character string
containing `'\'' and `'n'', while `"\n"' is a one-character string
containing a newline. Regular expressions will often be written in
Python code using this raw string notation.

Regular String          Raw string
----------------------------------------------- 
`"ab*"'                 `r"ab*"'
`"\\\\section"'         `r"\\section"'
`"\\w+\\s+\\1"'         `r"\w+\s+\1"'


File: python-howto-3.2.2.info,  Node: Performing Matches,  Next: Module-Level Functions,  Prev: The Backslash Plague,  Up: Using Regular Expressions

9.3.3 Performing Matches
------------------------

Once you have an object representing a compiled regular expression,
what do you do with it?  Pattern objects have several methods and
attributes.  Only the most significant ones will be covered here;
consult the `re' docs for a complete listing.

Method/Attribute       Purpose
--------------------------------------------------------------------------- 
`match()'              Determine if the RE matches at the beginning of
                       the string.
`search()'             Scan through a string, looking for any location
                       where this RE matches.
`findall()'            Find all substrings where the RE matches, and
                       returns them as a list.
`finditer()'           Find all substrings where the RE matches, and
                       returns them as an _iterator_.

  `match()' and `search()' return `None' if no match can be found.  If
they're successful, a `MatchObject' instance is returned, containing
information about the match: where it starts and ends, the substring it
matched, and more.

  You can learn about this by interactively experimenting with the `re'
module.  If you have `tkinter' available, you may also want to look at
`Tools/demo/redemo.py', a demonstration program included with the
Python distribution.  It allows you to enter REs and strings, and
displays whether the RE matches or fails. `redemo.py' can be quite
useful when trying to debug a complicated RE.  Phil Schwartz's Kodos(1)
is also an interactive tool for developing and testing RE patterns.

  This HOWTO uses the standard Python interpreter for its examples.
First, run the Python interpreter, import the `re' module, and compile
a RE:

    >>> import re
    >>> p = re.compile('[a-z]+')
    >>> p
    <_sre.SRE_Pattern object at 0x...>

Now, you can try matching various strings against the RE `[a-z]+'.  An
empty string shouldn't match at all, since `+' means 'one or more
repetitions'.  `match()' should return `None' in this case, which will
cause the interpreter to print no output.  You can explicitly print the
result of `match()' to make this clear.

    >>> p.match("")
    >>> print(p.match(""))
    None

Now, let's try it on a string that it should match, such as `tempo'.
In this case, `match()' will return a `MatchObject', so you should
store the result in a variable for later use.

    >>> m = p.match('tempo')
    >>> m
    <_sre.SRE_Match object at 0x...>

Now you can query the `MatchObject' for information about the matching
string.   `MatchObject' instances also have several methods and
attributes; the most important ones are:

Method/Attribute       Purpose
------------------------------------------------------------------------ 
`group()'              Return the string matched by the RE
`start()'              Return the starting position of the match
`end()'                Return the ending position of the match
`span()'               Return a tuple containing the (start, end)
                       positions  of the match

  Trying these methods will soon clarify their meaning:

    >>> m.group()
    'tempo'
    >>> m.start(), m.end()
    (0, 5)
    >>> m.span()
    (0, 5)

`group()' returns the substring that was matched by the RE.  `start()'
and `end()' return the starting and ending index of the match. `span()'
returns both start and end indexes in a single tuple.  Since the
`match()' method only checks if the RE matches at the start of a
string, `start()' will always be zero.  However, the `search()' method
of patterns scans through the string, so  the match may not start at
zero in that case.

    >>> print(p.match('::: message'))
    None
    >>> m = p.search('::: message') ; print(m)
    <_sre.SRE_Match object at 0x...>
    >>> m.group()
    'message'
    >>> m.span()
    (4, 11)

In actual programs, the most common style is to store the `MatchObject'
in a variable, and then check if it was `None'.  This usually looks
like:

    p = re.compile( ... )
    m = p.match( 'string goes here' )
    if m:
        print('Match found: ', m.group())
    else:
        print('No match')

Two pattern methods return all of the matches for a pattern.
`findall()' returns a list of matching strings:

    >>> p = re.compile('\d+')
    >>> p.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')
    ['12', '11', '10']

`findall()' has to create the entire list before it can be returned as
the result.  The `finditer()' method returns a sequence of `MatchObject'
instances as an _iterator_:

    >>> iterator = p.finditer('12 drummers drumming, 11 ... 10 ...')
    >>> iterator
    <callable_iterator object at 0x...>
    >>> for match in iterator:
    ...     print(match.span())
    ...
    (0, 2)
    (22, 24)
    (29, 31)


  ---------- Footnotes ----------

  (1) http://kodos.sourceforge.net/


File: python-howto-3.2.2.info,  Node: Module-Level Functions,  Next: Compilation Flags,  Prev: Performing Matches,  Up: Using Regular Expressions

9.3.4 Module-Level Functions
----------------------------

You don't have to create a pattern object and call its methods; the
`re' module also provides top-level functions called `match()',
`search()', `findall()', `sub()', and so forth.  These functions take
the same arguments as the corresponding pattern method, with the RE
string added as the first argument, and still return either `None' or a
`MatchObject' instance.

    >>> print(re.match(r'From\s+', 'Fromage amk'))
    None
    >>> re.match(r'From\s+', 'From amk Thu May 14 19:12:10 1998')
    <_sre.SRE_Match object at 0x...>

Under the hood, these functions simply create a pattern object for you
and call the appropriate method on it.  They also store the compiled
object in a cache, so future calls using the same RE are faster.

  Should you use these module-level functions, or should you get the
pattern and call its methods yourself?  That choice depends on how
frequently the RE will be used, and on your personal coding style.  If
the RE is being used at only one point in the code, then the module
functions are probably more convenient.  If a program contains a lot of
regular expressions, or re-uses the same ones in several locations,
then it might be worthwhile to collect all the definitions in one
place, in a section of code that compiles all the REs ahead of time.
To take an example from the standard library, here's an extract from
the now deprecated `xmllib.py':

    ref = re.compile( ... )
    entityref = re.compile( ... )
    charref = re.compile( ... )
    starttagopen = re.compile( ... )

I generally prefer to work with the compiled object, even for one-time
uses, but few people will be as much of a purist about this as I am.


File: python-howto-3.2.2.info,  Node: Compilation Flags,  Prev: Module-Level Functions,  Up: Using Regular Expressions

9.3.5 Compilation Flags
-----------------------

Compilation flags let you modify some aspects of how regular
expressions work.  Flags are available in the `re' module under two
names, a long name such as `IGNORECASE' and a short, one-letter form
such as `I'.  (If you're familiar with Perl's pattern modifiers, the
one-letter forms use the same letters; the short form of `re.VERBOSE'
is `re.X', for example.)  Multiple flags can be specified by bitwise
OR-ing them; `re.I | re.M' sets both the `I' and `M' flags, for example.

  Here's a table of the available flags, followed by a more detailed
explanation of each one.

Flag                                  Meaning
--------------------------------------------------------------------------------------- 
`DOTALL', `S'                         Make `.' match any character, including newlines
`IGNORECASE', `I'                     Do case-insensitive matches
`LOCALE', `L'                         Do a locale-aware match
`MULTILINE', `M'                      Multi-line matching, affecting `^' and `$'
`VERBOSE', `X'                        Enable verbose REs, which can be organized more
                                      cleanly and understandably.
`ASCII', `A'                          Makes several escapes like `\w', `\b', `\s' and
                                      `\d' match only on ASCII characters with the
                                      respective property.

 -- Data: I
 -- Data: IGNORECASE
     Perform case-insensitive matching; character class and literal
     strings will match letters by ignoring case.  For example, `[A-Z]'
     will match lowercase letters, too, and `Spam' will match `Spam',
     `spam', or `spAM'. This lowercasing doesn't take the current
     locale into account; it will if you also set the `LOCALE' flag.

 -- Data: L
 -- Data: LOCALE
     Make `\w', `\W', `\b', and `\B', dependent on the current locale.

     Locales are a feature of the C library intended to help in writing
     programs that take account of language differences.  For example,
     if you're processing French text, you'd want to be able to write
     `\w+' to match words, but `\w' only matches the character class
     `[A-Za-z]'; it won't match `''' or `'''.  If your system is
     configured properly and a French locale is selected, certain C
     functions will tell the program that `''' should also be
     considered a letter.  Setting the `LOCALE' flag when compiling a
     regular expression will cause the resulting compiled object to use
     these C functions for `\w'; this is slower, but also enables `\w+'
     to match French words as you'd expect.

 -- Data: M
 -- Data: MULTILINE
     (`^' and `$' haven't been explained yet;  they'll be introduced in
     section *note More Metacharacters: b5.)

     Usually `^' matches only at the beginning of the string, and `$'
     matches only at the end of the string and immediately before the
     newline (if any) at the end of the string. When this flag is
     specified, `^' matches at the beginning of the string and at the
     beginning of each line within the string, immediately following
     each newline.  Similarly, the `$' metacharacter matches either at
     the end of the string and at the end of each line (immediately
     preceding each newline).

 -- Data: S
 -- Data: DOTALL
     Makes the `'.'' special character match any character at all,
     including a newline; without this flag, `'.'' will match anything
     _except_ a newline.

 -- Data: A
 -- Data: ASCII
     Make `\w', `\W', `\b', `\B', `\s' and `\S' perform ASCII-only
     matching instead of full Unicode matching. This is only meaningful
     for Unicode patterns, and is ignored for byte patterns.

 -- Data: X
 -- Data: VERBOSE
     This flag allows you to write regular expressions that are more
     readable by granting you more flexibility in how you can format
     them.  When this flag has been specified, whitespace within the RE
     string is ignored, except when the whitespace is in a character
     class or preceded by an unescaped backslash; this lets you
     organize and indent the RE more clearly.  This flag also lets you
     put comments within a RE that will be ignored by the engine;
     comments are marked by a `'#'' that's neither in a character class
     or preceded by an unescaped backslash.

     For example, here's a RE that uses `re.VERBOSE'; see how much
     easier it is to read?

         charref = re.compile(r"""
          &[#]                # Start of a numeric entity reference
          (
              0[0-7]+         # Octal form
            | [0-9]+          # Decimal form
            | x[0-9a-fA-F]+   # Hexadecimal form
          )
          ;                   # Trailing semicolon
         """, re.VERBOSE)

     Without the verbose setting, the RE would look like this:

         charref = re.compile("&#(0[0-7]+"
                              "|[0-9]+"
                              "|x[0-9a-fA-F]+);")

     In the above example, Python's automatic concatenation of string
     literals has been used to break up the RE into smaller pieces, but
     it's still more difficult to understand than the version using
     `re.VERBOSE'.


File: python-howto-3.2.2.info,  Node: More Pattern Power,  Next: Modifying Strings,  Prev: Using Regular Expressions,  Up: Regular Expression HOWTO

9.4 More Pattern Power
======================

So far we've only covered a part of the features of regular
expressions.  In this section, we'll cover some new metacharacters, and
how to use groups to retrieve portions of the text that was matched.

* Menu:

* More Metacharacters::
* Grouping::
* Non-capturing and Named Groups::
* Lookahead Assertions::


File: python-howto-3.2.2.info,  Node: More Metacharacters,  Next: Grouping,  Up: More Pattern Power

9.4.1 More Metacharacters
-------------------------

There are some metacharacters that we haven't covered yet.  Most of
them will be covered in this section.

  Some of the remaining metacharacters to be discussed are _zero-width
assertions_.  They don't cause the engine to advance through the string;
instead, they consume no characters at all, and simply succeed or fail.
For example, `\b' is an assertion that the current position is located
at a word boundary; the position isn't changed by the `\b' at all.
This means that zero-width assertions should never be repeated, because
if they match once at a given location, they can obviously be matched
an infinite number of times.

`|'
     Alternation, or the "or" operator.   If A and B are regular
     expressions, `A|B' will match any string that matches either `A'
     or `B'. `|' has very low precedence in order to make it work
     reasonably when you're alternating multi-character strings.
     `Crow|Servo' will match either `Crow' or `Servo', not `Cro', a
     `'w'' or an `'S'', and `ervo'.

     To match a literal `'|'', use `\|', or enclose it inside a
     character class, as in `[|]'.

`^'
     Matches at the beginning of lines.  Unless the `MULTILINE' flag
     has been set, this will only match at the beginning of the string.
     In `MULTILINE' mode, this also matches immediately after each
     newline within the string.

     For example, if you wish to match the word `From' only at the
     beginning of a line, the RE to use is `^From'.

         >>> print(re.search('^From', 'From Here to Eternity'))
         <_sre.SRE_Match object at 0x...>
         >>> print(re.search('^From', 'Reciting From Memory'))
         None


`$'
     Matches at the end of a line, which is defined as either the end
     of the string, or any location followed by a newline character.

         >>> print(re.search('}$', '{block}'))
         <_sre.SRE_Match object at 0x...>
         >>> print(re.search('}$', '{block} '))
         None
         >>> print(re.search('}$', '{block}\n'))
         <_sre.SRE_Match object at 0x...>

     To match a literal `'$'', use `\$' or enclose it inside a
     character class, as in  `[$]'.

`\A'
     Matches only at the start of the string.  When not in `MULTILINE'
     mode, `\A' and `^' are effectively the same.  In `MULTILINE' mode,
     they're different: `\A' still matches only at the beginning of the
     string, but `^' may match at any location inside the string that
     follows a newline character.

`\Z'
     Matches only at the end of the string.

`\b'
     Word boundary.  This is a zero-width assertion that matches only
     at the beginning or end of a word.  A word is defined as a
     sequence of alphanumeric characters, so the end of a word is
     indicated by whitespace or a non-alphanumeric character.

     The following example matches `class' only when it's a complete
     word; it won't match when it's contained inside another word.

         >>> p = re.compile(r'\bclass\b')
         >>> print(p.search('no class at all'))
         <_sre.SRE_Match object at 0x...>
         >>> print(p.search('the declassified algorithm'))
         None
         >>> print(p.search('one subclass is'))
         None

     There are two subtleties you should remember when using this
     special sequence.  First, this is the worst collision between
     Python's string literals and regular expression sequences.  In
     Python's string literals, `\b' is the backspace character, ASCII
     value 8.  If you're not using raw strings, then Python will
     convert the `\b' to a backspace, and your RE won't match as you
     expect it to.  The following example looks the same as our
     previous RE, but omits the `'r'' in front of the RE string.

         >>> p = re.compile('\bclass\b')
         >>> print(p.search('no class at all'))
         None
         >>> print(p.search('\b' + 'class' + '\b')  )
         <_sre.SRE_Match object at 0x...>

     Second, inside a character class, where there's no use for this
     assertion, `\b' represents the backspace character, for
     compatibility with Python's string literals.

`\B'
     Another zero-width assertion, this is the opposite of `\b', only
     matching when the current position is not at a word boundary.


File: python-howto-3.2.2.info,  Node: Grouping,  Next: Non-capturing and Named Groups,  Prev: More Metacharacters,  Up: More Pattern Power

9.4.2 Grouping
--------------

Frequently you need to obtain more information than just whether the RE
matched or not.  Regular expressions are often used to dissect strings
by writing a RE divided into several subgroups which match different
components of interest.  For example, an RFC-822 header line is divided
into a header name and a value, separated by a `':'', like this:

    From: author@example.com
    User-Agent: Thunderbird 1.5.0.9 (X11/20061227)
    MIME-Version: 1.0
    To: editor@example.com

This can be handled by writing a regular expression which matches an
entire header line, and has one group which matches the header name,
and another group which matches the header's value.

  Groups are marked by the `'('', `')'' metacharacters. `'('' and `')''
have much the same meaning as they do in mathematical expressions; they
group together the expressions contained inside them, and you can
repeat the contents of a group with a repeating qualifier, such as `*',
`+', `?', or `{m,n}'.  For example, `(ab)*' will match zero or more
repetitions of `ab'.

    >>> p = re.compile('(ab)*')
    >>> print(p.match('ababababab').span())
    (0, 10)

Groups indicated with `'('', `')'' also capture the starting and ending
index of the text that they match; this can be retrieved by passing an
argument to `group()', `start()', `end()', and `span()'.  Groups are
numbered starting with 0.  Group 0 is always present; it's the whole
RE, so `MatchObject' methods all have group 0 as their default
argument.  Later we'll see how to express groups that don't capture the
span of text that they match.

    >>> p = re.compile('(a)b')
    >>> m = p.match('ab')
    >>> m.group()
    'ab'
    >>> m.group(0)
    'ab'

Subgroups are numbered from left to right, from 1 upward.  Groups can
be nested; to determine the number, just count the opening parenthesis
characters, going from left to right.

    >>> p = re.compile('(a(b)c)d')
    >>> m = p.match('abcd')
    >>> m.group(0)
    'abcd'
    >>> m.group(1)
    'abc'
    >>> m.group(2)
    'b'

`group()' can be passed multiple group numbers at a time, in which case
it will return a tuple containing the corresponding values for those
groups.

    >>> m.group(2,1,2)
    ('b', 'abc', 'b')

The `groups()' method returns a tuple containing the strings for all the
subgroups, from 1 up to however many there are.

    >>> m.groups()
    ('abc', 'b')

Backreferences in a pattern allow you to specify that the contents of
an earlier capturing group must also be found at the current location
in the string.  For example, `\1' will succeed if the exact contents of
group 1 can be found at the current position, and fails otherwise.
Remember that Python's string literals also use a backslash followed by
numbers to allow including arbitrary characters in a string, so be sure
to use a raw string when incorporating backreferences in a RE.

  For example, the following RE detects doubled words in a string.

    >>> p = re.compile(r'(\b\w+)\s+\1')
    >>> p.search('Paris in the the spring').group()
    'the the'

Backreferences like this aren't often useful for just searching through
a string -- there are few text formats which repeat data in this way --
but you'll soon find out that they're _very_ useful when performing
string substitutions.


File: python-howto-3.2.2.info,  Node: Non-capturing and Named Groups,  Next: Lookahead Assertions,  Prev: Grouping,  Up: More Pattern Power

9.4.3 Non-capturing and Named Groups
------------------------------------

Elaborate REs may use many groups, both to capture substrings of
interest, and to group and structure the RE itself.  In complex REs, it
becomes difficult to keep track of the group numbers.  There are two
features which help with this problem.  Both of them use a common
syntax for regular expression extensions, so we'll look at that first.

  Perl 5 added several additional features to standard regular
expressions, and the Python `re' module supports most of them.   It
would have been difficult to choose new single-keystroke metacharacters
or new special sequences beginning with `\' to represent the new
features without making Perl's regular expressions confusingly
different from standard REs.  If you chose `&' as a new metacharacter,
for example, old expressions would be assuming that `&' was a regular
character and wouldn't have escaped it by writing `\&' or `[&]'.

  The solution chosen by the Perl developers was to use `(?...)' as the
extension syntax.  `?' immediately after a parenthesis was a syntax
error because the `?' would have nothing to repeat, so this didn't
introduce any compatibility problems.  The characters immediately after
the `?'  indicate what extension is being used, so `(?=foo)' is one
thing (a positive lookahead assertion) and `(?:foo)' is something else
(a non-capturing group containing the subexpression `foo').

  Python adds an extension syntax to Perl's extension syntax.  If the
first character after the question mark is a `P', you know that it's an
extension that's specific to Python.  Currently there are two such
extensions: `(?P<name>...)' defines a named group, and `(?P=name)' is a
backreference to a named group.  If future versions of Perl 5 add
similar features using a different syntax, the `re' module will be
changed to support the new syntax, while preserving the Python-specific
syntax for compatibility's sake.

  Now that we've looked at the general extension syntax, we can return
to the features that simplify working with groups in complex REs. Since
groups are numbered from left to right and a complex expression may use
many groups, it can become difficult to keep track of the correct
numbering.  Modifying such a complex RE is annoying, too: insert a new
group near the beginning and you change the numbers of everything that
follows it.

  Sometimes you'll want to use a group to collect a part of a regular
expression, but aren't interested in retrieving the group's contents.
You can make this fact explicit by using a non-capturing group:
`(?:...)', where you can replace the `...' with any other regular
expression.

    >>> m = re.match("([abc])+", "abc")
    >>> m.groups()
    ('c',)
    >>> m = re.match("(?:[abc])+", "abc")
    >>> m.groups()
    ()

Except for the fact that you can't retrieve the contents of what the
group matched, a non-capturing group behaves exactly the same as a
capturing group; you can put anything inside it, repeat it with a
repetition metacharacter such as `*', and nest it within other groups
(capturing or non-capturing).  `(?:...)' is particularly useful when
modifying an existing pattern, since you can add new groups without
changing how all the other groups are numbered.  It should be mentioned
that there's no performance difference in searching between capturing
and non-capturing groups; neither form is any faster than the other.

  A more significant feature is named groups: instead of referring to
them by numbers, groups can be referenced by a name.

  The syntax for a named group is one of the Python-specific extensions:
`(?P<name>...)'.  _name_ is, obviously, the name of the group.  Named
groups also behave exactly like capturing groups, and additionally
associate a name with a group.  The `MatchObject' methods that deal
with capturing groups all accept either integers that refer to the
group by number or strings that contain the desired group's name.
Named groups are still given numbers, so you can retrieve information
about a group in two ways:

    >>> p = re.compile(r'(?P<word>\b\w+\b)')
    >>> m = p.search( '(((( Lots of punctuation )))' )
    >>> m.group('word')
    'Lots'
    >>> m.group(1)
    'Lots'

Named groups are handy because they let you use easily-remembered
names, instead of having to remember numbers.  Here's an example RE
from the `imaplib' module:

    InternalDate = re.compile(r'INTERNALDATE "'
            r'(?P<day>[ 123][0-9])-(?P<mon>[A-Z][a-z][a-z])-'
            r'(?P<year>[0-9][0-9][0-9][0-9])'
            r' (?P<hour>[0-9][0-9]):(?P<min>[0-9][0-9]):(?P<sec>[0-9][0-9])'
            r' (?P<zonen>[-+])(?P<zoneh>[0-9][0-9])(?P<zonem>[0-9][0-9])'
            r'"')

It's obviously much easier to retrieve `m.group('zonem')', instead of
having to remember to retrieve group 9.

  The syntax for backreferences in an expression such as `(...)\1'
refers to the number of the group.  There's naturally a variant that
uses the group name instead of the number. This is another Python
extension: `(?P=name)' indicates that the contents of the group called
_name_ should again be matched at the current point.  The regular
expression for finding doubled words, `(\b\w+)\s+\1' can also be
written as `(?P<word>\b\w+)\s+(?P=word)':

    >>> p = re.compile(r'(?P<word>\b\w+)\s+(?P=word)')
    >>> p.search('Paris in the the spring').group()
    'the the'



File: python-howto-3.2.2.info,  Node: Lookahead Assertions,  Prev: Non-capturing and Named Groups,  Up: More Pattern Power

9.4.4 Lookahead Assertions
--------------------------

Another zero-width assertion is the lookahead assertion.  Lookahead
assertions are available in both positive and negative form, and  look
like this:

`(?=...)'
     Positive lookahead assertion.  This succeeds if the contained
     regular expression, represented here by `...', successfully
     matches at the current location, and fails otherwise. But, once
     the contained expression has been tried, the matching engine
     doesn't advance at all; the rest of the pattern is tried right
     where the assertion started.

`(?!...)'
     Negative lookahead assertion.  This is the opposite of the
     positive assertion; it succeeds if the contained expression
     _doesn't_ match at the current position in the string.

  To make this concrete, let's look at a case where a lookahead is
useful.  Consider a simple pattern to match a filename and split it
apart into a base name and an extension, separated by a `.'.  For
example, in `news.rc', `news' is the base name, and `rc' is the
filename's extension.

  The pattern to match this is quite simple:

  `.*[.].*$'

  Notice that the `.' needs to be treated specially because it's a
metacharacter; I've put it inside a character class.  Also notice the
trailing `$'; this is added to ensure that all the rest of the string
must be included in the extension.  This regular expression matches
`foo.bar' and `autoexec.bat' and `sendmail.cf' and `printers.conf'.

  Now, consider complicating the problem a bit; what if you want to
match filenames where the extension is not `bat'? Some incorrect
attempts:

  `.*[.][^b].*$'  The first attempt above tries to exclude `bat' by
requiring that the first character of the extension is not a `b'.  This
is wrong, because the pattern also doesn't match `foo.bar'.

  `.*[.]([^b]..|.[^a].|..[^t])$'

  The expression gets messier when you try to patch up the first
solution by requiring one of the following cases to match: the first
character of the extension isn't `b'; the second character isn't `a';
or the third character isn't `t'.  This accepts `foo.bar' and rejects
`autoexec.bat', but it requires a three-letter extension and won't
accept a filename with a two-letter extension such as `sendmail.cf'.
We'll complicate the pattern again in an effort to fix it.

  `.*[.]([^b].?.?|.[^a]?.?|..?[^t]?)$'

  In the third attempt, the second and third letters are all made
optional in order to allow matching extensions shorter than three
characters, such as `sendmail.cf'.

  The pattern's getting really complicated now, which makes it hard to
read and understand.  Worse, if the problem changes and you want to
exclude both `bat' and `exe' as extensions, the pattern would get even
more complicated and confusing.

  A negative lookahead cuts through all this confusion:

  `.*[.](?!bat$).*$'  The negative lookahead means: if the expression
`bat' doesn't match at this point, try the rest of the pattern; if
`bat$' does match, the whole pattern will fail.  The trailing `$' is
required to ensure that something like `sample.batch', where the
extension only starts with `bat', will be allowed.

  Excluding another filename extension is now easy; simply add it as an
alternative inside the assertion.  The following pattern excludes
filenames that end in either `bat' or `exe':

  `.*[.](?!bat$|exe$).*$'


File: python-howto-3.2.2.info,  Node: Modifying Strings,  Next: Common Problems,  Prev: More Pattern Power,  Up: Regular Expression HOWTO

9.5 Modifying Strings
=====================

Up to this point, we've simply performed searches against a static
string.  Regular expressions are also commonly used to modify strings
in various ways, using the following pattern methods:

Method/Attribute       Purpose
--------------------------------------------------------------------------- 
`split()'              Split the string into a list, splitting it
                       wherever the RE matches
`sub()'                Find all substrings where the RE matches, and
                       replace them with a different string
`subn()'               Does the same thing as `sub()',  but returns the
                       new string and the number of replacements

* Menu:

* Splitting Strings::
* Search and Replace::


File: python-howto-3.2.2.info,  Node: Splitting Strings,  Next: Search and Replace,  Up: Modifying Strings

9.5.1 Splitting Strings
-----------------------

The `split()' method of a pattern splits a string apart wherever the RE
matches, returning a list of the pieces. It's similar to the `split()'
method of strings but provides much more generality in the delimiters
that you can split by; `split()' only supports splitting by whitespace
or by a fixed string.  As you'd expect, there's a module-level
`re.split()' function, too.

 -- Method: .split (string[, maxsplit=0])
     Split _string_ by the matches of the regular expression.  If
     capturing parentheses are used in the RE, then their contents will
     also be returned as part of the resulting list.  If _maxsplit_ is
     nonzero, at most _maxsplit_ splits are performed.

  You can limit the number of splits made, by passing a value for
_maxsplit_.  When _maxsplit_ is nonzero, at most _maxsplit_ splits will
be made, and the remainder of the string is returned as the final
element of the list.  In the following example, the delimiter is any
sequence of non-alphanumeric characters.

    >>> p = re.compile(r'\W+')
    >>> p.split('This is a test, short and sweet, of split().')
    ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']
    >>> p.split('This is a test, short and sweet, of split().', 3)
    ['This', 'is', 'a', 'test, short and sweet, of split().']

Sometimes you're not only interested in what the text between
delimiters is, but also need to know what the delimiter was.  If
capturing parentheses are used in the RE, then their values are also
returned as part of the list.  Compare the following calls:

    >>> p = re.compile(r'\W+')
    >>> p2 = re.compile(r'(\W+)')
    >>> p.split('This... is a test.')
    ['This', 'is', 'a', 'test', '']
    >>> p2.split('This... is a test.')
    ['This', '... ', 'is', ' ', 'a', ' ', 'test', '.', '']

The module-level function `re.split()' adds the RE to be used as the
first argument, but is otherwise the same.

    >>> re.split('[\W]+', 'Words, words, words.')
    ['Words', 'words', 'words', '']
    >>> re.split('([\W]+)', 'Words, words, words.')
    ['Words', ', ', 'words', ', ', 'words', '.', '']
    >>> re.split('[\W]+', 'Words, words, words.', 1)
    ['Words', 'words, words.']



File: python-howto-3.2.2.info,  Node: Search and Replace,  Prev: Splitting Strings,  Up: Modifying Strings

9.5.2 Search and Replace
------------------------

Another common task is to find all the matches for a pattern, and
replace them with a different string.  The `sub()' method takes a
replacement value, which can be either a string or a function, and the
string to be processed.

 -- Method: .sub (replacement, string[, count=0])
     Returns the string obtained by replacing the leftmost
     non-overlapping occurrences of the RE in _string_ by the
     replacement _replacement_.  If the pattern isn't found, _string_
     is returned unchanged.

     The optional argument _count_ is the maximum number of pattern
     occurrences to be replaced; _count_ must be a non-negative
     integer.  The default value of 0 means to replace all occurrences.

  Here's a simple example of using the `sub()' method.  It replaces
colour names with the word `colour':

    >>> p = re.compile( '(blue|white|red)')
    >>> p.sub( 'colour', 'blue socks and red shoes')
    'colour socks and colour shoes'
    >>> p.sub( 'colour', 'blue socks and red shoes', count=1)
    'colour socks and red shoes'

The `subn()' method does the same work, but returns a 2-tuple
containing the new string value and the number of replacements  that
were performed:

    >>> p = re.compile( '(blue|white|red)')
    >>> p.subn( 'colour', 'blue socks and red shoes')
    ('colour socks and colour shoes', 2)
    >>> p.subn( 'colour', 'no colours at all')
    ('no colours at all', 0)

Empty matches are replaced only when they're not adjacent to a previous
match.

    >>> p = re.compile('x*')
    >>> p.sub('-', 'abxd')
    '-a-b-d-'

If _replacement_ is a string, any backslash escapes in it are
processed.  That is, `\n' is converted to a single newline character,
`\r' is converted to a carriage return, and so forth. Unknown escapes
such as `\j' are left alone.  Backreferences, such as `\6', are
replaced with the substring matched by the corresponding group in the
RE.  This lets you incorporate portions of the original text in the
resulting replacement string.

  This example matches the word `section' followed by a string enclosed
in `{', `}', and changes `section' to `subsection':

    >>> p = re.compile('section{ ( [^}]* ) }', re.VERBOSE)
    >>> p.sub(r'subsection{\1}','section{First} section{second}')
    'subsection{First} subsection{second}'

There's also a syntax for referring to named groups as defined by the
`(?P<name>...)' syntax.  `\g<name>' will use the substring matched by
the group named `name', and  `\g<number>'  uses the corresponding group
number.  `\g<2>' is therefore equivalent to `\2',  but isn't ambiguous
in a replacement string such as `\g<2>0'.  (`\20' would be interpreted
as a reference to group 20, not a reference to group 2 followed by the
literal character `'0''.)  The following substitutions are all
equivalent, but use all three variations of the replacement string.

    >>> p = re.compile('section{ (?P<name> [^}]* ) }', re.VERBOSE)
    >>> p.sub(r'subsection{\1}','section{First}')
    'subsection{First}'
    >>> p.sub(r'subsection{\g<1>}','section{First}')
    'subsection{First}'
    >>> p.sub(r'subsection{\g<name>}','section{First}')
    'subsection{First}'

_replacement_ can also be a function, which gives you even more
control.  If _replacement_ is a function, the function is called for
every non-overlapping occurrence of _pattern_.  On each call, the
function is  passed a `MatchObject' argument for the match and can use
this information to compute the desired replacement string and return
it.

  In the following example, the replacement function translates
decimals into hexadecimal:

    >>> def hexrepl( match ):
    ...     "Return the hex string for a decimal number"
    ...     value = int( match.group() )
    ...     return hex(value)
    ...
    >>> p = re.compile(r'\d+')
    >>> p.sub(hexrepl, 'Call 65490 for printing, 49152 for user code.')
    'Call 0xffd2 for printing, 0xc000 for user code.'

When using the module-level `re.sub()' function, the pattern is passed
as the first argument.  The pattern may be provided as an object or as
a string; if you need to specify regular expression flags, you must
either use a pattern object as the first parameter, or use embedded
modifiers in the pattern string, e.g. `sub("(?i)b+", "x", "bbbb BBBB")'
returns `'x x''.


File: python-howto-3.2.2.info,  Node: Common Problems,  Next: Feedback,  Prev: Modifying Strings,  Up: Regular Expression HOWTO

9.6 Common Problems
===================

Regular expressions are a powerful tool for some applications, but in
some ways their behaviour isn't intuitive and at times they don't
behave the way you may expect them to.  This section will point out
some of the most common pitfalls.

* Menu:

* Use String Methods::
* match() versus search(): match versus search.
* Greedy versus Non-Greedy::
* Using re.VERBOSE: Using re VERBOSE.


File: python-howto-3.2.2.info,  Node: Use String Methods,  Next: match versus search,  Up: Common Problems

9.6.1 Use String Methods
------------------------

Sometimes using the `re' module is a mistake.  If you're matching a
fixed string, or a single character class, and you're not using any
`re' features such as the `IGNORECASE' flag, then the full power of
regular expressions may not be required. Strings have several methods
for performing operations with fixed strings and they're usually much
faster, because the implementation is a single small C loop that's been
optimized for the purpose, instead of the large, more generalized
regular expression engine.

  One example might be replacing a single fixed string with another
one; for example, you might replace `word' with `deed'.  `re.sub()'
seems like the function to use for this, but consider the `replace()'
method.  Note that `replace()' will also replace `word' inside words,
turning `swordfish' into `sdeedfish', but the  naive RE `word' would
have done that, too.  (To avoid performing the substitution on parts of
words, the pattern would have to be `\bword\b', in order to require
that `word' have a word boundary on either side.  This takes the job
beyond  `replace()''s abilities.)

  Another common task is deleting every occurrence of a single
character from a string or replacing it with another single character.
You might do this with something like `re.sub('\n', ' ', S)', but
`translate()' is capable of doing both tasks and will be faster than
any regular expression operation can be.

  In short, before turning to the `re' module, consider whether your
problem can be solved with a faster and simpler string method.


File: python-howto-3.2.2.info,  Node: match versus search,  Next: Greedy versus Non-Greedy,  Prev: Use String Methods,  Up: Common Problems

9.6.2 match() versus search()
-----------------------------

The `match()' function only checks if the RE matches at the beginning
of the string while `search()' will scan forward through the string for
a match.  It's important to keep this distinction in mind.  Remember,
`match()' will only report a successful match which will start at 0; if
the match wouldn't start at zero,  `match()' will _not_ report it.

    >>> print(re.match('super', 'superstition').span())
    (0, 5)
    >>> print(re.match('super', 'insuperable'))
    None

On the other hand, `search()' will scan forward through the string,
reporting the first match it finds.

    >>> print(re.search('super', 'superstition').span())
    (0, 5)
    >>> print(re.search('super', 'insuperable').span())
    (2, 7)

Sometimes you'll be tempted to keep using `re.match()', and just add
`.*' to the front of your RE.  Resist this temptation and use
`re.search()' instead.  The regular expression compiler does some
analysis of REs in order to speed up the process of looking for a
match.  One such analysis figures out what the first character of a
match must be; for example, a pattern starting with `Crow' must match
starting with a `'C''.  The analysis lets the engine quickly scan
through the string looking for the starting character, only trying the
full match if a `'C'' is found.

  Adding `.*' defeats this optimization, requiring scanning to the end
of the string and then backtracking to find a match for the rest of the
RE.  Use `re.search()' instead.


File: python-howto-3.2.2.info,  Node: Greedy versus Non-Greedy,  Next: Using re VERBOSE,  Prev: match versus search,  Up: Common Problems

9.6.3 Greedy versus Non-Greedy
------------------------------

When repeating a regular expression, as in `a*', the resulting action
is to consume as much of the pattern as possible.  This fact often
bites you when you're trying to match a pair of balanced delimiters,
such as the angle brackets surrounding an HTML tag.  The naive pattern
for matching a single HTML tag doesn't work because of the greedy
nature of `.*'.

    >>> s = '<html><head><title>Title</title>'
    >>> len(s)
    32
    >>> print(re.match('<.*>', s).span())
    (0, 32)
    >>> print(re.match('<.*>', s).group())
    <html><head><title>Title</title>

The RE matches the `'<'' in `<html>', and the `.*' consumes the rest of
the string.  There's still more left in the RE, though, and the `>'
can't match at the end of the string, so the regular expression engine
has to backtrack character by character until it finds a match for the
`>'.   The final match extends from the `'<'' in `<html>' to the `'>''
in `</title>', which isn't what you want.

  In this case, the solution is to use the non-greedy qualifiers `*?',
`+?', `??', or `{m,n}?', which match as _little_ text as possible.  In
the above example, the `'>'' is tried immediately after the first `'<''
matches, and when it fails, the engine advances a character at a time,
retrying the `'>'' at every step.  This produces just the right result:

    >>> print(re.match('<.*?>', s).group())
    <html>

(Note that parsing HTML or XML with regular expressions is painful.
Quick-and-dirty patterns will handle common cases, but HTML and XML
have special cases that will break the obvious regular expression; by
the time you've written a regular expression that handles all of the
possible cases, the patterns will be _very_ complicated.  Use an HTML
or XML parser module for such tasks.)


File: python-howto-3.2.2.info,  Node: Using re VERBOSE,  Prev: Greedy versus Non-Greedy,  Up: Common Problems

9.6.4 Using re.VERBOSE
----------------------

By now you've probably noticed that regular expressions are a very
compact notation, but they're not terribly readable.  REs of moderate
complexity can become lengthy collections of backslashes, parentheses,
and metacharacters, making them difficult to read and understand.

  For such REs, specifying the `re.VERBOSE' flag when compiling the
regular expression can be helpful, because it allows you to format the
regular expression more clearly.

  The `re.VERBOSE' flag has several effects.  Whitespace in the regular
expression that _isn't_ inside a character class is ignored.  This
means that an expression such as `dog | cat' is equivalent to the less
readable `dog|cat', but `[a b]' will still match the characters `'a'',
`'b'', or a space.  In addition, you can also put comments inside a RE;
comments extend from a `#' character to the next newline.  When used
with triple-quoted strings, this enables REs to be formatted more
neatly:

    pat = re.compile(r"""
     \s*                 # Skip leading whitespace
     (?P<header>[^:]+)   # Header name
     \s* :               # Whitespace, and a colon
     (?P<value>.*?)      # The header's value -- *? used to
                         # lose the following trailing whitespace
     \s*$                # Trailing whitespace to end-of-line
    """, re.VERBOSE)

This is far more readable than:

    pat = re.compile(r"\s*(?P<header>[^:]+)\s*:(?P<value>.*?)\s*$")



File: python-howto-3.2.2.info,  Node: Feedback,  Prev: Common Problems,  Up: Regular Expression HOWTO

9.7 Feedback
============

Regular expressions are a complicated topic.  Did this document help you
understand them?  Were there parts that were unclear, or Problems you
encountered that weren't covered here?  If so, please send suggestions
for improvements to the author.

  The most complete book on regular expressions is almost certainly
Jeffrey Friedl's Mastering Regular Expressions, published by O'Reilly.
Unfortunately, it exclusively concentrates on Perl and Java's flavours
of regular expressions, and doesn't contain any Python material at all,
so it won't be useful as a reference for programming in Python.  (The
first edition covered Python's now-removed `regex' module, which won't
help you much.)  Consider checking it out from your library.


File: python-howto-3.2.2.info,  Node: Socket Programming HOWTO,  Next: Sorting HOW TO,  Prev: Regular Expression HOWTO,  Up: Top

10 Socket Programming HOWTO
***************************

     Author: Gordon McMillan

Abstract
--------

Sockets are used nearly everywhere, but are one of the most severely
misunderstood technologies around. This is a 10,000 foot overview of
sockets.  It's not really a tutorial - you'll still have work to do in
getting things operational. It doesn't cover the fine points (and there
are a lot of them), but I hope it will give you enough background to
begin using them decently.

* Menu:

* Sockets::
* Creating a Socket::
* Using a Socket::
* Disconnecting::
* Non-blocking Sockets::

Sockets

* History::

Creating a Socket

* IPC::

Using a Socket

* Binary Data::

Disconnecting

* When Sockets Die::

Non-blocking Sockets

* Performance::


File: python-howto-3.2.2.info,  Node: Sockets,  Next: Creating a Socket,  Up: Socket Programming HOWTO

10.1 Sockets
============

Sockets are used nearly everywhere, but are one of the most severely
misunderstood technologies around. This is a 10,000 foot overview of
sockets.  It's not really a tutorial - you'll still have work to do in
getting things working. It doesn't cover the fine points (and there are
a lot of them), but I hope it will give you enough background to begin
using them decently.

  I'm only going to talk about INET sockets, but they account for at
least 99% of the sockets in use. And I'll only talk about STREAM
sockets - unless you really know what you're doing (in which case this
HOWTO isn't for you!), you'll get better behavior and performance from
a STREAM socket than anything else. I will try to clear up the mystery
of what a socket is, as well as some hints on how to work with blocking
and non-blocking sockets. But I'll start by talking about blocking
sockets. You'll need to know how they work before dealing with
non-blocking sockets.

  Part of the trouble with understanding these things is that "socket"
can mean a number of subtly different things, depending on context. So
first, let's make a distinction between a "client" socket - an endpoint
of a conversation, and a "server" socket, which is more like a
switchboard operator. The client application (your browser, for
example) uses "client" sockets exclusively; the web server it's talking
to uses both "server" sockets and "client" sockets.

* Menu:

* History::


File: python-howto-3.2.2.info,  Node: History,  Up: Sockets

10.1.1 History
--------------

Of the various forms of IPC (Inter Process Communication), sockets are
by far the most popular.  On any given platform, there are likely to be
other forms of IPC that are faster, but for cross-platform
communication, sockets are about the only game in town.

  They were invented in Berkeley as part of the BSD flavor of Unix.
They spread like wildfire with the Internet. With good reason -- the
combination of sockets with INET makes talking to arbitrary machines
around the world unbelievably easy (at least compared to other schemes).


File: python-howto-3.2.2.info,  Node: Creating a Socket,  Next: Using a Socket,  Prev: Sockets,  Up: Socket Programming HOWTO

10.2 Creating a Socket
======================

Roughly speaking, when you clicked on the link that brought you to this
page, your browser did something like the following:

    #create an INET, STREAMing socket
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    #now connect to the web server on port 80
    # - the normal http port
    s.connect(("www.mcmillan-inc.com", 80))

When the `connect' completes, the socket `s' can be used to send in a
request for the text of the page. The same socket will read the reply,
and then be destroyed. That's right, destroyed. Client sockets are
normally only used for one exchange (or a small set of sequential
exchanges).

  What happens in the web server is a bit more complex. First, the web
server creates a "server socket":

    #create an INET, STREAMing socket
    serversocket = socket.socket(
        socket.AF_INET, socket.SOCK_STREAM)
    #bind the socket to a public host,
    # and a well-known port
    serversocket.bind((socket.gethostname(), 80))
    #become a server socket
    serversocket.listen(5)

A couple things to notice: we used `socket.gethostname()' so that the
socket would be visible to the outside world. If we had used
`s.bind(('', 80))' or `s.bind(('localhost', 80))' or
`s.bind(('127.0.0.1', 80))' we would still have a "server" socket, but
one that was only visible within the same machine.

  A second thing to note: low number ports are usually reserved for
"well known" services (HTTP, SNMP etc). If you're playing around, use a
nice high number (4 digits).

  Finally, the argument to `listen' tells the socket library that we
want it to queue up as many as 5 connect requests (the normal max)
before refusing outside connections. If the rest of the code is written
properly, that should be plenty.

  Now that we have a "server" socket, listening on port 80, we can
enter the mainloop of the web server:

    while True:
        #accept connections from outside
        (clientsocket, address) = serversocket.accept()
        #now do something with the clientsocket
        #in this case, we'll pretend this is a threaded server
        ct = client_thread(clientsocket)
        ct.run()

There's actually 3 general ways in which this loop could work -
dispatching a thread to handle `clientsocket', create a new process to
handle `clientsocket', or restructure this app to use non-blocking
sockets, and mulitplex between our "server" socket and any active
`clientsocket's using `select'. More about that later. The important
thing to understand now is this: this is _all_ a "server" socket does.
It doesn't send any data. It doesn't receive any data. It just produces
"client" sockets. Each `clientsocket' is created in response to some
_other_ "client" socket doing a `connect()' to the host and port we're
bound to. As soon as we've created that `clientsocket', we go back to
listening for more connections. The two "clients" are free to chat it
up - they are using some dynamically allocated port which will be
recycled when the conversation ends.

* Menu:

* IPC::


File: python-howto-3.2.2.info,  Node: IPC,  Up: Creating a Socket

10.2.1 IPC
----------

If you need fast IPC between two processes on one machine, you should
look into whatever form of shared memory the platform offers. A simple
protocol based around shared memory and locks or semaphores is by far
the fastest technique.

  If you do decide to use sockets, bind the "server" socket to
`'localhost''. On most platforms, this will take a shortcut around a
couple of layers of network code and be quite a bit faster.


File: python-howto-3.2.2.info,  Node: Using a Socket,  Next: Disconnecting,  Prev: Creating a Socket,  Up: Socket Programming HOWTO

10.3 Using a Socket
===================

The first thing to note, is that the web browser's "client" socket and
the web server's "client" socket are identical beasts. That is, this is
a "peer to peer" conversation. Or to put it another way, _as the
designer, you will have to decide what the rules of etiquette are for a
conversation_. Normally, the `connect'ing socket starts the
conversation, by sending in a request, or perhaps a signon. But that's
a design decision - it's not a rule of sockets.

  Now there are two sets of verbs to use for communication. You can use
`send' and `recv', or you can transform your client socket into a
file-like beast and use `read' and `write'. The latter is the way Java
presents its sockets.  I'm not going to talk about it here, except to
warn you that you need to use `flush' on sockets. These are buffered
"files", and a common mistake is to `write' something, and then `read'
for a reply. Without a `flush' in there, you may wait forever for the
reply, because the request may still be in your output buffer.

  Now we come the major stumbling block of sockets - `send' and `recv'
operate on the network buffers. They do not necessarily handle all the
bytes you hand them (or expect from them), because their major focus is
handling the network buffers. In general, they return when the
associated network buffers have been filled (`send') or emptied
(`recv'). They then tell you how many bytes they handled. It is _your_
responsibility to call them again until your message has been
completely dealt with.

  When a `recv' returns 0 bytes, it means the other side has closed (or
is in the process of closing) the connection.  You will not receive any
more data on this connection. Ever.  You may be able to send data
successfully; I'll talk about that some on the next page.

  A protocol like HTTP uses a socket for only one transfer. The client
sends a request, then reads a reply.  That's it. The socket is
discarded. This means that a client can detect the end of the reply by
receiving 0 bytes.

  But if you plan to reuse your socket for further transfers, you need
to realize that _there is no_ EOT (End of Transfer) _on a socket._ I
repeat: if a socket `send' or `recv' returns after handling 0 bytes,
the connection has been broken.  If the connection has _not_ been
broken, you may wait on a `recv' forever, because the socket will _not_
tell you that there's nothing more to read (for now).  Now if you think
about that a bit, you'll come to realize a fundamental truth of
sockets: _messages must either be fixed length_ (yuck), _or be
delimited_ (shrug), _or indicate how long they are_ (much better), _or
end by shutting down the connection_. The choice is entirely yours,
(but some ways are righter than others).

  Assuming you don't want to end the connection, the simplest solution
is a fixed length message:

    class mysocket:
        """demonstration class only
          - coded for clarity, not efficiency
        """

        def __init__(self, sock=None):
            if sock is None:
                self.sock = socket.socket(
                                socket.AF_INET, socket.SOCK_STREAM)
                else:
                    self.sock = sock

        def connect(self, host, port):
            self.sock.connect((host, port))

        def mysend(self, msg):
            totalsent = 0
            while totalsent < MSGLEN:
                sent = self.sock.send(msg[totalsent:])
                if sent == 0:
                    raise RuntimeError("socket connection broken")
                totalsent = totalsent + sent

        def myreceive(self):
            msg = ''
            while len(msg) < MSGLEN:
                chunk = self.sock.recv(MSGLEN-len(msg))
                if chunk == '':
                    raise RuntimeError("socket connection broken")
                msg = msg + chunk
            return msg

The sending code here is usable for almost any messaging scheme - in
Python you send strings, and you can use `len()' to determine its
length (even if it has embedded `\0' characters). It's mostly the
receiving code that gets more complex. (And in C, it's not much worse,
except you can't use `strlen' if the message has embedded `\0's.)

  The easiest enhancement is to make the first character of the message
an indicator of message type, and have the type determine the length.
Now you have two `recv's - the first to get (at least) that first
character so you can look up the length, and the second in a loop to
get the rest. If you decide to go the delimited route, you'll be
receiving in some arbitrary chunk size, (4096 or 8192 is frequently a
good match for network buffer sizes), and scanning what you've received
for a delimiter.

  One complication to be aware of: if your conversational protocol
allows multiple messages to be sent back to back (without some kind of
reply), and you pass `recv' an arbitrary chunk size, you may end up
reading the start of a following message. You'll need to put that aside
and hold onto it, until it's needed.

  Prefixing the message with it's length (say, as 5 numeric characters)
gets more complex, because (believe it or not), you may not get all 5
characters in one `recv'. In playing around, you'll get away with it;
but in high network loads, your code will very quickly break unless you
use two `recv' loops - the first to determine the length, the second to
get the data part of the message. Nasty.  This is also when you'll
discover that `send' does not always manage to get rid of everything in
one pass. And despite having read this, you will eventually get bit by
it!

  In the interests of space, building your character, (and preserving my
competitive position), these enhancements are left as an exercise for
the reader. Lets move on to cleaning up.

* Menu:

* Binary Data::


File: python-howto-3.2.2.info,  Node: Binary Data,  Up: Using a Socket

10.3.1 Binary Data
------------------

It is perfectly possible to send binary data over a socket. The major
problem is that not all machines use the same formats for binary data.
For example, a Motorola chip will represent a 16 bit integer with the
value 1 as the two hex bytes 00 01. Intel and DEC, however, are
byte-reversed - that same 1 is 01 00.  Socket libraries have calls for
converting 16 and 32 bit integers - `ntohl, htonl, ntohs, htons' where
"n" means _network_ and "h" means _host_, "s" means _short_ and "l"
means _long_. Where network order is host order, these do nothing, but
where the machine is byte-reversed, these swap the bytes around
appropriately.

  In these days of 32 bit machines, the ascii representation of binary
data is frequently smaller than the binary representation. That's
because a surprising amount of the time, all those longs have the value
0, or maybe 1. The string "0" would be two bytes, while binary is four.
Of course, this doesn't fit well with fixed-length messages. Decisions,
decisions.


File: python-howto-3.2.2.info,  Node: Disconnecting,  Next: Non-blocking Sockets,  Prev: Using a Socket,  Up: Socket Programming HOWTO

10.4 Disconnecting
==================

Strictly speaking, you're supposed to use `shutdown' on a socket before
you `close' it.  The `shutdown' is an advisory to the socket at the
other end.  Depending on the argument you pass it, it can mean "I'm not
going to send anymore, but I'll still listen", or "I'm not listening,
good riddance!".  Most socket libraries, however, are so used to
programmers neglecting to use this piece of etiquette that normally a
`close' is the same as `shutdown(); close()'.  So in most situations,
an explicit `shutdown' is not needed.

  One way to use `shutdown' effectively is in an HTTP-like exchange.
The client sends a request and then does a `shutdown(1)'. This tells
the server "This client is done sending, but can still receive."  The
server can detect "EOF" by a receive of 0 bytes. It can assume it has
the complete request.  The server sends a reply. If the `send'
completes successfully then, indeed, the client was still receiving.

  Python takes the automatic shutdown a step further, and says that
when a socket is garbage collected, it will automatically do a `close'
if it's needed. But relying on this is a very bad habit. If your socket
just disappears without doing a `close', the socket at the other end
may hang indefinitely, thinking you're just being slow. _Please_
`close' your sockets when you're done.

* Menu:

* When Sockets Die::


File: python-howto-3.2.2.info,  Node: When Sockets Die,  Up: Disconnecting

10.4.1 When Sockets Die
-----------------------

Probably the worst thing about using blocking sockets is what happens
when the other side comes down hard (without doing a `close'). Your
socket is likely to hang. SOCKSTREAM is a reliable protocol, and it
will wait a long, long time before giving up on a connection. If you're
using threads, the entire thread is essentially dead. There's not much
you can do about it. As long as you aren't doing something dumb, like
holding a lock while doing a blocking read, the thread isn't really
consuming much in the way of resources. Do _not_ try to kill the thread
- part of the reason that threads are more efficient than processes is
that they avoid the overhead associated with the automatic recycling of
resources. In other words, if you do manage to kill the thread, your
whole process is likely to be screwed up.


File: python-howto-3.2.2.info,  Node: Non-blocking Sockets,  Prev: Disconnecting,  Up: Socket Programming HOWTO

10.5 Non-blocking Sockets
=========================

If you've understood the preceding, you already know most of what you
need to know about the mechanics of using sockets. You'll still use the
same calls, in much the same ways. It's just that, if you do it right,
your app will be almost inside-out.

  In Python, you use `socket.setblocking(0)' to make it non-blocking.
In C, it's more complex, (for one thing, you'll need to choose between
the BSD flavor `O_NONBLOCK' and the almost indistinguishable Posix
flavor `O_NDELAY', which is completely different from `TCP_NODELAY'),
but it's the exact same idea. You do this after creating the socket,
but before using it. (Actually, if you're nuts, you can switch back and
forth.)

  The major mechanical difference is that `send', `recv', `connect' and
`accept' can return without having done anything. You have (of course) a
number of choices. You can check return code and error codes and
generally drive yourself crazy. If you don't believe me, try it
sometime. Your app will grow large, buggy and suck CPU. So let's skip
the brain-dead solutions and do it right.

  Use `select'.

  In C, coding `select' is fairly complex. In Python, it's a piece of
cake, but it's close enough to the C version that if you understand
`select' in Python, you'll have little trouble with it in C:

    ready_to_read, ready_to_write, in_error = \
                   select.select(
                      potential_readers,
                      potential_writers,
                      potential_errs,
                      timeout)

You pass `select' three lists: the first contains all sockets that you
might want to try reading; the second all the sockets you might want to
try writing to, and the last (normally left empty) those that you want
to check for errors.  You should note that a socket can go into more
than one list. The `select' call is blocking, but you can give it a
timeout. This is generally a sensible thing to do - give it a nice long
timeout (say a minute) unless you have good reason to do otherwise.

  In return, you will get three lists. They contain the sockets that
are actually readable, writable and in error. Each of these lists is a
subset (possibly empty) of the corresponding list you passed in.

  If a socket is in the output readable list, you can be
as-close-to-certain-as-we-ever-get-in-this-business that a `recv' on
that socket will return _something_. Same idea for the writable list.
You'll be able to send _something_. Maybe not all you want to, but
_something_ is better than nothing.  (Actually, any reasonably healthy
socket will return as writable - it just means outbound network buffer
space is available.)

  If you have a "server" socket, put it in the potential_readers list.
If it comes out in the readable list, your `accept' will (almost
certainly) work. If you have created a new socket to `connect' to
someone else, put it in the potential_writers list. If it shows up in
the writable list, you have a decent chance that it has connected.

  One very nasty problem with `select': if somewhere in those input
lists of sockets is one which has died a nasty death, the `select' will
fail. You then need to loop through every single damn socket in all
those lists and do a `select([sock],[],[],0)' until you find the bad
one. That timeout of 0 means it won't take long, but it's ugly.

  Actually, `select' can be handy even with blocking sockets. It's one
way of determining whether you will block - the socket returns as
readable when there's something in the buffers.  However, this still
doesn't help with the problem of determining whether the other end is
done, or just busy with something else.

  *Portability alert*: On Unix, `select' works both with the sockets and
files. Don't try this on Windows. On Windows, `select' works with
sockets only. Also note that in C, many of the more advanced socket
options are done differently on Windows. In fact, on Windows I usually
use threads (which work very, very well) with my sockets. Face it, if
you want any kind of performance, your code will look very different on
Windows than on Unix.

* Menu:

* Performance::


File: python-howto-3.2.2.info,  Node: Performance,  Up: Non-blocking Sockets

10.5.1 Performance
------------------

There's no question that the fastest sockets code uses non-blocking
sockets and select to multiplex them. You can put together something
that will saturate a LAN connection without putting any strain on the
CPU. The trouble is that an app written this way can't do much of
anything else - it needs to be ready to shuffle bytes around at all
times.

  Assuming that your app is actually supposed to do something more than
that, threading is the optimal solution, (and using non-blocking
sockets will be faster than using blocking sockets). Unfortunately,
threading support in Unixes varies both in API and quality. So the
normal Unix solution is to fork a subprocess to deal with each
connection. The overhead for this is significant (and don't do this on
Windows - the overhead of process creation is enormous there). It also
means that unless each subprocess is completely independent, you'll
need to use another form of IPC, say a pipe, or shared memory and
semaphores, to communicate between the parent and child processes.

  Finally, remember that even though blocking sockets are somewhat
slower than non-blocking, in many cases they are the "right" solution.
After all, if your app is driven by the data it receives over a socket,
there's not much sense in complicating the logic just so your app can
wait on `select' instead of `recv'.


File: python-howto-3.2.2.info,  Node: Sorting HOW TO,  Next: Unicode HOWTO,  Prev: Socket Programming HOWTO,  Up: Top

11 Sorting HOW TO
*****************

     Author: Andrew Dalke and Raymond Hettinger

     Release: 0.1

  Python lists have a built-in `list.sort()' method that modifies the
list in-place.  There is also a `sorted()' built-in function that
builds a new sorted list from an iterable.

  In this document, we explore the various techniques for sorting data
using Python.

* Menu:

* Sorting Basics::
* Key Functions::
* Operator Module Functions::
* Ascending and Descending::
* Sort Stability and Complex Sorts::
* The Old Way Using Decorate-Sort-Undecorate::
* The Old Way Using the cmp Parameter::
* Odd and Ends::


File: python-howto-3.2.2.info,  Node: Sorting Basics,  Next: Key Functions,  Up: Sorting HOW TO

11.1 Sorting Basics
===================

A simple ascending sort is very easy: just call the `sorted()'
function. It returns a new sorted list:

    >>> sorted([5, 2, 3, 1, 4])
    [1, 2, 3, 4, 5]

You can also use the `list.sort()' method. It modifies the list
in-place (and returns _None_ to avoid confusion). Usually it's less
convenient than `sorted()' - but if you don't need the original list,
it's slightly more efficient.

    >>> a = [5, 2, 3, 1, 4]
    >>> a.sort()
    >>> a
    [1, 2, 3, 4, 5]

Another difference is that the `list.sort()' method is only defined for
lists. In contrast, the `sorted()' function accepts any iterable.

    >>> sorted({1: 'D', 2: 'B', 3: 'B', 4: 'E', 5: 'A'})
    [1, 2, 3, 4, 5]



File: python-howto-3.2.2.info,  Node: Key Functions,  Next: Operator Module Functions,  Prev: Sorting Basics,  Up: Sorting HOW TO

11.2 Key Functions
==================

Both `list.sort()' and `sorted()' have _key_ parameter to specify a
function to be called on each list element prior to making comparisons.

  For example, here's a case-insensitive string comparison:

    >>> sorted("This is a test string from Andrew".split(), key=str.lower)
    ['a', 'Andrew', 'from', 'is', 'string', 'test', 'This']

The value of the _key_ parameter should be a function that takes a
single argument and returns a key to use for sorting purposes. This
technique is fast because the key function is called exactly once for
each input record.

  A common pattern is to sort complex objects using some of the
object's indices as keys. For example:

    >>> student_tuples = [
        ('john', 'A', 15),
        ('jane', 'B', 12),
        ('dave', 'B', 10),
    ]
    >>> sorted(student_tuples, key=lambda student: student[2])   # sort by age
    [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

The same technique works for objects with named attributes. For example:

    >>> class Student:
            def __init__(self, name, grade, age):
                self.name = name
                self.grade = grade
                self.age = age
            def __repr__(self):
                return repr((self.name, self.grade, self.age))


    >>> student_objects = [
        Student('john', 'A', 15),
        Student('jane', 'B', 12),
        Student('dave', 'B', 10),
    ]
    >>> sorted(student_objects, key=lambda student: student.age)   # sort by age
    [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]



File: python-howto-3.2.2.info,  Node: Operator Module Functions,  Next: Ascending and Descending,  Prev: Key Functions,  Up: Sorting HOW TO

11.3 Operator Module Functions
==============================

The key-function patterns shown above are very common, so Python
provides convenience functions to make accessor functions easier and
faster. The `operator' module has `itemgetter()', `attrgetter()', and
an `methodcaller()' function.

  Using those functions, the above examples become simpler and faster:

    >>> from operator import itemgetter, attrgetter


    >>> sorted(student_tuples, key=itemgetter(2))
    [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]


    >>> sorted(student_objects, key=attrgetter('age'))
    [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

The operator module functions allow multiple levels of sorting. For
example, to sort by _grade_ then by _age_:

    >>> sorted(student_tuples, key=itemgetter(1,2))
    [('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)]


    >>> sorted(student_objects, key=attrgetter('grade', 'age'))
    [('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)]



File: python-howto-3.2.2.info,  Node: Ascending and Descending,  Next: Sort Stability and Complex Sorts,  Prev: Operator Module Functions,  Up: Sorting HOW TO

11.4 Ascending and Descending
=============================

Both `list.sort()' and `sorted()' accept a _reverse_ parameter with a
boolean value. This is using to flag descending sorts. For example, to
get the student data in reverse _age_ order:

    >>> sorted(student_tuples, key=itemgetter(2), reverse=True)
    [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]


    >>> sorted(student_objects, key=attrgetter('age'), reverse=True)
    [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]



File: python-howto-3.2.2.info,  Node: Sort Stability and Complex Sorts,  Next: The Old Way Using Decorate-Sort-Undecorate,  Prev: Ascending and Descending,  Up: Sorting HOW TO

11.5 Sort Stability and Complex Sorts
=====================================

Sorts are guaranteed to be stable(1). That means that when multiple
records have the same key, their original order is preserved.

    >>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]
    >>> sorted(data, key=itemgetter(0))
    [('blue', 1), ('blue', 2), ('red', 1), ('red', 2)]

Notice how the two records for _blue_ retain their original order so
that `('blue', 1)' is guaranteed to precede `('blue', 2)'.

  This wonderful property lets you build complex sorts in a series of
sorting steps. For example, to sort the student data by descending
_grade_ and then ascending _age_, do the _age_ sort first and then sort
again using _grade_:

    >>> s = sorted(student_objects, key=attrgetter('age'))     # sort on secondary key
    >>> sorted(s, key=attrgetter('grade'), reverse=True)       # now sort on primary key, descending
    [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

The Timsort(2) algorithm used in Python does multiple sorts efficiently
because it can take advantage of any ordering already present in a
dataset.

  ---------- Footnotes ----------

  (1) http://en.wikipedia.org/wiki/Sorting_algorithm#Stability

  (2) http://en.wikipedia.org/wiki/Timsort


File: python-howto-3.2.2.info,  Node: The Old Way Using Decorate-Sort-Undecorate,  Next: The Old Way Using the cmp Parameter,  Prev: Sort Stability and Complex Sorts,  Up: Sorting HOW TO

11.6 The Old Way Using Decorate-Sort-Undecorate
===============================================

This idiom is called Decorate-Sort-Undecorate after its three steps:

   * First, the initial list is decorated with new values that control
     the sort order.

   * Second, the decorated list is sorted.

   * Finally, the decorations are removed, creating a list that
     contains only the initial values in the new order.

  For example, to sort the student data by _grade_ using the DSU
approach:

    >>> decorated = [(student.grade, i, student) for i, student in enumerate(student_objects)]
    >>> decorated.sort()
    >>> [student for grade, i, student in decorated]               # undecorate
    [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]

This idiom works because tuples are compared lexicographically; the
first items are compared; if they are the same then the second items
are compared, and so on.

  It is not strictly necessary in all cases to include the index _i_ in
the decorated list, but including it gives two benefits:

   * The sort is stable - if two items have the same key, their order
     will be preserved in the sorted list.

   * The original items do not have to be comparable because the
     ordering of the decorated tuples will be determined by at most the
     first two items. So for example the original list could contain
     complex numbers which cannot be sorted directly.

  Another name for this idiom is Schwartzian transform(1), after Randal
L. Schwartz, who popularized it among Perl programmers.

  Now that Python sorting provides key-functions, this technique is not
often needed.

  ---------- Footnotes ----------

  (1) http://en.wikipedia.org/wiki/Schwartzian_transform


File: python-howto-3.2.2.info,  Node: The Old Way Using the cmp Parameter,  Next: Odd and Ends,  Prev: The Old Way Using Decorate-Sort-Undecorate,  Up: Sorting HOW TO

11.7 The Old Way Using the _cmp_ Parameter
==========================================

Many constructs given in this HOWTO assume Python 2.4 or later. Before
that, there was no `sorted()' builtin and `list.sort()' took no keyword
arguments. Instead, all of the Py2.x versions supported a _cmp_
parameter to handle user specified comparison functions.

  In Py3.0, the _cmp_ parameter was removed entirely (as part of a
larger effort to simplify and unify the language, eliminating the
conflict between rich comparisons and the `__cmp__()' magic method).

  In Py2.x, sort allowed an optional function which can be called for
doing the comparisons. That function should take two arguments to be
compared and then return a negative value for less-than, return zero if
they are equal, or return a positive value for greater-than. For
example, we can do:

    >>> def numeric_compare(x, y):
            return x - y
    >>> sorted([5, 2, 4, 1, 3], cmp=numeric_compare)
    [1, 2, 3, 4, 5]

Or you can reverse the order of comparison with:

    >>> def reverse_numeric(x, y):
            return y - x
    >>> sorted([5, 2, 4, 1, 3], cmp=reverse_numeric)
    [5, 4, 3, 2, 1]

When porting code from Python 2.x to 3.x, the situation can arise when
you have the user supplying a comparison function and you need to
convert that to a key function. The following wrapper makes that easy
to do:

    def cmp_to_key(mycmp):
        'Convert a cmp= function into a key= function'
        class K(object):
            def __init__(self, obj, *args):
                self.obj = obj
            def __lt__(self, other):
                return mycmp(self.obj, other.obj) < 0
            def __gt__(self, other):
                return mycmp(self.obj, other.obj) > 0
            def __eq__(self, other):
                return mycmp(self.obj, other.obj) == 0
            def __le__(self, other):
                return mycmp(self.obj, other.obj) <= 0
            def __ge__(self, other):
                return mycmp(self.obj, other.obj) >= 0
            def __ne__(self, other):
                return mycmp(self.obj, other.obj) != 0
        return K

To convert to a key function, just wrap the old comparison function:

    >>> sorted([5, 2, 4, 1, 3], key=cmp_to_key(reverse_numeric))
    [5, 4, 3, 2, 1]

In Python 3.2, the `functools.cmp_to_key()' function was added to the
`functools' module in the standard library.


File: python-howto-3.2.2.info,  Node: Odd and Ends,  Prev: The Old Way Using the cmp Parameter,  Up: Sorting HOW TO

11.8 Odd and Ends
=================

   * For locale aware sorting, use `locale.strxfrm()' for a key
     function or `locale.strcoll()' for a comparison function.

   * The _reverse_ parameter still maintains sort stability (so that
     records with equal keys retain the original order). Interestingly,
     that effect can be simulated without the parameter by using the
     builtin `reversed()' function twice:

         >>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]
         >>> assert sorted(data, reverse=True) == list(reversed(sorted(reversed(data))))


   * The sort routines are guaranteed to use `__lt__()' when making
     comparisons between two objects. So, it is easy to add a standard
     sort order to a class by defining an `__lt__()' method:

         >>> Student.__lt__ = lambda self, other: self.age < other.age
         >>> sorted(student_objects)
         [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]


   * Key functions need not depend directly on the objects being
     sorted. A key function can also access external resources. For
     instance, if the student grades are stored in a dictionary, they
     can be used to sort a separate list of student names:

         >>> students = ['dave', 'john', 'jane']
         >>> newgrades = {'john': 'F', 'jane':'A', 'dave': 'C'}
         >>> sorted(students, key=newgrades.__getitem__)
         ['jane', 'dave', 'john']




File: python-howto-3.2.2.info,  Node: Unicode HOWTO,  Next: HOWTO Fetch Internet Resources Using The urllib Package,  Prev: Sorting HOW TO,  Up: Top

12 Unicode HOWTO
****************

     Release: 1.12

  This HOWTO discusses Python support for Unicode, and explains various
problems that people commonly encounter when trying to work with
Unicode.

* Menu:

* Introduction to Unicode::
* Python's Unicode Support::
* Reading and Writing Unicode Data::
* Acknowledgements::

Introduction to Unicode

* History of Character Codes::
* Definitions::
* Encodings::
* References: References<2>.

Python's Unicode Support

* The String Type::
* Converting to Bytes::
* Unicode Literals in Python Source Code::
* Unicode Properties::
* References: References<3>.

Reading and Writing Unicode Data

* Unicode filenames::
* Tips for Writing Unicode-aware Programs::
* References: References<4>.


File: python-howto-3.2.2.info,  Node: Introduction to Unicode,  Next: Python's Unicode Support,  Up: Unicode HOWTO

12.1 Introduction to Unicode
============================

* Menu:

* History of Character Codes::
* Definitions::
* Encodings::
* References: References<2>.


File: python-howto-3.2.2.info,  Node: History of Character Codes,  Next: Definitions,  Up: Introduction to Unicode

12.1.1 History of Character Codes
---------------------------------

In 1968, the American Standard Code for Information Interchange, better
known by its acronym ASCII, was standardized.  ASCII defined numeric
codes for various characters, with the numeric values running from 0 to
127.  For example, the lowercase letter 'a' is assigned 97 as its code
value.

  ASCII was an American-developed standard, so it only defined
unaccented characters.  There was an 'e', but no '' or ''.  This
meant that languages which required accented characters couldn't be
faithfully represented in ASCII.  (Actually the missing accents matter
for English, too, which contains words such as 'nave' and 'caf', and
some publications have house styles which require spellings such as
'coperate'.)

  For a while people just wrote programs that didn't display accents.
I remember looking at Apple ][ BASIC programs, published in
French-language publications in the mid-1980s, that had lines like
these:

    PRINT "FICHIER EST COMPLETE."
    PRINT "CARACTERE NON ACCEPTE."

Those messages should contain accents, and they just look wrong to
someone who can read French.

  In the 1980s, almost all personal computers were 8-bit, meaning that
bytes could hold values ranging from 0 to 255.  ASCII codes only went
up to 127, so some machines assigned values between 128 and 255 to
accented characters.  Different machines had different codes, however,
which led to problems exchanging files.  Eventually various commonly
used sets of values for the 128-255 range emerged.  Some were true
standards, defined by the International Standards Organization, and
some were *de facto* conventions that were invented by one company or
another and managed to catch on.

  255 characters aren't very many.  For example, you can't fit both the
accented characters used in Western Europe and the Cyrillic alphabet
used for Russian into the 128-255 range because there are more than 127
such characters.

  You could write files using different codes (all your Russian files
in a coding system called KOI8, all your French files in a different
coding system called Latin1), but what if you wanted to write a French
document that quotes some Russian text?  In the 1980s people began to
want to solve this problem, and the Unicode standardization effort
began.

  Unicode started out using 16-bit characters instead of 8-bit
characters.  16 bits means you have 2^16 = 65,536 distinct values
available, making it possible to represent many different characters
from many different alphabets; an initial goal was to have Unicode
contain the alphabets for every single human language.  It turns out
that even 16 bits isn't enough to meet that goal, and the modern
Unicode specification uses a wider range of codes, 0 through 1,114,111
(0x10ffff in base 16).

  There's a related ISO standard, ISO 10646.  Unicode and ISO 10646 were
originally separate efforts, but the specifications were merged with
the 1.1 revision of Unicode.

  (This discussion of Unicode's history is highly simplified.  I don't
think the average Python programmer needs to worry about the historical
details; consult the Unicode consortium site listed in the References
for more information.)


File: python-howto-3.2.2.info,  Node: Definitions,  Next: Encodings,  Prev: History of Character Codes,  Up: Introduction to Unicode

12.1.2 Definitions
------------------

A *character* is the smallest possible component of a text.  'A', 'B',
'C', etc., are all different characters.  So are '' and ''.
Characters are abstractions, and vary depending on the language or
context you're talking about.  For example, the symbol for ohms () is
usually drawn much like the capital letter omega () in the Greek
alphabet (they may even be the same in some fonts), but these are two
different characters that have different meanings.

  The Unicode standard describes how characters are represented by *code
points*.  A code point is an integer value, usually denoted in base 16.
In the standard, a code point is written using the notation U+12ca to
mean the character with value 0x12ca (4,810 decimal).  The Unicode
standard contains a lot of tables listing characters and their
corresponding code points:

    0061    'a'; LATIN SMALL LETTER A
    0062    'b'; LATIN SMALL LETTER B
    0063    'c'; LATIN SMALL LETTER C
    ...
    007B    '{'; LEFT CURLY BRACKET

Strictly, these definitions imply that it's meaningless to say 'this is
character U+12ca'.  U+12ca is a code point, which represents some
particular character; in this case, it represents the character
'ETHIOPIC SYLLABLE WI'.  In informal contexts, this distinction between
code points and characters will sometimes be forgotten.

  A character is represented on a screen or on paper by a set of
graphical elements that's called a *glyph*.  The glyph for an uppercase
A, for example, is two diagonal strokes and a horizontal stroke, though
the exact details will depend on the font being used.  Most Python code
doesn't need to worry about glyphs; figuring out the correct glyph to
display is generally the job of a GUI toolkit or a terminal's font
renderer.


File: python-howto-3.2.2.info,  Node: Encodings,  Next: References<2>,  Prev: Definitions,  Up: Introduction to Unicode

12.1.3 Encodings
----------------

To summarize the previous section: a Unicode string is a sequence of
code points, which are numbers from 0 through 0x10ffff (1,114,111
decimal).  This sequence needs to be represented as a set of bytes
(meaning, values from 0 through 255) in memory.  The rules for
translating a Unicode string into a sequence of bytes are called an
*encoding*.

  The first encoding you might think of is an array of 32-bit integers.
In this representation, the string "Python" would look like this:

       P           y           t           h           o           n
    0x50 00 00 00 79 00 00 00 74 00 00 00 68 00 00 00 6f 00 00 00 6e 00 00 00
       0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

This representation is straightforward but using it presents a number of
problems.

  1. It's not portable; different processors order the bytes
     differently.

  2. It's very wasteful of space.  In most texts, the majority of the
     code points are less than 127, or less than 255, so a lot of space
     is occupied by zero bytes.  The above string takes 24 bytes
     compared to the 6 bytes needed for an ASCII representation.
     Increased RAM usage doesn't matter too much (desktop computers
     have megabytes of RAM, and strings aren't usually that large), but
     expanding our usage of disk and network bandwidth by a factor of 4
     is intolerable.

  3. It's not compatible with existing C functions such as `strlen()',
     so a new family of wide string functions would need to be used.

  4. Many Internet standards are defined in terms of textual data, and
     can't handle content with embedded zero bytes.

  Generally people don't use this encoding, instead choosing other
encodings that are more efficient and convenient.  UTF-8 is probably
the most commonly supported encoding; it will be discussed below.

  Encodings don't have to handle every possible Unicode character, and
most encodings don't.  The rules for converting a Unicode string into
the ASCII encoding, for example, are simple; for each code point:

  1. If the code point is < 128, each byte is the same as the value of
     the code point.

  2. If the code point is 128 or greater, the Unicode string can't be
     represented in this encoding.  (Python raises a
     `UnicodeEncodeError' exception in this case.)

  Latin-1, also known as ISO-8859-1, is a similar encoding.  Unicode
code points 0-255 are identical to the Latin-1 values, so converting to
this encoding simply requires converting code points to byte values; if
a code point larger than 255 is encountered, the string can't be
encoded into Latin-1.

  Encodings don't have to be simple one-to-one mappings like Latin-1.
Consider IBM's EBCDIC, which was used on IBM mainframes.  Letter values
weren't in one block: 'a' through 'i' had values from 129 to 137, but
'j' through 'r' were 145 through 153.  If you wanted to use EBCDIC as
an encoding, you'd probably use some sort of lookup table to perform
the conversion, but this is largely an internal detail.

  UTF-8 is one of the most commonly used encodings.  UTF stands for
"Unicode Transformation Format", and the '8' means that 8-bit numbers
are used in the encoding.  (There's also a UTF-16 encoding, but it's
less frequently used than UTF-8.)  UTF-8 uses the following rules:

  1. If the code point is <128, it's represented by the corresponding
     byte value.

  2. If the code point is between 128 and 0x7ff, it's turned into two
     byte values between 128 and 255.

  3. Code points >0x7ff are turned into three- or four-byte sequences,
     where each byte of the sequence is between 128 and 255.

  UTF-8 has several convenient properties:

  1. It can handle any Unicode code point.

  2. A Unicode string is turned into a string of bytes containing no
     embedded zero bytes.  This avoids byte-ordering issues, and means
     UTF-8 strings can be processed by C functions such as `strcpy()'
     and sent through protocols that can't handle zero bytes.

  3. A string of ASCII text is also valid UTF-8 text.

  4. UTF-8 is fairly compact; the majority of code points are turned
     into two bytes, and values less than 128 occupy only a single byte.

  5. If bytes are corrupted or lost, it's possible to determine the
     start of the next UTF-8-encoded code point and resynchronize.
     It's also unlikely that random 8-bit data will look like valid
     UTF-8.


File: python-howto-3.2.2.info,  Node: References<2>,  Prev: Encodings,  Up: Introduction to Unicode

12.1.4 References
-----------------

The Unicode Consortium site at <<http://www.unicode.org>> has character
charts, a glossary, and PDF versions of the Unicode specification.  Be
prepared for some difficult reading.
<<http://www.unicode.org/history/>> is a chronology of the origin and
development of Unicode.

  To help understand the standard, Jukka Korpela has written an
introductory guide to reading the Unicode character tables, available at
<<http://www.cs.tut.fi/~jkorpela/unicode/guide.html>>.

  Another good introductory article was written by Joel Spolsky
<<http://www.joelonsoftware.com/articles/Unicode.html>>.  If this
introduction didn't make things clear to you, you should try reading
this alternate article before continuing.

  Wikipedia entries are often helpful; see the entries for "character
encoding" <<http://en.wikipedia.org/wiki/Character_encoding>> and UTF-8
<<http://en.wikipedia.org/wiki/UTF-8>>, for example.


File: python-howto-3.2.2.info,  Node: Python's Unicode Support,  Next: Reading and Writing Unicode Data,  Prev: Introduction to Unicode,  Up: Unicode HOWTO

12.2 Python's Unicode Support
=============================

Now that you've learned the rudiments of Unicode, we can look at
Python's Unicode features.

* Menu:

* The String Type::
* Converting to Bytes::
* Unicode Literals in Python Source Code::
* Unicode Properties::
* References: References<3>.


File: python-howto-3.2.2.info,  Node: The String Type,  Next: Converting to Bytes,  Up: Python's Unicode Support

12.2.1 The String Type
----------------------

Since Python 3.0, the language features a `str' type that contain
Unicode characters, meaning any string created using `"unicode
rocks!"', `'unicode rocks!'', or the triple-quoted string syntax is
stored as Unicode.

  To insert a Unicode character that is not part ASCII, e.g., any
letters with accents, one can use escape sequences in their string
literals as such:

    >>> "\N{GREEK CAPITAL LETTER DELTA}"  # Using the character name
    '\u0394'
    >>> "\u0394"                          # Using a 16-bit hex value
    '\u0394'
    >>> "\U00000394"                      # Using a 32-bit hex value
    '\u0394'

In addition, one can create a string using the `decode()' method of
`bytes'.  This method takes an encoding, such as UTF-8, and, optionally,
an _errors_ argument.

  The _errors_ argument specifies the response when the input string
can't be converted according to the encoding's rules.  Legal values for
this argument are 'strict' (raise a `UnicodeDecodeError' exception),
'replace' (use U+FFFD, 'REPLACEMENT CHARACTER'), or 'ignore' (just
leave the character out of the Unicode result).  The following examples
show the differences:

    >>> b'\x80abc'.decode("utf-8", "strict")
    Traceback (most recent call last):
      File "<stdin>", line 1, in ?
    UnicodeDecodeError: 'utf8' codec can't decode byte 0x80 in position 0:
                        unexpected code byte
    >>> b'\x80abc'.decode("utf-8", "replace")
    '?abc'
    >>> b'\x80abc'.decode("utf-8", "ignore")
    'abc'

(In this code example, the Unicode replacement character has been
replaced by a question mark because it may not be displayed on some
systems.)

  Encodings are specified as strings containing the encoding's name.
Python 3.2 comes with roughly 100 different encodings; see the Python
Library Reference at _standard-encodings_ for a list.  Some encodings
have multiple names; for example, 'latin-1', 'iso_8859_1' and '8859'
are all synonyms for the same encoding.

  One-character Unicode strings can also be created with the `chr()'
built-in function, which takes integers and returns a Unicode string of
length 1 that contains the corresponding code point.  The reverse
operation is the built-in `ord()' function that takes a one-character
Unicode string and returns the code point value:

    >>> chr(57344)
    '\ue000'
    >>> ord('\ue000')
    57344



File: python-howto-3.2.2.info,  Node: Converting to Bytes,  Next: Unicode Literals in Python Source Code,  Prev: The String Type,  Up: Python's Unicode Support

12.2.2 Converting to Bytes
--------------------------

Another important str method is `.encode([encoding],
[errors='strict'])', which returns a `bytes' representation of the
Unicode string, encoded in the requested encoding.  The `errors'
parameter is the same as the parameter of the `decode()' method, with
one additional possibility; as well as 'strict', 'ignore', and
'replace' (which in this case inserts a question mark instead of the
unencodable character), you can also pass 'xmlcharrefreplace' which uses
XML's character references.  The following example shows the different
results:

    >>> u = chr(40960) + 'abcd' + chr(1972)
    >>> u.encode('utf-8')
    b'\xea\x80\x80abcd\xde\xb4'
    >>> u.encode('ascii')
    Traceback (most recent call last):
      File "<stdin>", line 1, in ?
    UnicodeEncodeError: 'ascii' codec can't encode character '\ua000' in
                        position 0: ordinal not in range(128)
    >>> u.encode('ascii', 'ignore')
    b'abcd'
    >>> u.encode('ascii', 'replace')
    b'?abcd?'
    >>> u.encode('ascii', 'xmlcharrefreplace')
    b'&#40960;abcd&#1972;'

The low-level routines for registering and accessing the available
encodings are found in the `codecs' module.  However, the encoding and
decoding functions returned by this module are usually more low-level
than is comfortable, so I'm not going to describe the `codecs' module
here.  If you need to implement a completely new encoding, you'll need
to learn about the `codecs' module interfaces, but implementing
encodings is a specialized task that also won't be covered here.
Consult the Python documentation to learn more about this module.


File: python-howto-3.2.2.info,  Node: Unicode Literals in Python Source Code,  Next: Unicode Properties,  Prev: Converting to Bytes,  Up: Python's Unicode Support

12.2.3 Unicode Literals in Python Source Code
---------------------------------------------

In Python source code, specific Unicode code points can be written
using the `\u' escape sequence, which is followed by four hex digits
giving the code point.  The `\U' escape sequence is similar, but
expects eight hex digits, not four:

    >>> s = "a\xac\u1234\u20ac\U00008000"
              ^^^^ two-digit hex escape
                   ^^^^^ four-digit Unicode escape
                              ^^^^^^^^^^ eight-digit Unicode escape
    >>> for c in s:  print(ord(c), end=" ")
    ...
    97 172 4660 8364 32768

Using escape sequences for code points greater than 127 is fine in
small doses, but becomes an annoyance if you're using many accented
characters, as you would in a program with messages in French or some
other accent-using language.  You can also assemble strings using the
`chr()' built-in function, but this is even more tedious.

  Ideally, you'd want to be able to write literals in your language's
natural encoding.  You could then edit Python source code with your
favorite editor which would display the accented characters naturally,
and have the right characters used at runtime.

  Python supports writing source code in UTF-8 by default, but you can
use almost any encoding if you declare the encoding being used.  This
is done by including a special comment as either the first or second
line of the source file:

    #!/usr/bin/env python
    # -*- coding: latin-1 -*-

    u = 'abcd'
    print(ord(u[-1]))

The syntax is inspired by Emacs's notation for specifying variables
local to a file.  Emacs supports many different variables, but Python
only supports 'coding'.  The `-*-' symbols indicate to Emacs that the
comment is special; they have no significance to Python but are a
convention.  Python looks for `coding: name' or `coding=name' in the
comment.

  If you don't include such a comment, the default encoding used will
be UTF-8 as already mentioned.


File: python-howto-3.2.2.info,  Node: Unicode Properties,  Next: References<3>,  Prev: Unicode Literals in Python Source Code,  Up: Python's Unicode Support

12.2.4 Unicode Properties
-------------------------

The Unicode specification includes a database of information about code
points.  For each code point that's defined, the information includes
the character's name, its category, the numeric value if applicable
(Unicode has characters representing the Roman numerals and fractions
such as one-third and four-fifths).  There are also properties related
to the code point's use in bidirectional text and other display-related
properties.

  The following program displays some information about several
characters, and prints the numeric value of one particular character:

    import unicodedata

    u = chr(233) + chr(0x0bf2) + chr(3972) + chr(6000) + chr(13231)

    for i, c in enumerate(u):
        print(i, '%04x' % ord(c), unicodedata.category(c), end=" ")
        print(unicodedata.name(c))

    # Get numeric value of second character
    print(unicodedata.numeric(u[1]))

When run, this prints:

    0 00e9 Ll LATIN SMALL LETTER E WITH ACUTE
    1 0bf2 No TAMIL NUMBER ONE THOUSAND
    2 0f84 Mn TIBETAN MARK HALANTA
    3 1770 Lo TAGBANWA LETTER SA
    4 33af So SQUARE RAD OVER S SQUARED
    1000.0

The category codes are abbreviations describing the nature of the
character.  These are grouped into categories such as "Letter",
"Number", "Punctuation", or "Symbol", which in turn are broken up into
subcategories.  To take the codes from the above output, `'Ll'' means
'Letter, lowercase', `'No'' means "Number, other", `'Mn'' is "Mark,
nonspacing", and `'So'' is "Symbol, other".  See
<<http://www.unicode.org/reports/tr44/#General_Category_Values>> for a
list of category codes.


File: python-howto-3.2.2.info,  Node: References<3>,  Prev: Unicode Properties,  Up: Python's Unicode Support

12.2.5 References
-----------------

The `str' type is described in the Python library reference at
_typesseq_.

  The documentation for the `unicodedata' module.

  The documentation for the `codecs' module.

  Marc-Andr Lemburg gave a presentation at EuroPython 2002 titled
"Python and Unicode".  A PDF version of his slides is available at
<<http://downloads.egenix.com/python/Unicode-EPC2002-Talk.pdf>>, and is
an excellent overview of the design of Python's Unicode features (based
on Python 2, where the Unicode string type is called `unicode' and
literals start with `u').


File: python-howto-3.2.2.info,  Node: Reading and Writing Unicode Data,  Next: Acknowledgements,  Prev: Python's Unicode Support,  Up: Unicode HOWTO

12.3 Reading and Writing Unicode Data
=====================================

Once you've written some code that works with Unicode data, the next
problem is input/output.  How do you get Unicode strings into your
program, and how do you convert Unicode into a form suitable for
storage or transmission?

  It's possible that you may not need to do anything depending on your
input sources and output destinations; you should check whether the
libraries used in your application support Unicode natively.  XML
parsers often return Unicode data, for example.  Many relational
databases also support Unicode-valued columns and can return Unicode
values from an SQL query.

  Unicode data is usually converted to a particular encoding before it
gets written to disk or sent over a socket.  It's possible to do all
the work yourself: open a file, read an 8-bit byte string from it, and
convert the string with `str(bytes, encoding)'.  However, the manual
approach is not recommended.

  One problem is the multi-byte nature of encodings; one Unicode
character can be represented by several bytes.  If you want to read the
file in arbitrary-sized chunks (say, 1K or 4K), you need to write
error-handling code to catch the case where only part of the bytes
encoding a single Unicode character are read at the end of a chunk.
One solution would be to read the entire file into memory and then
perform the decoding, but that prevents you from working with files that
are extremely large; if you need to read a 2Gb file, you need 2Gb of
RAM.  (More, really, since for at least a moment you'd need to have
both the encoded string and its Unicode version in memory.)

  The solution would be to use the low-level decoding interface to
catch the case of partial coding sequences.  The work of implementing
this has already been done for you: the built-in `open()' function can
return a file-like object that assumes the file's contents are in a
specified encoding and accepts Unicode parameters for methods such as
`.read()' and `.write()'.  This works through `open()''s _encoding_ and
_errors_ parameters which are interpreted just like those in string
objects' `encode()' and `decode()' methods.

  Reading Unicode from a file is therefore simple:

    with open('unicode.rst', encoding='utf-8') as f:
        for line in f:
            print(repr(line))

It's also possible to open files in update mode, allowing both reading
and writing:

    with open('test', encoding='utf-8', mode='w+') as f:
        f.write('\u4500 blah blah blah\n')
        f.seek(0)
        print(repr(f.readline()[:1]))

The Unicode character U+FEFF is used as a byte-order mark (BOM), and is
often written as the first character of a file in order to assist with
autodetection of the file's byte ordering.  Some encodings, such as
UTF-16, expect a BOM to be present at the start of a file; when such an
encoding is used, the BOM will be automatically written as the first
character and will be silently dropped when the file is read.  There
are variants of these encodings, such as 'utf-16-le' and 'utf-16-be'
for little-endian and big-endian encodings, that specify one particular
byte ordering and don't skip the BOM.

  In some areas, it is also convention to use a "BOM" at the start of
UTF-8 encoded files; the name is misleading since UTF-8 is not
byte-order dependent.  The mark simply announces that the file is
encoded in UTF-8.  Use the 'utf-8-sig' codec to automatically skip the
mark if present for reading such files.

* Menu:

* Unicode filenames::
* Tips for Writing Unicode-aware Programs::
* References: References<4>.


File: python-howto-3.2.2.info,  Node: Unicode filenames,  Next: Tips for Writing Unicode-aware Programs,  Up: Reading and Writing Unicode Data

12.3.1 Unicode filenames
------------------------

Most of the operating systems in common use today support filenames
that contain arbitrary Unicode characters.  Usually this is implemented
by converting the Unicode string into some encoding that varies
depending on the system.  For example, Mac OS X uses UTF-8 while
Windows uses a configurable encoding; on Windows, Python uses the name
"mbcs" to refer to whatever the currently configured encoding is.  On
Unix systems, there will only be a filesystem encoding if you've set
the `LANG' or `LC_CTYPE' environment variables; if you haven't, the
default encoding is ASCII.

  The `sys.getfilesystemencoding()' function returns the encoding to
use on your current system, in case you want to do the encoding
manually, but there's not much reason to bother.  When opening a file
for reading or writing, you can usually just provide the Unicode string
as the filename, and it will be automatically converted to the right
encoding for you:

    filename = 'filename\u4500abc'
    with open(filename, 'w') as f:
        f.write('blah\n')

Functions in the `os' module such as `os.stat()' will also accept
Unicode filenames.

  Function `os.listdir()', which returns filenames, raises an issue:
should it return the Unicode version of filenames, or should it return
byte strings containing the encoded versions?  `os.listdir()' will do
both, depending on whether you provided the directory path as a byte
string or a Unicode string.  If you pass a Unicode string as the path,
filenames will be decoded using the filesystem's encoding and a list of
Unicode strings will be returned, while passing a byte path will return
the byte string versions of the filenames.  For example, assuming the
default filesystem encoding is UTF-8, running the following program:

    fn = 'filename\u4500abc'
    f = open(fn, 'w')
    f.close()

    import os
    print(os.listdir(b'.'))
    print(os.listdir('.'))

will produce the following output:

    amk:~$ python t.py
    [b'.svn', b'filename\xe4\x94\x80abc', ...]
    ['.svn', 'filename\u4500abc', ...]

The first list contains UTF-8-encoded filenames, and the second list
contains the Unicode versions.

  Note that in most occasions, the Unicode APIs should be used.  The
bytes APIs should only be used on systems where undecodable file names
can be present, i.e. Unix systems.


File: python-howto-3.2.2.info,  Node: Tips for Writing Unicode-aware Programs,  Next: References<4>,  Prev: Unicode filenames,  Up: Reading and Writing Unicode Data

12.3.2 Tips for Writing Unicode-aware Programs
----------------------------------------------

This section provides some suggestions on writing software that deals
with Unicode.

  The most important tip is:

     Software should only work with Unicode strings internally,
     converting to a particular encoding on output.

  If you attempt to write processing functions that accept both Unicode
and byte strings, you will find your program vulnerable to bugs
wherever you combine the two different kinds of strings.  There is no
automatic encoding or decoding if you do e.g. `str + bytes', a
`TypeError' is raised for this expression.

  When using data coming from a web browser or some other untrusted
source, a common technique is to check for illegal characters in a
string before using the string in a generated command line or storing
it in a database.  If you're doing this, be careful to check the string
once it's in the form that will be used or stored; it's possible for
encodings to be used to disguise characters.  This is especially true
if the input data also specifies the encoding; many encodings leave the
commonly checked-for characters alone, but Python includes some
encodings such as `'base64'' that modify every single character.

  For example, let's say you have a content management system that
takes a Unicode filename, and you want to disallow paths with a '/'
character.  You might write this code:

    def read_file(filename, encoding):
        if '/' in filename:
            raise ValueError("'/' not allowed in filenames")
        unicode_name = filename.decode(encoding)
        with open(unicode_name, 'r') as f:
            # ... return contents of file ...

However, if an attacker could specify the `'base64'' encoding, they
could pass `'L2V0Yy9wYXNzd2Q='', which is the base-64 encoded form of
the string `'/etc/passwd'', to read a system file.  The above code
looks for `'/'' characters in the encoded form and misses the dangerous
character in the resulting decoded form.


File: python-howto-3.2.2.info,  Node: References<4>,  Prev: Tips for Writing Unicode-aware Programs,  Up: Reading and Writing Unicode Data

12.3.3 References
-----------------

The PDF slides for Marc-Andr Lemburg's presentation "Writing
Unicode-aware Applications in Python" are available at
<<http://downloads.egenix.com/python/LSM2005-Developing-Unicode-aware-applications-in-Python.pdf>>
and discuss questions of character encodings as well as how to
internationalize and localize an application.  These slides cover
Python 2.x only.


File: python-howto-3.2.2.info,  Node: Acknowledgements,  Prev: Reading and Writing Unicode Data,  Up: Unicode HOWTO

12.4 Acknowledgements
=====================

Thanks to the following people who have noted errors or offered
suggestions on this article: Nicholas Bastin, Marius Gedminas, Kent
Johnson, Ken Krugler, Marc-Andr Lemburg, Martin von Lwis, Chad
Whitacre.


File: python-howto-3.2.2.info,  Node: HOWTO Fetch Internet Resources Using The urllib Package,  Next: HOWTO Use Python in the web,  Prev: Unicode HOWTO,  Up: Top

13 HOWTO Fetch Internet Resources Using The urllib Package
**********************************************************

     Author: Michael Foord(1)

     Note: There is a French translation of an earlier revision of this
     HOWTO, available at urllib2 - Le Manuel manquant(2).

* Menu:

* Introduction: Introduction<3>.
* Fetching URLs::
* Handling Exceptions::
* info and geturl::
* Openers and Handlers::
* Basic Authentication::
* Proxies::
* Sockets and Layers::
* Footnotes::

  ---------- Footnotes ----------

  (1) http://www.voidspace.org.uk/python/index.shtml

  (2) http://www.voidspace.org.uk/python/articles/urllib2_francais.shtml


File: python-howto-3.2.2.info,  Node: Introduction<3>,  Next: Fetching URLs,  Up: HOWTO Fetch Internet Resources Using The urllib Package

13.1 Introduction
=================

Related Articles
................

You may also find useful the following article on fetching web resources
with Python:

   * Basic Authentication(1)

          A tutorial on _Basic Authentication_, with examples in Python.

  *urllib.request* is a Python(2) module for fetching URLs (Uniform
Resource Locators). It offers a very simple interface, in the form of
the _urlopen_ function. This is capable of fetching URLs using a
variety of different protocols. It also offers a slightly more complex
interface for handling common situations - like basic authentication,
cookies, proxies and so on. These are provided by objects called
handlers and openers.

  urllib.request supports fetching URLs for many "URL schemes"
(identified by the string before the ":" in URL - for example "ftp" is
the URL scheme of "<ftp://python.org/>") using their associated network
protocols (e.g. FTP, HTTP).  This tutorial focuses on the most common
case, HTTP.

  For straightforward situations _urlopen_ is very easy to use. But as
soon as you encounter errors or non-trivial cases when opening HTTP
URLs, you will need some understanding of the HyperText Transfer
Protocol. The most comprehensive and authoritative reference to HTTP is RFC
2616(3). This is a technical document and not intended to be easy to
read. This HOWTO aims to illustrate using _urllib_, with enough detail
about HTTP to help you through. It is not intended to replace the
`urllib.request' docs, but is supplementary to them.

  ---------- Footnotes ----------

  (1) http://www.voidspace.org.uk/python/articles/authentication.shtml

  (2) http://www.python.org

  (3) http://tools.ietf.org/html/rfc2616.html


File: python-howto-3.2.2.info,  Node: Fetching URLs,  Next: Handling Exceptions,  Prev: Introduction<3>,  Up: HOWTO Fetch Internet Resources Using The urllib Package

13.2 Fetching URLs
==================

The simplest way to use urllib.request is as follows:

    import urllib.request
    response = urllib.request.urlopen('http://python.org/')
    html = response.read()

Many uses of urllib will be that simple (note that instead of an
'http:' URL we could have used an URL starting with 'ftp:', 'file:',
etc.).  However, it's the purpose of this tutorial to explain the more
complicated cases, concentrating on HTTP.

  HTTP is based on requests and responses - the client makes requests
and servers send responses. urllib.request mirrors this with a
`Request' object which represents the HTTP request you are making. In
its simplest form you create a Request object that specifies the URL
you want to fetch. Calling `urlopen' with this Request object returns a
response object for the URL requested. This response is a file-like
object, which means you can for example call `.read()' on the response:

    import urllib.request

    req = urllib.request.Request('http://www.voidspace.org.uk')
    response = urllib.request.urlopen(req)
    the_page = response.read()

Note that urllib.request makes use of the same Request interface to
handle all URL schemes.  For example, you can make an FTP request like
so:

    req = urllib.request.Request('ftp://example.com/')

In the case of HTTP, there are two extra things that Request objects
allow you to do: First, you can pass data to be sent to the server.
Second, you can pass extra information ("metadata") _about_ the data or
the about request itself, to the server - this information is sent as
HTTP "headers".  Let's look at each of these in turn.

* Menu:

* Data::
* Headers::


File: python-howto-3.2.2.info,  Node: Data,  Next: Headers,  Up: Fetching URLs

13.2.1 Data
-----------

Sometimes you want to send data to a URL (often the URL will refer to a
CGI (Common Gateway Interface) script (1) or other web application).
With HTTP, this is often done using what's known as a *POST* request.
This is often what your browser does when you submit a HTML form that
you filled in on the web. Not all POSTs have to come from forms: you
can use a POST to transmit arbitrary data to your own application. In
the common case of HTML forms, the data needs to be encoded in a
standard way, and then passed to the Request object as the `data'
argument. The encoding is done using a function from the `urllib.parse'
library.

    import urllib.parse
    import urllib.request

    url = 'http://www.someserver.com/cgi-bin/register.cgi'
    values = {'name' : 'Michael Foord',
              'location' : 'Northampton',
              'language' : 'Python' }

    data = urllib.parse.urlencode(values)
    req = urllib.request.Request(url, data)
    response = urllib.request.urlopen(req)
    the_page = response.read()

Note that other encodings are sometimes required (e.g. for file upload
from HTML forms - see HTML Specification, Form Submission(2) for more
details).

  If you do not pass the `data' argument, urllib uses a *GET* request.
One way in which GET and POST requests differ is that POST requests
often have "side-effects": they change the state of the system in some
way (for example by placing an order with the website for a
hundredweight of tinned spam to be delivered to your door).  Though the
HTTP standard makes it clear that POSTs are intended to _always_ cause
side-effects, and GET requests _never_ to cause side-effects, nothing
prevents a GET request from having side-effects, nor a POST requests
from having no side-effects. Data can also be passed in an HTTP GET
request by encoding it in the URL itself.

  This is done as follows:

    >>> import urllib.request
    >>> import urllib.parse
    >>> data = {}
    >>> data['name'] = 'Somebody Here'
    >>> data['location'] = 'Northampton'
    >>> data['language'] = 'Python'
    >>> url_values = urllib.parse.urlencode(data)
    >>> print(url_values)
    name=Somebody+Here&language=Python&location=Northampton
    >>> url = 'http://www.example.com/example.cgi'
    >>> full_url = url + '?' + url_values
    >>> data = urllib.request.urlopen(full_url)

Notice that the full URL is created by adding a `?' to the URL,
followed by the encoded values.

  ---------- Footnotes ----------

  (1) For an introduction to the CGI protocol see Writing Web
Applications in Python
(http://www.pyzine.com/Issue008/Section_Articles/article_CGIOne.html).

  (2) http://www.w3.org/TR/REC-html40/interact/forms.html#h-17.13


File: python-howto-3.2.2.info,  Node: Headers,  Prev: Data,  Up: Fetching URLs

13.2.2 Headers
--------------

We'll discuss here one particular HTTP header, to illustrate how to add
headers to your HTTP request.

  Some websites (1) dislike being browsed by programs, or send
different versions to different browsers (2) . By default urllib
identifies itself as `Python-urllib/x.y' (where `x' and `y' are the
major and minor version numbers of the Python release, e.g.
`Python-urllib/2.5'), which may confuse the site, or just plain not
work. The way a browser identifies itself is through the `User-Agent'
header (3). When you create a Request object you can pass a dictionary
of headers in. The following example makes the same request as above,
but identifies itself as a version of Internet Explorer (4).

    import urllib.parse
    import urllib.request

    url = 'http://www.someserver.com/cgi-bin/register.cgi'
    user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'
    values = {'name' : 'Michael Foord',
              'location' : 'Northampton',
              'language' : 'Python' }
    headers = { 'User-Agent' : user_agent }

    data = urllib.parse.urlencode(values)
    req = urllib.request.Request(url, data, headers)
    response = urllib.request.urlopen(req)
    the_page = response.read()

The response also has two useful methods. See the section on *note info
and geturl: f5.  which comes after we have a look at what happens when
things go wrong.

  ---------- Footnotes ----------

  (1) Like Google for example. The _proper_ way to use google from a
program is to use PyGoogle (http://pygoogle.sourceforge.net) of course.
See Voidspace Google
(http://www.voidspace.org.uk/python/recipebook.shtml#google) for some
examples of using the Google API.

  (2) Browser sniffing is a very bad practise for website design -
building sites using web standards is much more sensible. Unfortunately
a lot of sites still send different versions to different browsers.

  (3) The user agent for MSIE 6 is _'Mozilla/4.0 (compatible; MSIE 6.0;
Windows NT 5.1; SV1; .NET CLR 1.1.4322)'_

  (4) For details of more HTTP request headers, see Quick Reference to
HTTP Headers (http://www.cs.tut.fi/~jkorpela/http.html).


File: python-howto-3.2.2.info,  Node: Handling Exceptions,  Next: info and geturl,  Prev: Fetching URLs,  Up: HOWTO Fetch Internet Resources Using The urllib Package

13.3 Handling Exceptions
========================

_urlopen_ raises `URLError' when it cannot handle a response (though as
usual with Python APIs, built-in exceptions such as `ValueError',
`TypeError' etc. may also be raised).

  `HTTPError' is the subclass of `URLError' raised in the specific case
of HTTP URLs.

  The exception classes are exported from the `urllib.error' module.

* Menu:

* URLError::
* HTTPError::
* Wrapping it Up::


File: python-howto-3.2.2.info,  Node: URLError,  Next: HTTPError,  Up: Handling Exceptions

13.3.1 URLError
---------------

Often, URLError is raised because there is no network connection (no
route to the specified server), or the specified server doesn't exist.
In this case, the exception raised will have a 'reason' attribute,
which is a tuple containing an error code and a text error message.

  e.g.

    >>> req = urllib.request.Request('http://www.pretend_server.org')
    >>> try: urllib.request.urlopen(req)
    >>> except urllib.error.URLError as e:
    >>>    print(e.reason)
    >>>
    (4, 'getaddrinfo failed')



File: python-howto-3.2.2.info,  Node: HTTPError,  Next: Wrapping it Up,  Prev: URLError,  Up: Handling Exceptions

13.3.2 HTTPError
----------------

Every HTTP response from the server contains a numeric "status code".
Sometimes the status code indicates that the server is unable to fulfil
the request. The default handlers will handle some of these responses
for you (for example, if the response is a "redirection" that requests
the client fetch the document from a different URL, urllib will handle
that for you). For those it can't handle, urlopen will raise an
`HTTPError'. Typical errors include '404' (page not found), '403'
(request forbidden), and '401' (authentication required).

  See section 10 of RFC 2616 for a reference on all the HTTP error
codes.

  The `HTTPError' instance raised will have an integer 'code'
attribute, which corresponds to the error sent by the server.

* Menu:

* Error Codes::


File: python-howto-3.2.2.info,  Node: Error Codes,  Up: HTTPError

13.3.2.1 Error Codes
....................

Because the default handlers handle redirects (codes in the 300 range),
and codes in the 100-299 range indicate success, you will usually only
see error codes in the 400-599 range.

  `http.server.BaseHTTPRequestHandler.responses' is a useful dictionary
of response codes in that shows all the response codes used by RFC
2616. The dictionary is reproduced here for convenience

    # Table mapping response codes to messages; entries have the
    # form {code: (shortmessage, longmessage)}.
    responses = {
        100: ('Continue', 'Request received, please continue'),
        101: ('Switching Protocols',
              'Switching to new protocol; obey Upgrade header'),

        200: ('OK', 'Request fulfilled, document follows'),
        201: ('Created', 'Document created, URL follows'),
        202: ('Accepted',
              'Request accepted, processing continues off-line'),
        203: ('Non-Authoritative Information', 'Request fulfilled from cache'),
        204: ('No Content', 'Request fulfilled, nothing follows'),
        205: ('Reset Content', 'Clear input form for further input.'),
        206: ('Partial Content', 'Partial content follows.'),

        300: ('Multiple Choices',
              'Object has several resources -- see URI list'),
        301: ('Moved Permanently', 'Object moved permanently -- see URI list'),
        302: ('Found', 'Object moved temporarily -- see URI list'),
        303: ('See Other', 'Object moved -- see Method and URL list'),
        304: ('Not Modified',
              'Document has not changed since given time'),
        305: ('Use Proxy',
              'You must use proxy specified in Location to access this '
              'resource.'),
        307: ('Temporary Redirect',
              'Object moved temporarily -- see URI list'),

        400: ('Bad Request',
              'Bad request syntax or unsupported method'),
        401: ('Unauthorized',
              'No permission -- see authorization schemes'),
        402: ('Payment Required',
              'No payment -- see charging schemes'),
        403: ('Forbidden',
              'Request forbidden -- authorization will not help'),
        404: ('Not Found', 'Nothing matches the given URI'),
        405: ('Method Not Allowed',
              'Specified method is invalid for this server.'),
        406: ('Not Acceptable', 'URI not available in preferred format.'),
        407: ('Proxy Authentication Required', 'You must authenticate with '
              'this proxy before proceeding.'),
        408: ('Request Timeout', 'Request timed out; try again later.'),
        409: ('Conflict', 'Request conflict.'),
        410: ('Gone',
              'URI no longer exists and has been permanently removed.'),
        411: ('Length Required', 'Client must specify Content-Length.'),
        412: ('Precondition Failed', 'Precondition in headers is false.'),
        413: ('Request Entity Too Large', 'Entity is too large.'),
        414: ('Request-URI Too Long', 'URI is too long.'),
        415: ('Unsupported Media Type', 'Entity body in unsupported format.'),
        416: ('Requested Range Not Satisfiable',
              'Cannot satisfy request range.'),
        417: ('Expectation Failed',
              'Expect condition could not be satisfied.'),

        500: ('Internal Server Error', 'Server got itself in trouble'),
        501: ('Not Implemented',
              'Server does not support this operation'),
        502: ('Bad Gateway', 'Invalid responses from another server/proxy.'),
        503: ('Service Unavailable',
              'The server cannot process the request due to a high load'),
        504: ('Gateway Timeout',
              'The gateway server did not receive a timely response'),
        505: ('HTTP Version Not Supported', 'Cannot fulfill request.'),
        }

When an error is raised the server responds by returning an HTTP error
code _and_ an error page. You can use the `HTTPError' instance as a
response on the page returned. This means that as well as the code
attribute, it also has read, geturl, and info, methods as returned by
the `urllib.response' module:

    >>> req = urllib.request.Request('http://www.python.org/fish.html')
    >>> try:
    >>>     urllib.request.urlopen(req)
    >>> except urllib.error.HTTPError as e:
    >>>     print(e.code)
    >>>     print(e.read())
    >>>
    404
    <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
        "http://www.w3.org/TR/html4/loose.dtd">
    <?xml-stylesheet href="./css/ht2html.css"
        type="text/css"?>
    <html><head><title>Error 404: File Not Found</title>
    ...... etc...



File: python-howto-3.2.2.info,  Node: Wrapping it Up,  Prev: HTTPError,  Up: Handling Exceptions

13.3.3 Wrapping it Up
---------------------

So if you want to be prepared for `HTTPError' _or_ `URLError' there are
two basic approaches. I prefer the second approach.

* Menu:

* Number 1::
* Number 2::


File: python-howto-3.2.2.info,  Node: Number 1,  Next: Number 2,  Up: Wrapping it Up

13.3.3.1 Number 1
.................

    from urllib.request import Request, urlopen
    from urllib.error import URLError, HTTPError
    req = Request(someurl)
    try:
        response = urlopen(req)
    except HTTPError as e:
        print('The server couldn\'t fulfill the request.')
        print('Error code: ', e.code)
    except URLError as e:
        print('We failed to reach a server.')
        print('Reason: ', e.reason)
    else:
        # everything is fine


     Note: The `except HTTPError' _must_ come first, otherwise `except
     URLError' will _also_ catch an `HTTPError'.


File: python-howto-3.2.2.info,  Node: Number 2,  Prev: Number 1,  Up: Wrapping it Up

13.3.3.2 Number 2
.................

    from urllib.request import Request, urlopen
    from urllib.error import  URLError
    req = Request(someurl)
    try:
        response = urlopen(req)
    except URLError as e:
        if hasattr(e, 'reason'):
            print('We failed to reach a server.')
            print('Reason: ', e.reason)
        elif hasattr(e, 'code'):
            print('The server couldn\'t fulfill the request.')
            print('Error code: ', e.code)
    else:
        # everything is fine



File: python-howto-3.2.2.info,  Node: info and geturl,  Next: Openers and Handlers,  Prev: Handling Exceptions,  Up: HOWTO Fetch Internet Resources Using The urllib Package

13.4 info and geturl
====================

The response returned by urlopen (or the `HTTPError' instance) has two
useful methods `info()' and `geturl()' and is defined in the module
`urllib.response'..

  *geturl* - this returns the real URL of the page fetched. This is
useful because `urlopen' (or the opener object used) may have followed a
redirect. The URL of the page fetched may not be the same as the URL
requested.

  *info* - this returns a dictionary-like object that describes the page
fetched, particularly the headers sent by the server. It is currently an
`http.client.HTTPMessage' instance.

  Typical headers include 'Content-length', 'Content-type', and so on.
See the Quick Reference to HTTP Headers(1) for a useful listing of HTTP
headers with brief explanations of their meaning and use.

  ---------- Footnotes ----------

  (1) http://www.cs.tut.fi/~jkorpela/http.html


File: python-howto-3.2.2.info,  Node: Openers and Handlers,  Next: Basic Authentication,  Prev: info and geturl,  Up: HOWTO Fetch Internet Resources Using The urllib Package

13.5 Openers and Handlers
=========================

When you fetch a URL you use an opener (an instance of the perhaps
confusingly-named `urllib.request.OpenerDirector'). Normally we have
been using the default opener - via `urlopen' - but you can create
custom openers. Openers use handlers. All the "heavy lifting" is done
by the handlers. Each handler knows how to open URLs for a particular
URL scheme (http, ftp, etc.), or how to handle an aspect of URL
opening, for example HTTP redirections or HTTP cookies.

  You will want to create openers if you want to fetch URLs with
specific handlers installed, for example to get an opener that handles
cookies, or to get an opener that does not handle redirections.

  To create an opener, instantiate an `OpenerDirector', and then call
`.add_handler(some_handler_instance)' repeatedly.

  Alternatively, you can use `build_opener', which is a convenience
function for creating opener objects with a single function call.
`build_opener' adds several handlers by default, but provides a quick
way to add more and/or override the default handlers.

  Other sorts of handlers you might want to can handle proxies,
authentication, and other common but slightly specialised situations.

  `install_opener' can be used to make an `opener' object the (global)
default opener. This means that calls to `urlopen' will use the opener
you have installed.

  Opener objects have an `open' method, which can be called directly to
fetch urls in the same way as the `urlopen' function: there's no need
to call `install_opener', except as a convenience.


File: python-howto-3.2.2.info,  Node: Basic Authentication,  Next: Proxies,  Prev: Openers and Handlers,  Up: HOWTO Fetch Internet Resources Using The urllib Package

13.6 Basic Authentication
=========================

To illustrate creating and installing a handler we will use the
`HTTPBasicAuthHandler'. For a more detailed discussion of this subject -
including an explanation of how Basic Authentication works - see the
Basic Authentication Tutorial(1).

  When authentication is required, the server sends a header (as well
as the 401 error code) requesting authentication.  This specifies the
authentication scheme and a 'realm'. The header looks like :
`Www-authenticate: SCHEME realm="REALM"'.

  e.g.

    Www-authenticate: Basic realm="cPanel Users"

The client should then retry the request with the appropriate name and
password for the realm included as a header in the request. This is
'basic authentication'. In order to simplify this process we can create
an instance of `HTTPBasicAuthHandler' and an opener to use this handler.

  The `HTTPBasicAuthHandler' uses an object called a password manager
to handle the mapping of URLs and realms to passwords and usernames. If
you know what the realm is (from the authentication header sent by the
server), then you can use a `HTTPPasswordMgr'. Frequently one doesn't
care what the realm is. In that case, it is convenient to use
`HTTPPasswordMgrWithDefaultRealm'. This allows you to specify a default
username and password for a URL. This will be supplied in the absence
of you providing an alternative combination for a specific realm. We
indicate this by providing `None' as the realm argument to the
`add_password' method.

  The top-level URL is the first URL that requires authentication. URLs
"deeper" than the URL you pass to .add_password() will also match.

    # create a password manager
    password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()

    # Add the username and password.
    # If we knew the realm, we could use it instead of None.
    top_level_url = "http://example.com/foo/"
    password_mgr.add_password(None, top_level_url, username, password)

    handler = urllib.request.HTTPBasicAuthHandler(password_mgr)

    # create "opener" (OpenerDirector instance)
    opener = urllib.request.build_opener(handler)

    # use the opener to fetch a URL
    opener.open(a_url)

    # Install the opener.
    # Now all calls to urllib.request.urlopen use our opener.
    urllib.request.install_opener(opener)


     Note: In the above example we only supplied our
     `HTTPBasicAuthHandler' to `build_opener'. By default openers have
     the handlers for normal situations - `ProxyHandler',
     `UnknownHandler', `HTTPHandler', `HTTPDefaultErrorHandler',
     `HTTPRedirectHandler', `FTPHandler', `FileHandler',
     `HTTPErrorProcessor'.

  `top_level_url' is in fact _either_ a full URL (including the 'http:'
scheme component and the hostname and optionally the port number) e.g.
"<http://example.com/>" _or_ an "authority" (i.e. the hostname,
optionally including the port number) e.g. "example.com" or
"example.com:8080" (the latter example includes a port number).  The
authority, if present, must NOT contain the "userinfo" component - for
example "joe@password:example.com" is not correct.

  ---------- Footnotes ----------

  (1) http://www.voidspace.org.uk/python/articles/authentication.shtml


File: python-howto-3.2.2.info,  Node: Proxies,  Next: Sockets and Layers,  Prev: Basic Authentication,  Up: HOWTO Fetch Internet Resources Using The urllib Package

13.7 Proxies
============

*urllib* will auto-detect your proxy settings and use those. This is
through the `ProxyHandler' which is part of the normal handler chain.
Normally that's a good thing, but there are occasions when it may not
be helpful (1). One way to do this is to setup our own `ProxyHandler',
with no proxies defined. This is done using similar steps to setting up
a Basic Authentication(2) handler :

    >>> proxy_support = urllib.request.ProxyHandler({})
    >>> opener = urllib.request.build_opener(proxy_support)
    >>> urllib.request.install_opener(opener)


     Note: Currently `urllib.request' _does not_ support fetching of
     `https' locations through a proxy.  However, this can be enabled
     by extending urllib.request as shown in the recipe (3).

  ---------- Footnotes ----------

  (1) In my case I have to use a proxy to access the internet at work.
If you attempt to fetch _localhost_ URLs through this proxy it blocks
them. IE is set to use the proxy, which urllib picks up on. In order to
test scripts with a localhost server, I have to prevent urllib from
using the proxy.

  (2) http://www.voidspace.org.uk/python/articles/authentication.shtml

  (3) urllib opener for SSL proxy (CONNECT method): ASPN Cookbook
Recipe (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/456195).


File: python-howto-3.2.2.info,  Node: Sockets and Layers,  Next: Footnotes,  Prev: Proxies,  Up: HOWTO Fetch Internet Resources Using The urllib Package

13.8 Sockets and Layers
=======================

The Python support for fetching resources from the web is layered.
urllib uses the `http.client' library, which in turn uses the socket
library.

  As of Python 2.3 you can specify how long a socket should wait for a
response before timing out. This can be useful in applications which
have to fetch web pages. By default the socket module has _no timeout_
and can hang. Currently, the socket timeout is not exposed at the
http.client or urllib.request levels.  However, you can set the default
timeout globally for all sockets using

    import socket
    import urllib.request

    # timeout in seconds
    timeout = 10
    socket.setdefaulttimeout(timeout)

    # this call to urllib.request.urlopen now uses the default timeout
    # we have set in the socket module
    req = urllib.request.Request('http://www.voidspace.org.uk')
    response = urllib.request.urlopen(req)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 



File: python-howto-3.2.2.info,  Node: Footnotes,  Prev: Sockets and Layers,  Up: HOWTO Fetch Internet Resources Using The urllib Package

13.9 Footnotes
==============

This document was reviewed and revised by John Lee.


File: python-howto-3.2.2.info,  Node: HOWTO Use Python in the web,  Next: Index,  Prev: HOWTO Fetch Internet Resources Using The urllib Package,  Up: Top

14 HOWTO Use Python in the web
******************************

     Author: Marek Kubica

Abstract
--------

This document shows how Python fits into the web.  It presents some ways
to integrate Python with a web server, and general practices useful for
developing web sites.

  Programming for the Web has become a hot topic since the rise of "Web
2.0", which focuses on user-generated content on web sites.  It has
always been possible to use Python for creating web sites, but it was a
rather tedious task.  Therefore, many frameworks and helper tools have
been created to assist developers in creating faster and more robust
sites.  This HOWTO describes some of the methods used to combine Python
with a web server to create dynamic content.  It is not meant as a
complete introduction, as this topic is far too broad to be covered in
one single document.  However, a short overview of the most popular
libraries is provided.

See also
--------

While this HOWTO tries to give an overview of Python in the web, it
cannot always be as up to date as desired.  Web development in Python
is rapidly moving forward, so the wiki page on Web Programming(1) may
be more in sync with recent development.

* Menu:

* The Low-Level View::
* Step back; WSGI: Step back WSGI.
* Model-View-Controller::
* Ingredients for Websites::
* Frameworks::

The Low-Level View

* Common Gateway Interface::
* mod_python::
* FastCGI and SCGI::
* mod_wsgi::

Common Gateway Interface

* Simple script for testing CGI::
* Setting up CGI on your own server::
* Common problems with CGI scripts::

FastCGI and SCGI

* Setting up FastCGI::

Step back: WSGI

* WSGI Servers::
* Case study; MoinMoin: Case study MoinMoin.

Ingredients for Websites

* Templates::
* Data persistence::

Frameworks

* Some notable frameworks::

Some notable frameworks

* Django::
* TurboGears::
* Zope::
* Other notable frameworks::

  ---------- Footnotes ----------

  (1) http://wiki.python.org/moin/WebProgramming


File: python-howto-3.2.2.info,  Node: The Low-Level View,  Next: Step back WSGI,  Up: HOWTO Use Python in the web

14.1 The Low-Level View
=======================

When a user enters a web site, their browser makes a connection to the
site's web server (this is called the _request_).  The server looks up
the file in the file system and sends it back to the user's browser,
which displays it (this is the _response_).  This is roughly how the
underlying protocol, HTTP, works.

  Dynamic web sites are not based on files in the file system, but
rather on programs which are run by the web server when a request comes
in, and which _generate_ the content that is returned to the user.
They can do all sorts of useful things, like display the postings of a
bulletin board, show your email, configure software, or just display
the current time.  These programs can be written in any programming
language the server supports.  Since most servers support Python, it is
easy to use Python to create dynamic web sites.

  Most HTTP servers are written in C or C++, so they cannot execute
Python code directly - a bridge is needed between the server and the
program.  These bridges, or rather interfaces, define how programs
interact with the server.  There have been numerous attempts to create
the best possible interface, but there are only a few worth mentioning.

  Not every web server supports every interface.  Many web servers only
support old, now-obsolete interfaces; however, they can often be
extended using third-party modules to support newer ones.

* Menu:

* Common Gateway Interface::
* mod_python::
* FastCGI and SCGI::
* mod_wsgi::

Common Gateway Interface

* Simple script for testing CGI::
* Setting up CGI on your own server::
* Common problems with CGI scripts::

FastCGI and SCGI

* Setting up FastCGI::


File: python-howto-3.2.2.info,  Node: Common Gateway Interface,  Next: mod_python,  Up: The Low-Level View

14.1.1 Common Gateway Interface
-------------------------------

This interface, most commonly referred to as "CGI", is the oldest, and
is supported by nearly every web server out of the box.  Programs using
CGI to communicate with their web server need to be started by the
server for every request.  So, every request starts a new Python
interpreter - which takes some time to start up - thus making the whole
interface only usable for low load situations.

  The upside of CGI is that it is simple - writing a Python program
which uses CGI is a matter of about three lines of code.  This
simplicity comes at a price: it does very few things to help the
developer.

  Writing CGI programs, while still possible, is no longer recommended.
With *note WSGI: 106, a topic covered later in this document, it is
possible to write programs that emulate CGI, so they can be run as CGI
if no better option is available.

See also
........

The Python standard library includes some modules that are helpful for
creating plain CGI programs:

   * `cgi' - Handling of user input in CGI scripts

   * `cgitb' - Displays nice tracebacks when errors happen in CGI
     applications, instead of presenting a "500 Internal Server Error"
     message

  The Python wiki features a page on CGI scripts(1) with some
additional information about CGI in Python.

* Menu:

* Simple script for testing CGI::
* Setting up CGI on your own server::
* Common problems with CGI scripts::

  ---------- Footnotes ----------

  (1) http://wiki.python.org/moin/CgiScripts


File: python-howto-3.2.2.info,  Node: Simple script for testing CGI,  Next: Setting up CGI on your own server,  Up: Common Gateway Interface

14.1.1.1 Simple script for testing CGI
......................................

To test whether your web server works with CGI, you can use this short
and simple CGI program:

    #!/usr/bin/env python
    # -*- coding: UTF-8 -*-

    # enable debugging
    import cgitb
    cgitb.enable()

    print("Content-Type: text/plain;charset=utf-8")
    print()

    print("Hello World!")

Depending on your web server configuration, you may need to save this
code with a `.py' or `.cgi' extension.  Additionally, this file may
also need to be in a `cgi-bin' folder, for security reasons.

  You might wonder what the `cgitb' line is about.  This line makes it
possible to display a nice traceback instead of just crashing and
displaying an "Internal Server Error" in the user's browser.  This is
useful for debugging, but it might risk exposing some confidential data
to the user.  You should not use `cgitb' in production code for this
reason.  You should _always_ catch exceptions, and display proper error
pages - end-users don't like to see nondescript "Internal Server
Errors" in their browsers.


File: python-howto-3.2.2.info,  Node: Setting up CGI on your own server,  Next: Common problems with CGI scripts,  Prev: Simple script for testing CGI,  Up: Common Gateway Interface

14.1.1.2 Setting up CGI on your own server
..........................................

If you don't have your own web server, this does not apply to you.  You
can check whether it works as-is, and if not you will need to talk to
the administrator of your web server. If it is a big host, you can try
filing a ticket asking for Python support.

  If you are your own administrator or want to set up CGI for testing
purposes on your own computers, you have to configure it by yourself.
There is no single way to configure CGI, as there are many web servers
with different configuration options.  Currently the most widely used
free web server is Apache HTTPd(1), or Apache for short. Apache can be
easily installed on nearly every system using the system's package
management tool.  lighttpd(2) is another alternative and is said to
have better performance.  On many systems this server can also be
installed using the package management tool, so manually compiling the
web server may not be needed.

   * On Apache you can take a look at the Dynamic Content with CGI(3)
     tutorial, where everything is described.  Most of the time it is
     enough just to set `+ExecCGI'.  The tutorial also describes the
     most common gotchas that might arise.

   * On lighttpd you need to use the CGI module(4), which can be
     configured in a straightforward way.  It boils down to setting
     `cgi.assign' properly.

  ---------- Footnotes ----------

  (1) http://httpd.apache.org/

  (2) http://www.lighttpd.net

  (3) http://httpd.apache.org/docs/2.2/howto/cgi.html

  (4) http://redmine.lighttpd.net/wiki/lighttpd/Docs:ModCGI


File: python-howto-3.2.2.info,  Node: Common problems with CGI scripts,  Prev: Setting up CGI on your own server,  Up: Common Gateway Interface

14.1.1.3 Common problems with CGI scripts
.........................................

Using CGI sometimes leads to small annoyances while trying to get these
scripts to run.  Sometimes a seemingly correct script does not work as
expected, the cause being some small hidden problem that's difficult to
spot.

  Some of these potential problems are:

   * The Python script is not marked as executable.  When CGI scripts
     are not executable most web servers will let the user download it,
     instead of running it and sending the output to the user.  For CGI
     scripts to run properly on Unix-like operating systems, the `+x'
     bit needs to be set.  Using `chmod a+x your_script.py' may solve
     this problem.

   * On a Unix-like system, The line endings in the program file must
     be Unix style line endings.  This is important because the web
     server checks the first line of the script (called shebang) and
     tries to run the program specified there.  It gets easily confused
     by Windows line endings (Carriage Return & Line Feed, also called
     CRLF), so you have to convert the file to Unix line endings (only
     Line Feed, LF).  This can be done automatically by uploading the
     file via FTP in text mode instead of binary mode, but the
     preferred way is just telling your editor to save the files with
     Unix line endings.  Most editors support this.

   * Your web server must be able to read the file, and you need to
     make sure the permissions are correct.  On unix-like systems, the
     server often runs as user and group `www-data', so it might be
     worth a try to change the file ownership, or making the file world
     readable by using `chmod a+r your_script.py'.

   * The web server must know that the file you're trying to access is
     a CGI script.  Check the configuration of your web server, as it
     may be configured to expect a specific file extension for CGI
     scripts.

   * On Unix-like systems, the path to the interpreter in the shebang
     (`#!/usr/bin/env python') must be correct.  This line calls
     `/usr/bin/env' to find Python, but it will fail if there is no
     `/usr/bin/env', or if Python is not in the web server's path.  If
     you know where your Python is installed, you can also use that
     full path.  The commands `whereis python' and `type -p python'
     could help you find where it is installed.  Once you know the
     path, you can change the shebang accordingly: `#!/usr/bin/python'.

   * The file must not contain a BOM (Byte Order Mark). The BOM is
     meant for determining the byte order of UTF-16 and UTF-32
     encodings, but some editors write this also into UTF-8 files.  The
     BOM interferes with the shebang line, so be sure to tell your
     editor not to write the BOM.

   * If the web server is using *note mod_python: 10a, `mod_python' may
     be having problems.  `mod_python' is able to handle CGI scripts by
     itself, but it can also be a source of issues.


File: python-howto-3.2.2.info,  Node: mod_python,  Next: FastCGI and SCGI,  Prev: Common Gateway Interface,  Up: The Low-Level View

14.1.2 mod_python
-----------------

People coming from PHP often find it hard to grasp how to use Python in
the web.  Their first thought is mostly mod_python(1), because they
think that this is the equivalent to `mod_php'.  Actually, there are
many differences.  What `mod_python' does is embed the interpreter into
the Apache process, thus speeding up requests by not having to start a
Python interpreter for each request.  On the other hand, it is not
"Python intermixed with HTML" in the way that PHP is often intermixed
with HTML. The Python equivalent of that is a template engine.
`mod_python' itself is much more powerful and provides more access to
Apache internals.  It can emulate CGI, work in a "Python Server Pages"
mode (similar to JSP) which is "HTML intermingled with Python", and it
has a "Publisher" which designates one file to accept all requests and
decide what to do with them.

  `mod_python' does have some problems.  Unlike the PHP interpreter,
the Python interpreter uses caching when executing files, so changes to
a file will require the web server to be restarted.  Another problem is
the basic concept - Apache starts child processes to handle the
requests, and unfortunately every child process needs to load the whole
Python interpreter even if it does not use it.  This makes the whole
web server slower.  Another problem is that, because `mod_python' is
linked against a specific version of `libpython', it is not possible to
switch from an older version to a newer (e.g. 2.4 to 2.5) without
recompiling `mod_python'.  `mod_python' is also bound to the Apache web
server, so programs written for `mod_python' cannot easily run on other
web servers.

  These are the reasons why `mod_python' should be avoided when writing
new programs.  In some circumstances it still might be a good idea to
use `mod_python' for deployment, but WSGI makes it possible to run WSGI
programs under `mod_python' as well.

  ---------- Footnotes ----------

  (1) http://www.modpython.org/


File: python-howto-3.2.2.info,  Node: FastCGI and SCGI,  Next: mod_wsgi,  Prev: mod_python,  Up: The Low-Level View

14.1.3 FastCGI and SCGI
-----------------------

FastCGI and SCGI try to solve the performance problem of CGI in another
way.  Instead of embedding the interpreter into the web server, they
create long-running background processes. There is still a module in
the web server which makes it possible for the web server to "speak"
with the background process.  As the background process is independent
of the server, it can be written in any language, including Python.
The language just needs to have a library which handles the
communication with the webserver.

  The difference between FastCGI and SCGI is very small, as SCGI is
essentially just a "simpler FastCGI".  As the web server support for
SCGI is limited, most people use FastCGI instead, which works the same
way.  Almost everything that applies to SCGI also applies to FastCGI as
well, so we'll only cover the latter.

  These days, FastCGI is never used directly.  Just like `mod_python',
it is only used for the deployment of WSGI applications.

See also
........

   * FastCGI, SCGI, and Apache: Background and Future(1) is a
     discussion on why the concept of FastCGI and SCGI is better that
     that of mod_python.

* Menu:

* Setting up FastCGI::

  ---------- Footnotes ----------

  (1)
http://www.vmunix.com/mark/blog/archives/2006/01/02/fastcgi-scgi-and-apache-background-and-future/


File: python-howto-3.2.2.info,  Node: Setting up FastCGI,  Up: FastCGI and SCGI

14.1.3.1 Setting up FastCGI
...........................

Each web server requires a specific module.

   * Apache has both mod_fastcgi(1) and mod_fcgid(2).  `mod_fastcgi' is
     the original one, but it has some licensing issues, which is why
     it is sometimes considered non-free.  `mod_fcgid' is a smaller,
     compatible alternative.  One of these modules needs to be loaded
     by Apache.

   * lighttpd ships its own FastCGI module(3) as well as an SCGI
     module(4).

   * nginx(5) also supports FastCGI(6).

  Once you have installed and configured the module, you can test it
with the following WSGI-application:

    #!/usr/bin/env python
    # -*- coding: UTF-8 -*-

    import sys, os
    from html import escape
    from flup.server.fcgi import WSGIServer

    def app(environ, start_response):
        start_response('200 OK', [('Content-Type', 'text/html')])

        yield '<h1>FastCGI Environment</h1>'
        yield '<table>'
        for k, v in sorted(environ.items()):
             yield '<tr><th>{0}</th><td>{1}</td></tr>'.format(
                 escape(k), escape(v))
        yield '</table>'

    WSGIServer(app).run()

This is a simple WSGI application, but you need to install flup(7)
first, as flup handles the low level FastCGI access.

See also
........

There is some documentation on setting up Django with FastCGI(8), most
of which can be reused for other WSGI-compliant frameworks and
libraries.  Only the `manage.py' part has to be changed, the example
used here can be used instead.  Django does more or less the exact same
thing.

  ---------- Footnotes ----------

  (1) http://www.fastcgi.com/drupal/

  (2) http://fastcgi.coremail.cn/

  (3) http://redmine.lighttpd.net/wiki/lighttpd/Docs:ModFastCGI

  (4) http://redmine.lighttpd.net/wiki/lighttpd/Docs:ModSCGI

  (5) http://nginx.org/

  (6) http://wiki.nginx.org/NginxSimplePythonFCGI

  (7) http://pypi.python.org/pypi/flup/1.0

  (8) http://docs.djangoproject.com/en/dev/howto/deployment/fastcgi/


File: python-howto-3.2.2.info,  Node: mod_wsgi,  Prev: FastCGI and SCGI,  Up: The Low-Level View

14.1.4 mod_wsgi
---------------

mod_wsgi(1) is an attempt to get rid of the low level gateways.  Given
that FastCGI, SCGI, and mod_python are mostly used to deploy WSGI
applications, mod_wsgi was started to directly embed WSGI applications
into the Apache web server. mod_wsgi is specifically designed to host
WSGI applications.  It makes the deployment of WSGI applications much
easier than deployment using other low level methods, which need glue
code.  The downside is that mod_wsgi is limited to the Apache web
server; other servers would need their own implementations of mod_wsgi.

  mod_wsgi supports two modes: embedded mode, in which it integrates
with the Apache process, and daemon mode, which is more FastCGI-like.
Unlike FastCGI, mod_wsgi handles the worker-processes by itself, which
makes administration easier.

  ---------- Footnotes ----------

  (1) http://code.google.com/p/modwsgi/


File: python-howto-3.2.2.info,  Node: Step back WSGI,  Next: Model-View-Controller,  Prev: The Low-Level View,  Up: HOWTO Use Python in the web

14.2 Step back: WSGI
====================

WSGI has already been mentioned several times, so it has to be something
important.  In fact it really is, and now it is time to explain it.

  The _Web Server Gateway Interface_,  or WSGI for short, is defined in PEP
333(1) and is currently the best way to do Python web programming.
While it is great for programmers writing frameworks, a normal web
developer does not need to get in direct contact with it.  When
choosing a framework for web development it is a good idea to choose
one which supports WSGI.

  The big benefit of WSGI is the unification of the application
programming interface.  When your program is compatible with WSGI -
which at the outer level means that the framework you are using has
support for WSGI - your program can be deployed via any web server
interface for which there are WSGI wrappers.  You do not need to care
about whether the application user uses mod_python or FastCGI or
mod_wsgi - with WSGI your application will work on any gateway
interface.  The Python standard library contains its own WSGI server,
`wsgiref', which is a small web server that can be used for testing.

  A really great WSGI feature is middleware.  Middleware is a layer
around your program which can add various functionality to it.  There
is quite a bit of middleware(2) already available.  For example,
instead of writing your own session management (HTTP is a stateless
protocol, so to associate multiple HTTP requests with a single user
your application must create and manage such state via a session), you
can just download middleware which does that, plug it in, and get on
with coding the unique parts of your application.  The same thing with
compression - there is existing middleware which handles compressing
your HTML using gzip to save on your server's bandwidth.
Authentication is another a problem easily solved using existing
middleware.

  Although WSGI may seem complex, the initial phase of learning can be
very rewarding because WSGI and the associated middleware already have
solutions to many problems that might arise while developing web sites.

* Menu:

* WSGI Servers::
* Case study; MoinMoin: Case study MoinMoin.

  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-0333

  (2) http://wsgi.org/wsgi/Middleware_and_Utilities


File: python-howto-3.2.2.info,  Node: WSGI Servers,  Next: Case study MoinMoin,  Up: Step back WSGI

14.2.1 WSGI Servers
-------------------

The code that is used to connect to various low level gateways like CGI
or mod_python is called a _WSGI server_.  One of these servers is
`flup', which supports FastCGI and SCGI, as well as AJP(1).  Some of
these servers are written in Python, as `flup' is, but there also exist
others which are written in C and can be used as drop-in replacements.

  There are many servers already available, so a Python web application
can be deployed nearly anywhere.  This is one big advantage that Python
has compared with other web technologies.

See also
........

A good overview of WSGI-related code can be found in the WSGI wiki(2),
which contains an extensive list of WSGI servers(3) which can be used
by _any_ application supporting WSGI.

  You might be interested in some WSGI-supporting modules already
contained in the standard library, namely:

   * `wsgiref' - some tiny utilities and servers for WSGI

  ---------- Footnotes ----------

  (1) http://en.wikipedia.org/wiki/Apache_JServ_Protocol

  (2) http://wsgi.org/wsgi

  (3) http://wsgi.org/wsgi/Servers


File: python-howto-3.2.2.info,  Node: Case study MoinMoin,  Prev: WSGI Servers,  Up: Step back WSGI

14.2.2 Case study: MoinMoin
---------------------------

What does WSGI give the web application developer?  Let's take a look at
an application that's been around for a while, which was written in
Python without using WSGI.

  One of the most widely used wiki software packages is MoinMoin(1).
It was created in 2000, so it predates WSGI by about three years.
Older versions needed separate code to run on CGI, mod_python, FastCGI
and standalone.

  It now includes support for WSGI.  Using WSGI, it is possible to
deploy MoinMoin on any WSGI compliant server, with no additional glue
code.  Unlike the pre-WSGI versions, this could include WSGI servers
that the authors of MoinMoin know nothing about.

  ---------- Footnotes ----------

  (1) http://moinmo.in/


File: python-howto-3.2.2.info,  Node: Model-View-Controller,  Next: Ingredients for Websites,  Prev: Step back WSGI,  Up: HOWTO Use Python in the web

14.3 Model-View-Controller
==========================

The term _MVC_ is often encountered in statements such as "framework
_foo_ supports MVC".  MVC is more about the overall organization of
code, rather than any particular API.  Many web frameworks use this
model to help the developer bring structure to their program.  Bigger
web applications can have lots of code, so it is a good idea to have an
effective structure right from the beginning.  That way, even users of
other frameworks (or even other languages, since MVC is not
Python-specific) can easily understand the code, given that they are
already familiar with the MVC structure.

  MVC stands for three components:

   * The _model_.  This is the data that will be displayed and
     modified.  In Python frameworks, this component is often
     represented by the classes used by an object-relational mapper.

   * The _view_.  This component's job is to display the data of the
     model to the user.  Typically this component is implemented via
     templates.

   * The _controller_.  This is the layer between the user and the
     model.  The controller reacts to user actions (like opening some
     specific URL), tells the model to modify the data if necessary,
     and tells the view code what to display,

  While one might think that MVC is a complex design pattern, in fact
it is not.  It is used in Python because it has turned out to be useful
for creating clean, maintainable web sites.

     Note: While not all Python frameworks explicitly support MVC, it
     is often trivial to create a web site which uses the MVC pattern
     by separating the data logic (the model) from the user interaction
     logic (the controller) and the templates (the view).  That's why
     it is important not to write unnecessary Python code in the
     templates - it works against the MVC model and creates chaos in
     the code base, making it harder to understand and modify.

See also
........

The English Wikipedia has an article about the Model-View-Controller
pattern(1).  It includes a long list of web frameworks for various
programming languages.

  ---------- Footnotes ----------

  (1) http://en.wikipedia.org/wiki/Model-view-controller


File: python-howto-3.2.2.info,  Node: Ingredients for Websites,  Next: Frameworks,  Prev: Model-View-Controller,  Up: HOWTO Use Python in the web

14.4 Ingredients for Websites
=============================

Websites are complex constructs, so tools have been created to help web
developers make their code easier to write and more maintainable.
Tools like these exist for all web frameworks in all languages.
Developers are not forced to use these tools, and often there is no
"best" tool.  It is worth learning about the available tools because
they can greatly simplify the process of developing a web site.

See also
........

There are far more components than can be presented here.  The Python
wiki has a page about these components, called Web Components(1).

* Menu:

* Templates::
* Data persistence::

  ---------- Footnotes ----------

  (1) http://wiki.python.org/moin/WebComponents


File: python-howto-3.2.2.info,  Node: Templates,  Next: Data persistence,  Up: Ingredients for Websites

14.4.1 Templates
----------------

Mixing of HTML and Python code is made possible by a few libraries.
While convenient at first, it leads to horribly unmaintainable code.
That's why templates exist.  Templates are, in the simplest case, just
HTML files with placeholders.  The HTML is sent to the user's browser
after filling in the placeholders.

  Python already includes a way to build simple templates:

    # a simple template
    template = "<html><body><h1>Hello {who}!</h1></body></html>"
    print(template.format(who="Reader"))

To generate complex HTML based on non-trivial model data, conditional
and looping constructs like Python's _for_ and _if_ are generally
needed.  _Template engines_ support templates of this complexity.

  There are a lot of template engines available for Python which can be
used with or without a *note framework: 115.  Some of these define a
plain-text programming language which is easy to learn, partly because
it is limited in scope.  Others use XML, and the template output is
guaranteed to be always be valid XML.  There are many other variations.

  Some *note frameworks: 116. ship their own template engine or
recommend one in particular.  In the absence of a reason to use a
different template engine, using the one provided by or recommended by
the framework is a good idea.

  Popular template engines include:

        * Mako(1)

        * Genshi(2)

        * Jinja(3)

See also
........

There are many template engines competing for attention, because it is
pretty easy to create them in Python.  The page Templating(4) in the
wiki lists a big, ever-growing number of these.  The three listed above
are considered "second generation" template engines and are a good
place to start.

  ---------- Footnotes ----------

  (1) http://www.makotemplates.org/

  (2) http://genshi.edgewall.org/

  (3) http://jinja.pocoo.org/2/

  (4) http://wiki.python.org/moin/Templating


File: python-howto-3.2.2.info,  Node: Data persistence,  Prev: Templates,  Up: Ingredients for Websites

14.4.2 Data persistence
-----------------------

_Data persistence_, while sounding very complicated, is just about
storing data.  This data might be the text of blog entries, the
postings on a bulletin board or the text of a wiki page.  There are, of
course, a number of different ways to store information on a web server.

  Often, relational database engines like MySQL(1) or PostgreSQL(2) are
used because of their good performance when handling very large
databases consisting of millions of entries.  There is also a small
database engine called SQLite(3), which is bundled with Python in the
`sqlite3' module, and which uses only one file.  It has no other
dependencies.  For smaller sites SQLite is just enough.

  Relational databases are _queried_ using a language called SQL(4).
Python programmers in general do not like SQL too much, as they prefer
to work with objects.  It is possible to save Python objects into a
database using a technology called ORM(5) (Object Relational Mapping).
ORM translates all object-oriented access into SQL code under the hood,
so the developer does not need to think about it.  Most *note
frameworks: 116. use ORMs, and it works quite well.

  A second possibility is storing data in normal, plain text files (some
times called "flat files").  This is very easy for simple sites, but
can be difficult to get right if the web site is performing many
updates to the stored data.

  A third possibility are object oriented databases (also called "object
databases").  These databases store the object data in a form that
closely parallels the way the objects are structured in memory during
program execution.  (By contrast, ORMs store the object data as rows of
data in tables and relations between those rows.)  Storing the objects
directly has the advantage that nearly all objects can be saved in a
straightforward way, unlike in relational databases where some objects
are very hard to represent.

  *note Frameworks: 116. often give hints on which data storage method
to choose.  It is usually a good idea to stick to the data store
recommended by the framework unless the application has special
requirements better satisfied by an alternate storage mechanism.

See also
........

   * Persistence Tools(6) lists possibilities on how to save data in
     the file system.  Some of these modules are part of the standard
     library

   * Database Programming(7) helps with choosing a method for saving
     data

   * SQLAlchemy(8), the most powerful OR-Mapper for Python, and
     Elixir(9), which makes SQLAlchemy easier to use

   * SQLObject(10), another popular OR-Mapper

   * ZODB(11) and Durus(12), two object oriented databases

  ---------- Footnotes ----------

  (1) http://www.mysql.com/

  (2) http://www.postgresql.org/

  (3) http://www.sqlite.org/

  (4) http://en.wikipedia.org/wiki/SQL

  (5) http://en.wikipedia.org/wiki/Object-relational_mapping

  (6) http://wiki.python.org/moin/PersistenceTools

  (7) http://wiki.python.org/moin/DatabaseProgramming

  (8) http://www.sqlalchemy.org/

  (9) http://elixir.ematia.de/

  (10) http://www.sqlobject.org/

  (11) https://launchpad.net/zodb

  (12) http://www.mems-exchange.org/software/durus/


File: python-howto-3.2.2.info,  Node: Frameworks,  Prev: Ingredients for Websites,  Up: HOWTO Use Python in the web

14.5 Frameworks
===============

The process of creating code to run web sites involves writing code to
provide various services.  The code to provide a particular service
often works the same way regardless of the complexity or purpose of the
web site in question.  Abstracting these common solutions into reusable
code produces what are called "frameworks" for web development.
Perhaps the most well-known framework for web development is Ruby on
Rails, but Python has its own frameworks.  Some of these were partly
inspired by Rails, or borrowed ideas from Rails, but many existed a
long time before Rails.

  Originally Python web frameworks tended to incorporate all of the
services needed to develop web sites as a giant, integrated set of
tools.  No two web frameworks were interoperable:  a program developed
for one could not be deployed on a different one without considerable
re-engineering work.  This led to the development of "minimalist" web
frameworks that provided just the tools to communicate between the
Python code and the http protocol, with all other services to be added
on top via separate components.  Some ad hoc standards were developed
that allowed for limited interoperability between frameworks, such as a
standard that allowed different template engines to be used
interchangeably.

  Since the advent of WSGI, the Python web framework world has been
evolving toward interoperability based on the WSGI standard.  Now many
web frameworks, whether "full stack" (providing all the tools one needs
to deploy the most complex web sites) or minimalist, or anything in
between, are built from collections of reusable components that can be
used with more than one framework.

  The majority of users will probably want to select a "full stack"
framework that has an active community.  These frameworks tend to be
well documented, and provide the easiest path to producing a fully
functional web site in minimal time.

* Menu:

* Some notable frameworks::

Some notable frameworks

* Django::
* TurboGears::
* Zope::
* Other notable frameworks::


File: python-howto-3.2.2.info,  Node: Some notable frameworks,  Up: Frameworks

14.5.1 Some notable frameworks
------------------------------

There are an incredible number of frameworks, so they cannot all be
covered here.  Instead we will briefly touch on some of the most
popular.

* Menu:

* Django::
* TurboGears::
* Zope::
* Other notable frameworks::


File: python-howto-3.2.2.info,  Node: Django,  Next: TurboGears,  Up: Some notable frameworks

14.5.1.1 Django
...............

Django(1) is a framework consisting of several tightly coupled elements
which were written from scratch and work together very well.  It
includes an ORM which is quite powerful while being simple to use, and
has a great online administration interface which makes it possible to
edit the data in the database with a browser.  The template engine is
text-based and is designed to be usable for page designers who cannot
write Python.  It supports template inheritance and filters (which work
like Unix pipes).  Django has many handy features bundled, such as
creation of RSS feeds or generic views, which make it possible to
create web sites almost without writing any Python code.

  It has a big, international community, the members of which have
created many web sites.  There are also a lot of add-on projects which
extend Django's normal functionality.  This is partly due to Django's
well written online documentation(2) and the Django book(3).

     Note: Although Django is an MVC-style framework, it names the
     elements differently, which is described in the Django FAQ(4).

  ---------- Footnotes ----------

  (1) http://www.djangoproject.com/

  (2) http://docs.djangoproject.com/

  (3) http://www.djangobook.com/

  (4)
http://docs.djangoproject.com/en/dev/faq/general/#django-appears-to-be-a-mvc-framework-but-you-call-the-controller-the-view-and-the-view-the-template-how-come-you-don-t-use-the-standard-names


File: python-howto-3.2.2.info,  Node: TurboGears,  Next: Zope,  Prev: Django,  Up: Some notable frameworks

14.5.1.2 TurboGears
...................

Another popular web framework for Python is TurboGears(1).  TurboGears
takes the approach of using already existing components and combining
them with glue code to create a seamless experience.  TurboGears gives
the user flexibility in choosing components. For example the ORM and
template engine can be changed to use packages different from those
used by default.

  The documentation can be found in the TurboGears wiki(2), where links
to screencasts can be found.  TurboGears has also an active user
community which can respond to most related questions.  There is also a
TurboGears book(3) published, which is a good starting point.

  The newest version of TurboGears, version 2.0, moves even further in
direction of WSGI support and a component-based architecture.
TurboGears 2 is based on the WSGI stack of another popular
component-based web framework, Pylons(4).

  ---------- Footnotes ----------

  (1) http://www.turbogears.org/

  (2) http://docs.turbogears.org/

  (3) http://turbogearsbook.com/

  (4) http://pylonshq.com/


File: python-howto-3.2.2.info,  Node: Zope,  Next: Other notable frameworks,  Prev: TurboGears,  Up: Some notable frameworks

14.5.1.3 Zope
.............

The Zope framework is one of the "old original" frameworks.  Its current
incarnation in Zope2 is a tightly integrated full-stack framework.  One
of its most interesting feature is its tight integration with a
powerful object database called the ZODB(1) (Zope Object Database).
Because of its highly integrated nature, Zope wound up in a somewhat
isolated ecosystem:  code written for Zope wasn't very usable outside
of Zope, and vice-versa.  To solve this problem the Zope 3 effort was
started.  Zope 3 re-engineers Zope as a set of more cleanly isolated
components.  This effort was started before the advent of the WSGI
standard, but there is WSGI support for Zope 3 from the Repoze(2)
project.  Zope components have many years of production use behind
them, and the Zope 3 project gives access to these components to the
wider Python community.  There is even a separate framework based on
the Zope components: Grok(3).

  Zope is also the infrastructure used by the Plone(4) content
management system, one of the most powerful and popular content
management systems available.

  ---------- Footnotes ----------

  (1) https://launchpad.net/zodb

  (2) http://repoze.org/

  (3) http://grok.zope.org/

  (4) http://plone.org/


File: python-howto-3.2.2.info,  Node: Other notable frameworks,  Prev: Zope,  Up: Some notable frameworks

14.5.1.4 Other notable frameworks
.................................

Of course these are not the only frameworks that are available.  There
are many other frameworks worth mentioning.

  Another framework that's already been mentioned is Pylons(1).  Pylons
is much like TurboGears, but with an even stronger emphasis on
flexibility, which comes at the cost of being more difficult to use.
Nearly every component can be exchanged, which makes it necessary to
use the documentation of every single component, of which there are
many.  Pylons builds upon Paste(2), an extensive set of tools which are
handy for WSGI.

  And that's still not everything.  The most up-to-date information can
always be found in the Python wiki.

See also
........

The Python wiki contains an extensive list of web frameworks(3).

  Most frameworks also have their own mailing lists and IRC channels,
look out for these on the projects' web sites.  There is also a general
"Python in the Web" IRC channel on freenode called #python.web(4).

  ---------- Footnotes ----------

  (1) http://pylonshq.com/

  (2) http://pythonpaste.org/

  (3) http://wiki.python.org/moin/WebFrameworks

  (4) http://wiki.python.org/moin/PoundPythonWeb


File: python-howto-3.2.2.info,  Node: Index,  Prev: HOWTO Use Python in the web,  Up: Top

Index
*****

 [index ]
* Menu:

* __init__() (logging.logging.Formatter method): Formatters.   (line 13)
* Python Enhancement Proposals; PEP 289: Python documentation. (line 10)
* Python Enhancement Proposals; PEP 3121: Module initialization and state.
                                                               (line  6)
* Python Enhancement Proposals; PEP 333: Step back WSGI.       (line  9)
* Python Enhancement Proposals; PEP 342: Python documentation. (line 12)
* RFC; RFC 2616:                         Introduction<3>.      (line 33)



Tag Table:
Node: Top426
Ref: howto/index doc689
Ref: 0689
Node: Python Advocacy HOWTO8923
Ref: howto/advocacy python-howtos9050
Ref: 19050
Ref: howto/advocacy doc9050
Ref: 29050
Ref: howto/advocacy python-advocacy-howto9050
Ref: 39050
Node: Reasons to Use Python9660
Ref: howto/advocacy reasons-to-use-python9783
Ref: 49783
Node: Programmability10150
Ref: howto/advocacy programmability10255
Ref: 510255
Node: Prototyping12425
Ref: howto/advocacy prototyping12575
Ref: 612575
Node: Simplicity and Ease of Understanding16772
Ref: howto/advocacy simplicity-and-ease-of-understanding16923
Ref: 716923
Node: Java Integration20051
Ref: howto/advocacy java-integration20182
Ref: 820182
Node: Arguments and Rebuttals20831
Ref: howto/advocacy arguments-and-rebuttals20979
Ref: 920979
Node: Useful Resources25296
Ref: howto/advocacy useful-resources25414
Ref: a25414
Node: Porting Python 2 Code to Python 328192
Ref: howto/pyporting pyporting-howto28348
Ref: b28348
Ref: howto/pyporting porting-python-2-code-to-python-328348
Ref: c28348
Ref: howto/pyporting doc28348
Ref: d28348
Node: Choosing a Strategy30290
Ref: howto/pyporting choosing-a-strategy30417
Ref: f30417
Node: Universal Bits of Advice32027
Ref: howto/pyporting universal-bits-of-advice32119
Ref: 1332119
Ref: howto/pyporting cheeseshop34639
Ref: 1434639
Ref: Universal Bits of Advice-Footnote-134674
Ref: Universal Bits of Advice-Footnote-234707
Ref: Universal Bits of Advice-Footnote-334738
Ref: Universal Bits of Advice-Footnote-434769
Ref: Universal Bits of Advice-Footnote-534825
Ref: Universal Bits of Advice-Footnote-634890
Ref: Universal Bits of Advice-Footnote-734928
Ref: Universal Bits of Advice-Footnote-834963
Ref: Universal Bits of Advice-Footnote-934998
Node: Python 3 and 3to235033
Ref: howto/pyporting python-3-and-3to235186
Ref: 1535186
Ref: howto/pyporting use-3to235186
Ref: 1035186
Ref: Python 3 and 3to2-Footnote-136017
Node: Python 2 and 2to336072
Ref: howto/pyporting use-2to336234
Ref: 1236234
Ref: howto/pyporting python-2-and-2to336234
Ref: 1636234
Ref: Python 2 and 2to3-Footnote-138106
Node: Support Python 2 738159
Ref: howto/pyporting support-python-2-738292
Ref: 1738292
Ref: Support Python 2 7-Footnote-138718
Node: Try to Support Python 2 6 and Newer Only38753
Ref: howto/pyporting try-to-support-python-2-6-and-newer-only38931
Ref: 1838931
Ref: Try to Support Python 2 6 and Newer Only-Footnote-139915
Ref: Try to Support Python 2 6 and Newer Only-Footnote-239950
Ref: Try to Support Python 2 6 and Newer Only-Footnote-339985
Node: from __future__ import print_function40020
Ref: howto/pyporting from-future-import-print-function40194
Ref: 1940194
Node: from __future__ import unicode_literals40564
Ref: howto/pyporting from-future-import-unicode-literals40761
Ref: 1a40761
Node: Bytes literals41311
Ref: howto/pyporting bytes-literals41462
Ref: 1b41462
Node: Supporting Python 2 5 and Newer Only42563
Ref: howto/pyporting supporting-python-2-5-and-newer-only42746
Ref: 1c42746
Ref: Supporting Python 2 5 and Newer Only-Footnote-143030
Node: from __future__ import absolute_import43065
Ref: howto/pyporting from-future-import-absolute-import43188
Ref: 1d43188
Ref: from __future__ import absolute_import-Footnote-144058
Ref: from __future__ import absolute_import-Footnote-244093
Ref: from __future__ import absolute_import-Footnote-344128
Node: Handle Common "Gotchas"44163
Ref: howto/pyporting handle-common-gotchas44327
Ref: 1e44327
Node: from __future__ import division44904
Ref: howto/pyporting from-future-import-division45053
Ref: 1f45053
Node: Specify when opening a file as binary45385
Ref: howto/pyporting specify-when-opening-a-file-as-binary45553
Ref: 2045553
Node: Text files46133
Ref: howto/pyporting text-files46285
Ref: 2146285
Node: Subclass object46958
Ref: howto/pyporting subclass-object47109
Ref: 2247109
Ref: Subclass object-Footnote-147490
Node: Deal With the Bytes/String Dichotomy47525
Ref: howto/pyporting deal-with-the-bytes-string-dichotomy47688
Ref: 2347688
Node: Mark Up Python 2 String Literals48580
Ref: howto/pyporting mark-up-python-2-string-literals48734
Ref: 2448734
Ref: Mark Up Python 2 String Literals-Footnote-149412
Node: Decide what APIs Will Accept49450
Ref: howto/pyporting decide-what-apis-will-accept49639
Ref: 2549639
Node: Bytes / Unicode Comparison50374
Ref: howto/pyporting bytes-unicode-comparison50522
Ref: 2650522
Node: Indexing bytes objects51574
Ref: howto/pyporting indexing-bytes-objects51742
Ref: 2751742
Node: __str__ /__unicode__52547
Ref: howto/pyporting str-unicode52704
Ref: 2852704
Node: Don't Index on Exceptions54327
Ref: howto/pyporting don-t-index-on-exceptions54494
Ref: 2954494
Node: Don't use __getslice__ & Friends54994
Ref: howto/pyporting don-t-use-getslice-friends55158
Ref: 2a55158
Node: Updating doctests55392
Ref: howto/pyporting updating-doctests55522
Ref: 2b55522
Ref: Updating doctests-Footnote-156018
Node: Eliminate -3 Warnings56071
Ref: howto/pyporting eliminate-3-warnings56207
Ref: 2c56207
Node: Run 2to356594
Ref: howto/pyporting run-2to356720
Ref: 2d56720
Ref: Run 2to3-Footnote-156958
Node: Manually57011
Ref: howto/pyporting manually57104
Ref: 2e57104
Ref: Manually-Footnote-157642
Node: During Installation57695
Ref: howto/pyporting during-installation57788
Ref: 2f57788
Ref: During Installation-Footnote-158590
Ref: During Installation-Footnote-258636
Node: Verify & Test58689
Ref: howto/pyporting verify-test58785
Ref: 3058785
Node: Python 2/3 Compatible Source59182
Ref: howto/pyporting python-2-3-compatible-source59342
Ref: 3159342
Ref: howto/pyporting use-same-source59342
Ref: 1159342
Ref: Python 2/3 Compatible Source-Footnote-160551
Ref: Python 2/3 Compatible Source-Footnote-260604
Node: Follow The Steps for Using 2to360664
Ref: howto/pyporting follow-the-steps-for-using-2to360788
Ref: 3260788
Ref: howto/pyporting what-s-new-in-python-3-060788
Ref: 3360788
Ref: Follow The Steps for Using 2to3-Footnote-161416
Node: Use six61469
Ref: howto/pyporting use-six61642
Ref: 3461642
Ref: Use six-Footnote-161985
Node: Capturing the Currently Raised Exception62023
Ref: howto/pyporting capturing-the-currently-raised-exception62156
Ref: 3562156
Ref: Capturing the Currently Raised Exception-Footnote-163894
Ref: Capturing the Currently Raised Exception-Footnote-263929
Node: Other Resources63964
Ref: howto/pyporting other-resources64098
Ref: 3664098
Ref: Other Resources-Footnote-164994
Node: Porting Extension Modules to 3 065056
Ref: howto/cporting python-porting65221
Ref: 3765221
Ref: howto/cporting porting-extension-modules-to-3-065221
Ref: 3865221
Ref: howto/cporting doc65221
Ref: 3965221
Ref: howto/cporting cporting-howto65221
Ref: e65221
Node: Conditional compilation65790
Ref: howto/cporting conditional-compilation65925
Ref: 3a65925
Node: Changes to Object APIs66259
Ref: howto/cporting changes-to-object-apis66434
Ref: 3b66434
Node: str/unicode Unification66647
Ref: howto/cporting str-unicode-unification66770
Ref: 3c66770
Node: long/int Unification68334
Ref: howto/cporting long-int-unification68457
Ref: 3d68457
Node: Module initialization and state69216
Ref: howto/cporting module-initialization-and-state69381
Ref: 3e69381
Ref: Module initialization and state-Footnote-171703
Node: Other options71750
Ref: howto/cporting other-options71884
Ref: 3f71884
Ref: Other options-Footnote-172148
Node: Curses Programming with Python72177
Ref: howto/curses curses-howto72331
Ref: 4072331
Ref: howto/curses doc72331
Ref: 4172331
Ref: howto/curses curses-programming-with-python72331
Ref: 4272331
Node: What is curses?72862
Ref: howto/curses what-is-curses73005
Ref: 4373005
Node: The Python curses module75318
Ref: howto/curses the-python-curses-module75406
Ref: 4475406
Node: Starting and ending a curses application76202
Ref: howto/curses starting-and-ending-a-curses-application76370
Ref: 4576370
Node: Windows and Pads79007
Ref: howto/curses windows-and-pads79175
Ref: 4679175
Node: Displaying Text82894
Ref: howto/curses displaying-text83032
Ref: 4783032
Node: Attributes and Color86067
Ref: howto/curses attributes-and-color86151
Ref: 4886151
Node: User Input90172
Ref: howto/curses user-input90314
Ref: 4990314
Node: For More Information93027
Ref: howto/curses for-more-information93145
Ref: 4a93145
Node: Descriptor HowTo Guide94292
Ref: howto/descriptor descriptor-howto-guide94442
Ref: 4b94442
Ref: howto/descriptor doc94442
Ref: 4c94442
Node: Abstract94769
Ref: howto/descriptor abstract94884
Ref: 4d94884
Node: Definition and Introduction95399
Ref: howto/descriptor definition-and-introduction95542
Ref: 4e95542
Node: Descriptor Protocol96970
Ref: howto/descriptor descriptor-protocol97125
Ref: 4f97125
Node: Invoking Descriptors98344
Ref: howto/descriptor invoking-descriptors98490
Ref: 5098490
Ref: Invoking Descriptors-Footnote-1101622
Ref: Invoking Descriptors-Footnote-2101698
Ref: Invoking Descriptors-Footnote-3101778
Node: Descriptor Example101841
Ref: howto/descriptor descriptor-example101978
Ref: 51101978
Node: Properties103333
Ref: howto/descriptor properties103471
Ref: 52103471
Node: Functions and Methods105715
Ref: howto/descriptor functions-and-methods105867
Ref: 53105867
Ref: Functions and Methods-Footnote-1108258
Node: Static Methods and Class Methods108339
Ref: howto/descriptor static-methods-and-class-methods108472
Ref: 54108472
Node: Functional Programming HOWTO112534
Ref: howto/functional doc112667
Ref: 55112667
Ref: howto/functional functional-programming-howto112667
Ref: 56112667
Node: Introduction113856
Ref: howto/functional introduction113963
Ref: 57113963
Node: Formal provability118603
Ref: howto/functional formal-provability118701
Ref: 58118701
Node: Modularity120600
Ref: howto/functional modularity120736
Ref: 59120736
Node: Ease of debugging and testing121135
Ref: howto/functional ease-of-debugging-and-testing121266
Ref: 5a121266
Node: Composability121995
Ref: howto/functional composability122107
Ref: 5b122107
Node: Iterators122822
Ref: howto/functional iterators122983
Ref: 5c122983
Node: Data Types That Support Iterators126089
Ref: howto/functional data-types-that-support-iterators126180
Ref: 5d126180
Node: Generator expressions and list comprehensions127904
Ref: howto/functional generator-expressions-and-list-comprehensions128063
Ref: 5e128063
Node: Generators132449
Ref: howto/functional generators132617
Ref: 5f132617
Node: Passing values into a generator136475
Ref: howto/functional passing-values-into-a-generator136565
Ref: 60136565
Node: Built-in functions140266
Ref: howto/functional built-in-functions140409
Ref: 61140409
Ref: Built-in functions-Footnote-1144267
Node: The itertools module144319
Ref: howto/functional the-itertools-module144472
Ref: 62144472
Node: Creating new iterators145167
Ref: howto/functional creating-new-iterators145296
Ref: 63145296
Node: Calling functions on elements147742
Ref: howto/functional calling-functions-on-elements147898
Ref: 64147898
Node: Selecting elements148639
Ref: howto/functional selecting-elements148790
Ref: 65148790
Node: Grouping elements149900
Ref: howto/functional grouping-elements150013
Ref: 66150013
Node: The functools module151502
Ref: howto/functional the-functools-module151678
Ref: 67151678
Node: The operator module154757
Ref: howto/functional the-operator-module154875
Ref: 68154875
Node: The functional module155602
Ref: howto/functional the-functional-module155720
Ref: 69155720
Ref: The functional module-Footnote-1159262
Ref: The functional module-Footnote-2159307
Ref: The functional module-Footnote-3159366
Node: Small functions and the lambda expression159411
Ref: howto/functional small-functions-and-the-lambda-expression159604
Ref: 6a159604
Node: Revision History and Acknowledgements162428
Ref: howto/functional revision-history-and-acknowledgements162611
Ref: 6b162611
Node: References163390
Ref: howto/functional references163523
Ref: 6c163523
Node: General163623
Ref: howto/functional general163713
Ref: 6d163713
Node: Python-specific164632
Ref: howto/functional python-specific164751
Ref: 6e164751
Ref: Python-specific-Footnote-1165205
Ref: Python-specific-Footnote-2165270
Ref: Python-specific-Footnote-3165336
Node: Python documentation165408
Ref: howto/functional python-documentation165511
Ref: 6f165511
Ref: Python documentation-Footnote-1165833
Ref: Python documentation-Footnote-2165880
Node: Logging HOWTO165927
Ref: howto/logging logging-howto166054
Ref: 70166054
Ref: howto/logging doc166054
Ref: 71166054
Node: Basic Logging Tutorial166815
Ref: howto/logging basic-logging-tutorial166933
Ref: 72166933
Ref: howto/logging logging-basic-tutorial166933
Ref: 73166933
Node: When to use logging167709
Ref: howto/logging when-to-use-logging167824
Ref: 74167824
Node: A simple example170997
Ref: howto/logging a-simple-example171138
Ref: 75171138
Ref: howto/logging howto-minimal-example171138
Ref: 76171138
Node: Logging to a file171887
Ref: howto/logging logging-to-a-file172038
Ref: 77172038
Node: Logging from multiple modules174343
Ref: howto/logging logging-from-multiple-modules174499
Ref: 78174499
Node: Logging variable data175671
Ref: howto/logging logging-variable-data175851
Ref: 7a175851
Node: Changing the format of displayed messages176538
Ref: howto/logging changing-the-format-of-displayed-messages176725
Ref: 7b176725
Node: Displaying the date/time in messages177691
Ref: howto/logging displaying-the-date-time-in-messages177867
Ref: 7c177867
Node: Next Steps178831
Ref: howto/logging next-steps178957
Ref: 7d178957
Node: Advanced Logging Tutorial179886
Ref: howto/logging logging-advanced-tutorial180027
Ref: 79180027
Ref: howto/logging advanced-logging-tutorial180027
Ref: 7f180027
Node: Loggers183092
Ref: howto/logging loggers183190
Ref: 80183190
Node: Handlers187224
Ref: howto/logging handler-basic187341
Ref: 81187341
Ref: howto/logging handlers187341
Ref: 82187341
Node: Formatters189287
Ref: howto/logging formatters189416
Ref: 84189416
Ref: howto/logging logging logging Formatter __init__189847
Ref: 85189847
Node: Configuring Logging191425
Ref: howto/logging configuring-logging191590
Ref: 86191590
Node: What happens if no configuration is provided197012
Ref: howto/logging what-happens-if-no-configuration-is-provided197200
Ref: 87197200
Node: Configuring Logging for a Library198576
Ref: howto/logging library-config198736
Ref: 88198736
Ref: howto/logging configuring-logging-for-a-library198736
Ref: 89198736
Node: Logging Levels201065
Ref: howto/logging logging-levels201199
Ref: 8a201199
Node: Custom Levels203657
Ref: howto/logging custom-levels203733
Ref: 8b203733
Ref: howto/logging id1203733
Ref: 8c203733
Node: Useful Handlers204440
Ref: howto/logging useful-handlers204581
Ref: 83204581
Ref: howto/logging id2204581
Ref: 8d204581
Node: Exceptions raised during logging208104
Ref: howto/logging logging-exceptions208266
Ref: 8e208266
Ref: howto/logging exceptions-raised-during-logging208266
Ref: 8f208266
Node: Using arbitrary objects as messages209292
Ref: howto/logging using-arbitrary-objects-as-messages209451
Ref: 90209451
Ref: howto/logging arbitrary-object-messages209451
Ref: 91209451
Node: Optimization210036
Ref: howto/logging optimization210154
Ref: 92210154
Node: Logging Cookbook212053
Ref: howto/logging-cookbook id1212176
Ref: 93212176
Ref: howto/logging-cookbook doc212176
Ref: 94212176
Ref: howto/logging-cookbook logging-cookbook212176
Ref: 7e212176
Node: Using logging in multiple modules212860
Ref: howto/logging-cookbook using-logging-in-multiple-modules212999
Ref: 95212999
Node: Multiple handlers and formatters216503
Ref: howto/logging-cookbook multiple-handlers-and-formatters216683
Ref: 96216683
Node: Logging to multiple destinations218794
Ref: howto/logging-cookbook logging-to-multiple-destinations218969
Ref: 97218969
Ref: howto/logging-cookbook multiple-destinations218969
Ref: 98218969
Node: Configuration server example221772
Ref: howto/logging-cookbook configuration-server-example221947
Ref: 99221947
Node: Dealing with handlers that block223463
Ref: howto/logging-cookbook dealing-with-handlers-that-block223659
Ref: 9a223659
Node: Sending and receiving logging events across a network226598
Ref: howto/logging-cookbook network-logging226818
Ref: 9b226818
Ref: howto/logging-cookbook sending-and-receiving-logging-events-across-a-network226818
Ref: 9c226818
Node: Adding contextual information to your logging output232153
Ref: howto/logging-cookbook context-info232389
Ref: 9d232389
Ref: howto/logging-cookbook adding-contextual-information-to-your-logging-output232389
Ref: 9e232389
Node: Using LoggerAdapters to impart contextual information233446
Ref: howto/logging-cookbook using-loggeradapters-to-impart-contextual-information233655
Ref: 9f233655
Node: Using Filters to impart contextual information239472
Ref: howto/logging-cookbook using-filters-to-impart-contextual-information239681
Ref: a0239681
Ref: howto/logging-cookbook filters-contextual239681
Ref: a1239681
Node: Logging to a single file from multiple processes243375
Ref: howto/logging-cookbook logging-to-a-single-file-from-multiple-processes243577
Ref: a2243577
Ref: howto/logging-cookbook multiple-processes243577
Ref: a3243577
Node: Using file rotation253745
Ref: howto/logging-cookbook using-file-rotation253938
Ref: a4253938
Node: Subclassing QueueHandler - a ZeroMQ example255785
Ref: howto/logging-cookbook zeromq-handlers255974
Ref: a5255974
Ref: howto/logging-cookbook subclassing-queuehandler-a-zeromq-example255974
Ref: a6255974
Node: Subclassing QueueListener - a ZeroMQ example257334
Ref: howto/logging-cookbook subclassing-queuelistener-a-zeromq-example257495
Ref: a7257495
Node: Regular Expression HOWTO258500
Ref: howto/regex regex-howto258634
Ref: a8258634
Ref: howto/regex regular-expression-howto258634
Ref: a9258634
Ref: howto/regex doc258634
Ref: aa258634
Node: Introduction<2>259119
Ref: howto/regex introduction259231
Ref: ab259231
Node: Simple Patterns260815
Ref: howto/regex simple-patterns260961
Ref: ac260961
Node: Matching Characters261449
Ref: howto/regex matching-characters261557
Ref: ad261557
Node: Repeating Things265312
Ref: howto/regex repeating-things265420
Ref: ae265420
Node: Using Regular Expressions270003
Ref: howto/regex using-regular-expressions270152
Ref: af270152
Node: Compiling Regular Expressions270602
Ref: howto/regex compiling-regular-expressions270734
Ref: b0270734
Node: The Backslash Plague271902
Ref: howto/regex the-backslash-plague272061
Ref: b1272061
Node: Performing Matches274137
Ref: howto/regex performing-matches274289
Ref: b2274289
Ref: Performing Matches-Footnote-1279109
Node: Module-Level Functions279146
Ref: howto/regex module-level-functions279295
Ref: b3279295
Node: Compilation Flags281016
Ref: howto/regex compilation-flags281138
Ref: b4281138
Node: More Pattern Power286375
Ref: howto/regex more-pattern-power286526
Ref: b6286526
Node: More Metacharacters286882
Ref: howto/regex more-metacharacters286985
Ref: b5286985
Ref: howto/regex id1286985
Ref: b7286985
Node: Grouping291290
Ref: howto/regex grouping291432
Ref: b8291432
Node: Non-capturing and Named Groups294737
Ref: howto/regex non-capturing-and-named-groups294880
Ref: b9294880
Node: Lookahead Assertions300283
Ref: howto/regex lookahead-assertions300409
Ref: ba300409
Node: Modifying Strings303778
Ref: howto/regex modifying-strings303919
Ref: bb303919
Node: Splitting Strings304699
Ref: howto/regex splitting-strings304809
Ref: bc304809
Node: Search and Replace307042
Ref: howto/regex search-and-replace307152
Ref: bd307152
Node: Common Problems311470
Ref: howto/regex common-problems311601
Ref: be311601
Node: Use String Methods312029
Ref: howto/regex use-string-methods312139
Ref: bf312139
Node: match versus search313733
Ref: howto/regex match-versus-search313876
Ref: c0313876
Node: Greedy versus Non-Greedy315402
Ref: howto/regex greedy-versus-non-greedy315543
Ref: c1315543
Node: Using re VERBOSE317364
Ref: howto/regex using-re-verbose317477
Ref: c2317477
Node: Feedback318949
Ref: howto/regex feedback319054
Ref: c3319054
Node: Socket Programming HOWTO319813
Ref: howto/sockets doc319945
Ref: c4319945
Ref: howto/sockets socket-programming-howto319945
Ref: c5319945
Node: Sockets320694
Ref: howto/sockets sockets320800
Ref: c6320800
Node: History322261
Ref: howto/sockets history322324
Ref: c7322324
Node: Creating a Socket322894
Ref: howto/sockets creating-a-socket323023
Ref: c8323023
Node: IPC326084
Ref: howto/sockets ipc326153
Ref: c9326153
Node: Using a Socket326604
Ref: howto/sockets using-a-socket326739
Ref: ca326739
Node: Binary Data332581
Ref: howto/sockets binary-data332655
Ref: cb332655
Node: Disconnecting333695
Ref: howto/sockets disconnecting333833
Ref: cc333833
Node: When Sockets Die335225
Ref: howto/sockets when-sockets-die335303
Ref: cd335303
Node: Non-blocking Sockets336166
Ref: howto/sockets non-blocking-sockets336281
Ref: ce336281
Node: Performance340443
Ref: howto/sockets performance340523
Ref: cf340523
Node: Sorting HOW TO341907
Ref: howto/sorting sortinghowto342028
Ref: d0342028
Ref: howto/sorting doc342028
Ref: d1342028
Ref: howto/sorting sorting-how-to342028
Ref: d2342028
Node: Sorting Basics342646
Ref: howto/sorting sorting-basics342745
Ref: d3342745
Node: Key Functions343470
Ref: howto/sorting key-functions343603
Ref: d4343603
Node: Operator Module Functions345189
Ref: howto/sorting operator-module-functions345332
Ref: d5345332
Node: Ascending and Descending346344
Ref: howto/sorting ascending-and-descending346506
Ref: d6346506
Node: Sort Stability and Complex Sorts347015
Ref: howto/sorting sort-stability-and-complex-sorts347194
Ref: d7347194
Ref: Sort Stability and Complex Sorts-Footnote-1348359
Ref: Sort Stability and Complex Sorts-Footnote-2348423
Node: The Old Way Using Decorate-Sort-Undecorate348467
Ref: howto/sorting the-old-way-using-decorate-sort-undecorate348657
Ref: d8348657
Ref: The Old Way Using Decorate-Sort-Undecorate-Footnote-1350340
Node: The Old Way Using the cmp Parameter350398
Ref: howto/sorting the-old-way-using-the-cmp-parameter350568
Ref: d9350568
Node: Odd and Ends352974
Ref: howto/sorting odd-and-ends353093
Ref: da353093
Node: Unicode HOWTO354521
Ref: howto/unicode unicode-howto354673
Ref: db354673
Ref: howto/unicode doc354673
Ref: dc354673
Ref: howto/unicode id1354673
Ref: dd354673
Node: Introduction to Unicode355412
Ref: howto/unicode introduction-to-unicode355530
Ref: de355530
Node: History of Character Codes355689
Ref: howto/unicode history-of-character-codes355807
Ref: df355807
Node: Definitions359044
Ref: howto/unicode definitions359180
Ref: e0359180
Node: Encodings360975
Ref: howto/unicode encodings361098
Ref: e1361098
Node: References<2>365547
Ref: howto/unicode references365650
Ref: e2365650
Node: Python's Unicode Support366593
Ref: howto/unicode python-s-unicode-support366752
Ref: e3366752
Node: The String Type367055
Ref: howto/unicode the-string-type367171
Ref: e4367171
Node: Converting to Bytes369579
Ref: howto/unicode converting-to-bytes369742
Ref: e5369742
Node: Unicode Literals in Python Source Code371394
Ref: howto/unicode unicode-literals-in-python-source-code371560
Ref: e6371560
Node: Unicode Properties373551
Ref: howto/unicode unicode-properties373711
Ref: e7373711
Node: References<3>375358
Ref: howto/unicode id2375471
Ref: e8375471
Node: Reading and Writing Unicode Data376054
Ref: howto/unicode reading-and-writing-unicode-data376206
Ref: e9376206
Node: Unicode filenames379811
Ref: howto/unicode unicode-filenames379957
Ref: ea379957
Node: Tips for Writing Unicode-aware Programs382322
Ref: howto/unicode tips-for-writing-unicode-aware-programs382490
Ref: eb382490
Node: References<4>384509
Ref: howto/unicode id3384651
Ref: ec384651
Node: Acknowledgements385052
Ref: howto/unicode acknowledgements385171
Ref: ed385171
Node: HOWTO Fetch Internet Resources Using The urllib Package385426
Ref: howto/urllib2 howto-fetch-internet-resources-using-the-urllib-package385591
Ref: ee385591
Ref: howto/urllib2 doc385591
Ref: ef385591
Ref: howto/urllib2 urllib-howto385591
Ref: f0385591
Ref: HOWTO Fetch Internet Resources Using The urllib Package-Footnote-1386111
Ref: HOWTO Fetch Internet Resources Using The urllib Package-Footnote-2386165
Node: Introduction<3>386239
Ref: howto/urllib2 introduction386380
Ref: f1386380
Ref: Introduction<3>-Footnote-1387939
Ref: Introduction<3>-Footnote-2388011
Ref: Introduction<3>-Footnote-3388040
Node: Fetching URLs388087
Ref: howto/urllib2 fetching-urls388256
Ref: f2388256
Node: Data389928
Ref: howto/urllib2 data390010
Ref: f3390010
Ref: Data-Footnote-1392505
Ref: Data-Footnote-2392662
Node: Headers392729
Ref: howto/urllib2 headers392811
Ref: f4392811
Ref: Headers-Footnote-1394249
Ref: Headers-Footnote-2394516
Ref: Headers-Footnote-3394724
Ref: Headers-Footnote-4394839
Node: Handling Exceptions394968
Ref: howto/urllib2 handling-exceptions395137
Ref: f6395137
Node: URLError395578
Ref: howto/urllib2 urlerror395672
Ref: f7395672
Node: HTTPError396210
Ref: howto/urllib2 httperror396327
Ref: f8396327
Node: Error Codes397131
Ref: howto/urllib2 error-codes397200
Ref: f9397200
Node: Wrapping it Up401872
Ref: howto/urllib2 wrapping-it-up401972
Ref: fa401972
Node: Number 1402178
Ref: howto/urllib2 number-1402266
Ref: fb402266
Node: Number 2402862
Ref: howto/urllib2 number-2402950
Ref: fc402950
Node: info and geturl403470
Ref: howto/urllib2 info-and-geturl403646
Ref: f5403646
Ref: info and geturl-Footnote-1404491
Node: Openers and Handlers404539
Ref: howto/urllib2 openers-and-handlers404716
Ref: fd404716
Node: Basic Authentication406306
Ref: howto/urllib2 id6406475
Ref: fe406475
Ref: Basic Authentication-Footnote-1409638
Node: Proxies409710
Ref: howto/urllib2 proxies409877
Ref: ff409877
Ref: Proxies-Footnote-1410693
Ref: Proxies-Footnote-2410992
Ref: Proxies-Footnote-3411064
Node: Sockets and Layers411204
Ref: howto/urllib2 sockets-and-layers411360
Ref: 100411360
Node: Footnotes412355
Ref: howto/urllib2 footnotes412495
Ref: 101412495
Node: HOWTO Use Python in the web412579
Ref: howto/webservers doc412736
Ref: 102412736
Ref: howto/webservers howto-use-python-in-the-web412736
Ref: 103412736
Ref: HOWTO Use Python in the web-Footnote-1414659
Node: The Low-Level View414709
Ref: howto/webservers the-low-level-view414826
Ref: 104414826
Node: Common Gateway Interface416535
Ref: howto/webservers common-gateway-interface416645
Ref: 105416645
Ref: Common Gateway Interface-Footnote-1418143
Node: Simple script for testing CGI418189
Ref: howto/webservers simple-script-for-testing-cgi418333
Ref: 107418333
Node: Setting up CGI on your own server419428
Ref: howto/webservers setting-up-cgi-on-your-own-server419613
Ref: 108419613
Ref: Setting up CGI on your own server-Footnote-1421062
Ref: Setting up CGI on your own server-Footnote-2421094
Ref: Setting up CGI on your own server-Footnote-3421125
Ref: Setting up CGI on your own server-Footnote-4421180
Node: Common problems with CGI scripts421241
Ref: howto/webservers common-problems-with-cgi-scripts421388
Ref: 109421388
Node: mod_python424392
Ref: howto/webservers mod-python424527
Ref: 10a424527
Ref: howto/webservers id1424527
Ref: 10b424527
Ref: mod_python-Footnote-1426499
Node: FastCGI and SCGI426532
Ref: howto/webservers fastcgi-and-scgi426651
Ref: 10c426651
Ref: FastCGI and SCGI-Footnote-1427906
Node: Setting up FastCGI428012
Ref: howto/webservers setting-up-fastcgi428095
Ref: 10d428095
Ref: Setting up FastCGI-Footnote-1429704
Ref: Setting up FastCGI-Footnote-2429742
Ref: Setting up FastCGI-Footnote-3429777
Ref: Setting up FastCGI-Footnote-4429842
Ref: Setting up FastCGI-Footnote-5429904
Ref: Setting up FastCGI-Footnote-6429929
Ref: Setting up FastCGI-Footnote-7429980
Ref: Setting up FastCGI-Footnote-8430024
Node: mod_wsgi430094
Ref: howto/webservers mod-wsgi430194
Ref: 10e430194
Ref: mod_wsgi-Footnote-1431059
Node: Step back WSGI431100
Ref: howto/webservers wsgi431247
Ref: 106431247
Ref: howto/webservers step-back-wsgi431247
Ref: 10f431247
Ref: Step back WSGI-Footnote-1433482
Ref: Step back WSGI-Footnote-2433529
Node: WSGI Servers433582
Ref: howto/webservers wsgi-servers433685
Ref: 110433685
Ref: WSGI Servers-Footnote-1434667
Ref: WSGI Servers-Footnote-2434725
Ref: WSGI Servers-Footnote-3434753
Node: Case study MoinMoin434789
Ref: howto/webservers case-study-moinmoin434892
Ref: 111434892
Ref: Case study MoinMoin-Footnote-1435632
Node: Model-View-Controller435657
Ref: howto/webservers model-view-controller435810
Ref: 112435810
Ref: Model-View-Controller-Footnote-1437974
Node: Ingredients for Websites438032
Ref: howto/webservers ingredients-for-websites438181
Ref: 113438181
Ref: Ingredients for Websites-Footnote-1438882
Node: Templates438931
Ref: howto/webservers templates439038
Ref: 114439038
Ref: Templates-Footnote-1440813
Ref: Templates-Footnote-2440850
Ref: Templates-Footnote-3440885
Ref: Templates-Footnote-4440918
Node: Data persistence440964
Ref: howto/webservers data-persistence441071
Ref: 117441071
Ref: Data persistence-Footnote-1443795
Ref: Data persistence-Footnote-2443824
Ref: Data persistence-Footnote-3443858
Ref: Data persistence-Footnote-4443888
Ref: Data persistence-Footnote-5443928
Ref: Data persistence-Footnote-6443990
Ref: Data persistence-Footnote-7444042
Ref: Data persistence-Footnote-8444097
Ref: Data persistence-Footnote-9444131
Ref: Data persistence-Footnote-10444163
Ref: Data persistence-Footnote-11444197
Ref: Data persistence-Footnote-12444232
Node: Frameworks444285
Ref: howto/webservers framework444404
Ref: 115444404
Ref: howto/webservers frameworks444404
Ref: 116444404
Node: Some notable frameworks446475
Ref: howto/webservers some-notable-frameworks446557
Ref: 118446557
Node: Django446837
Ref: howto/webservers django446934
Ref: 119446934
Ref: Django-Footnote-1448090
Ref: Django-Footnote-2448127
Ref: Django-Footnote-3448165
Ref: Django-Footnote-4448199
Node: TurboGears448398
Ref: howto/webservers turbogears448508
Ref: 11a448508
Ref: TurboGears-Footnote-1449458
Ref: TurboGears-Footnote-2449492
Ref: TurboGears-Footnote-3449527
Ref: TurboGears-Footnote-4449561
Node: Zope449589
Ref: howto/webservers zope449717
Ref: 11b449717
Ref: Zope-Footnote-1450863
Ref: Zope-Footnote-2450897
Ref: Zope-Footnote-3450923
Ref: Zope-Footnote-4450952
Node: Other notable frameworks450977
Ref: howto/webservers other-notable-frameworks451086
Ref: 11c451086
Ref: Other notable frameworks-Footnote-1452140
Ref: Other notable frameworks-Footnote-2452168
Ref: Other notable frameworks-Footnote-3452199
Ref: Other notable frameworks-Footnote-4452248
Node: Index452298

End Tag Table


Local Variables:
coding: utf-8
End:
